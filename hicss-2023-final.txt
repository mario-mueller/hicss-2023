							************************
									 hicss-2023-final.txt
							************************

Filename is hicss-2023-final.txt.

This file contains primary output for SIENA project <<hicss-2023-final>>.

Date and time: 01/06/2022 19:57:37 

RSiena version 1.3.0.1 (02 05 2021)


@1
Data input.
===========

Dependent variables	  Type		 NodeSet(s) (R, C)
-------------------	  ----		 -----------------
net                  bipartite   devs (1172), pkgs (250)
0 constant actor covariates,
6 exogenous changing actor covariates,
0 constant dyadic covariates,
2 exogenous changing dyadic covariates,
1 file with times of composition change.


@2
Reading network variables.
--------------------------

Name of network variable: net.
bipartite network.
This is a two-mode network.
The number of units in the second mode is 250.
For observation moment 1, degree distributions are as follows:
Nodes
   1    2    3    4    5    6    7    8    9   10   11   12 
  13   14   15   16   17   18   19   20   21   22   23   24 
  25   26   27   28   29   30   31   32   33   34   35   36 
  37   38   39   40   41   42   43   44   45   46   47   48 
  49   50   51   52   53   54   55   56   57   58   59   60 
  61   62   63   64   65   66   67   68   69   70   71   72 
  73   74   75   76   77   78   79   80   81   82   83   84 
  85   86   87   88   89   90   91   92   93   94   95   96 
  97   98   99  100  101  102  103  104  105  106  107  108 
 109  110  111  112  113  114  115  116  117  118  119  120 
 121  122  123  124  125  126  127  128  129  130  131  132 
 133  134  135  136  137  138  139  140  141  142  143  144 
 145  146  147  148  149  150  151  152  153  154  155  156 
 157  158  159  160  161  162  163  164  165  166  167  168 
 169  170  171  172  173  174  175  176  177  178  179  180 
 181  182  183  184  185  186  187  188  189  190  191  192 
 193  194  195  196  197  198  199  200  201  202  203  204 
 205  206  207  208  209  210  211  212  213  214  215  216 
 217  218  219  220  221  222  223  224  225  226  227  228 
 229  230  231  232  233  234  235  236  237  238  239  240 
 241  242  243  244  245  246  247  248  249  250  251  252 
 253  254  255  256  257  258  259  260  261  262  263  264 
 265  266  267  268  269  270  271  272  273  274  275  276 
 277  278  279  280  281  282  283  284  285  286  287  288 
 289  290  291  292  293  294  295  296  297  298  299  300 
 301  302  303  304  305  306  307  308  309  310  311  312 
 313  314  315  316  317  318  319  320  321  322  323  324 
 325  326  327  328  329  330  331  332  333  334  335  336 
 337  338  339  340  341  342  343  344  345  346  347  348 
 349  350  351  352  353  354  355  356  357  358  359  360 
 361  362  363  364  365  366  367  368  369  370  371  372 
 373  374  375  376  377  378  379  380  381  382  383  384 
 385  386  387  388  389  390  391  392  393  394  395  396 
 397  398  399  400  401  402  403  404  405  406  407  408 
 409  410  411  412  413  414  415  416  417  418  419  420 
 421  422  423  424  425  426  427  428  429  430  431  432 
 433  434  435  436  437  438  439  440  441  442  443  444 
 445  446  447  448  449  450  451  452  453  454  455  456 
 457  458  459  460  461  462  463  464  465  466  467  468 
 469  470  471  472  473  474  475  476  477  478  479  480 
 481  482  483  484  485  486  487  488  489  490  491  492 
 493  494  495  496  497  498  499  500  501  502  503  504 
 505  506  507  508  509  510  511  512  513  514  515  516 
 517  518  519  520  521  522  523  524  525  526  527  528 
 529  530  531  532  533  534  535  536  537  538  539  540 
 541  542  543  544  545  546  547  548  549  550  551  552 
 553  554  555  556  557  558  559  560  561  562  563  564 
 565  566  567  568  569  570  571  572  573  574  575  576 
 577  578  579  580  581  582  583  584  585  586  587  588 
 589  590  591  592  593  594  595  596  597  598  599  600 
 601  602  603  604  605  606  607  608  609  610  611  612 
 613  614  615  616  617  618  619  620  621  622  623  624 
 625  626  627  628  629  630  631  632  633  634  635  636 
 637  638  639  640  641  642  643  644  645  646  647  648 
 649  650  651  652  653  654  655  656  657  658  659  660 
 661  662  663  664  665  666  667  668  669  670  671  672 
 673  674  675  676  677  678  679  680  681  682  683  684 
 685  686  687  688  689  690  691  692  693  694  695  696 
 697  698  699  700  701  702  703  704  705  706  707  708 
 709  710  711  712  713  714  715  716  717  718  719  720 
 721  722  723  724  725  726  727  728  729  730  731  732 
 733  734  735  736  737  738  739  740  741  742  743  744 
 745  746  747  748  749  750  751  752  753  754  755  756 
 757  758  759  760  761  762  763  764  765  766  767  768 
 769  770  771  772  773  774  775  776  777  778  779  780 
 781  782  783  784  785  786  787  788  789  790  791  792 
 793  794  795  796  797  798  799  800  801  802  803  804 
 805  806  807  808  809  810  811  812  813  814  815  816 
 817  818  819  820  821  822  823  824  825  826  827  828 
 829  830  831  832  833  834  835  836  837  838  839  840 
 841  842  843  844  845  846  847  848  849  850  851  852 
 853  854  855  856  857  858  859  860  861  862  863  864 
 865  866  867  868  869  870  871  872  873  874  875  876 
 877  878  879  880  881  882  883  884  885  886  887  888 
 889  890  891  892  893  894  895  896  897  898  899  900 
 901  902  903  904  905  906  907  908  909  910  911  912 
 913  914  915  916  917  918  919  920  921  922  923  924 
 925  926  927  928  929  930  931  932  933  934  935  936 
 937  938  939  940  941  942  943  944  945  946  947  948 
 949  950  951  952  953  954  955  956  957  958  959  960 
 961  962  963  964  965  966  967  968  969  970  971  972 
 973  974  975  976  977  978  979  980  981  982  983  984 
 985  986  987  988  989  990  991  992  993  994  995  996 
 997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 
1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 
1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 
1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 
1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 
1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 
1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 
1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 
1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 
1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 
1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 
1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 
1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 
1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 
1165 1166 1167 1168 1169 1170 1171 1172
out-degrees
   1    2    7    1    0    1    0    1    1    4    1    0 
   1    0    1    0    0    2    5    0    1    1    1    0 
   0    1    1    0    1    3    0    1    1    1    1    3 
   0    0    4    0    0    1    2    0    4    1    3    0 
   2    2    0    1    0    0    1    2    1    1    1    1 
   0    0    1    0    0    1    0    0    0    0    4    1 
   2    1    0    0    1    1    0    0    1    1    0    0 
   3    1    1    1    0    1    2    1    1    0    0    3 
   0    0    0    1    1    2    1    1    1    0    2    0 
   2    0    1    1    1    5    1    0    0    1    1    1 
   2    0    0    0    1    0    0    1    1    0    1    0 
   0    0    0    1    0    0    0    1    1    0    1    1 
   0    2    2    2    1    1    7    0    1    0    0    0 
   0    1    1    1    0    1    1    1    0    1    0    0 
   1    0    0    0    1    0    0    1    0    1    0    1 
   0    0    1    0    1    0    0    1    1    1    1    1 
   1    0    0    0    1    6    1    1    1    2    1    0 
   2    1    2    1    0    2    1    0    2    1    1    0 
   1    1    2    1    1    1    0    1    0    0    0    1 
   1    1    2    1    1    1    1    1    1    0    1    3 
   0    0    0    1    0    1    1    0    0    0    1    0 
   1    0    0    1    0    1    1    1    1    1    1    0 
   0    2    1    0    1    1    0    1    0    1    0    0 
   0    1    0    0    2    1    0    0    1    1    1    0 
   1    1    1    1    1    1    0    1    1    1    0    0 
   0    1    0    1    1    1    0    0    1    0    1    1 
   0    2    0    1    2    1    1    1    1    1    0    0 
   0    0    1    1    1    1    1    0    1    0    0    1 
   1    0    0    0    1    0    0    1    1    1    0    0 
   0    1    1    2    2    1    0    0    0    1    0    0 
   1    0    1    0    0    1    1    1    1    1    1    0 
   0    1    1    0    1    1    1    1    1    1    0    1 
   1    0    0    1    0    1    1    1    0    0    0    0 
   1    0    2    1    0    1    0    1    0    1    1    1 
   0    1    2    3    0    0    0    0    1    3    2    2 
   1    2    1    0    0    1    1    1    0    1    0    0 
   1    1    0    0    4    1    2    0    0    1    0    0 
   0    1    2    1    0    0    0    1    0    1    0    0 
   0    0    0    0    1    0    1    0    0    1    0    1 
   1    0    0    1    1    0    1    1    0    0    1    1 
   0    0    0    0    0    1    1    0    0    0    1    0 
   0    3    0    0    0    0    1    1    0    0    1    1 
   1    1    1    0    1    0    0    1    1    0    0    0 
   1    1    0    0    1    0    0    2    0    1    1    0 
   1    0    2    1    1    1    1    0    2    1    0    0 
   4    3    0    1    2    1    1    0    1    1    1    1 
   0    0    0    2    0    1    0    1    1    1    0    1 
   1    3    2    1    0    2    1    1    2    0    0    2 
   0    1    0    1    1    0    0    1    0    1    1    0 
   1    0    1    0    0    0    1    1    0    2    0    1 
   1    2    0    1    0    0    0    0    1    0    1    0 
   0    0    0    1    2    1    1    2    1    1    1    0 
   1    1    1    0    0    1    0    1    1    0    1    1 
   0    3    1    1    0    1    1    1    1    0    0    0 
   0    3    3    2    1    0    1    0    1    0    0    0 
   0    0    0    1    0    2    1    1    1    1    0    0 
   0    0    1    1    0    0    1    1    0    0    0    0 
   0    1    0    0    0    0    1    0    1    0    0    1 
   1    1    1    1    1    1    1    1    1    0    1    1 
   1    1    1    0    0    1    0    0    1    1    0    1 
   0    2    1    0    0    0    0    1    1    0    0    1 
   1    0    0    1    0    1    1    0    0    1    1    0 
   1    1    0    1    0    0    1    0    0    1    0    0 
   1    0    0    0    1    0    0    0    1    1    1    1 
   0    0    0    1    0    1    1    0    0    1    1    0 
   0    1    1    1    1    0    1    1    0    0    0    1 
   0    0    1    0    1    0    2    1    0    1    1    1 
   1    1    1    1    0    1    0    0    0    1    0    0 
   0    0    1    0    1    0    2    1    1    1    0    0 
   1    1    1    1    1    1    0    1    3    0    0    0 
   0    0    0    1    1    0    1    1    1    0    0    1 
   0    0    0    1    0    0    1    0    2    2    0    1 
   0    1    1    1    1    1    1    0    1    1    1    0 
   1    0    0    0    0    1    1    1    1    0    0    1 
   0    1    1    1    0    0    1    0    0    0    0    0 
   1    1    1    1    0    0    1    1    0    0    1    1 
   1    0    1    1    1    0    0    1    1    1    0    0 
   1    0    0    0    1    0    0    1    0    1    0    1 
   0    1    0    0    0    0    1    0    1    0    1    0 
   0    1    1    0    0    0    0    0    2    1    1    1 
   1    0    0    1    0    0    0    0    0    1    0    0 
   0    1    0    1    1    1    1    1    0    0    0    0 
   0    0    0    0    0    0    0    1    0    0    0    1 
   1    1    1    1    0    0    0    1    1    1    0    1 
   1    0    0    1    0    0    1    0    0    0    1    0 
   0    1    1    1    1    0    1    1    1    1    0    0 
   1    0    0    2    1    2    1    0    0    1    0    1 
   1    0    0    0    0    1    0    0    0    0    0    0 
   0    0    0    0    1    0    0    0    1    1    1    1 
   1    1    0    2    1    1    0    1    0    1    0    0 
   1    1    0    0    1    0    0    1    1    1    0    1 
   1    1    1    1    0    1    1    1    1    1    1    1 
   0    0    1    0    0    0    0    0    0    1    0    0 
   1    0    0    1    0    0    1    0    1    0    0    0 
   1    0    1    0    1    1    0    1    0    0    0    1 
   0    0    1    0    0    0    0    0    1    0    1    0 
   0    0    1    0    1    1    1    0    0    1    0    0 
   1    1    0    1    0    0    1    1
in-degrees
  3   4   1   1   0   0   0   5   3   0   1   2   6   0   1 
  1   1  11   2   0   5   0   1   0   1   0   2   1   1   4 
  7   0   2   4   1   1   0   1   1   2   5   0   0   2   4 
  1   3   4   1   4   7   0   0   1  38   2   0   3   3   5 
  4   2   1  39   0   2   2   0   1   1   1   9   4   2   2 
  2   8   0   2   0   0   7   7   1   0   8   0   1   4   1 
  2   1   6   0   4   1   2   0   5   1   5   6   3   1   0 
 28   3   3   5   1   1   9   1   2   0   0   0   3   6   1 
  1   1   2   0   3   2   0   2   1   0   0   0   2   2   1 
  1   6   1   1   0   2   2  58   1   1   0   3   0   0   5 
  3   1   0   0   0   0   2   2   2   1   1   2   1   0   3 
  4   1   2   3   2   3   0   1   0   2   2   7   2   1   4 
  3   0   2   2   3   6   1   0   2   2   1   1   1   8   3 
  3   2   0  21  10   5   3   0   1   0  43   1   2   2   0 
  0  15   0   1   2   0  10   0   0   1   1   2  11   0   3 
  1   4   0   8   7  11   0   1   1   1   0   0   2   0   3 
  1   2   0   2   7   7   1   4   1   0

For observation moment 1, number of missing values are:
Senders
   1    2    3    4    5    6    7    8    9   10   11   12 
  13   14   15   16   17   18   19   20   21   22   23   24 
  25   26   27   28   29   30   31   32   33   34   35   36 
  37   38   39   40   41   42   43   44   45   46   47   48 
  49   50   51   52   53   54   55   56   57   58   59   60 
  61   62   63   64   65   66   67   68   69   70   71   72 
  73   74   75   76   77   78   79   80   81   82   83   84 
  85   86   87   88   89   90   91   92   93   94   95   96 
  97   98   99  100  101  102  103  104  105  106  107  108 
 109  110  111  112  113  114  115  116  117  118  119  120 
 121  122  123  124  125  126  127  128  129  130  131  132 
 133  134  135  136  137  138  139  140  141  142  143  144 
 145  146  147  148  149  150  151  152  153  154  155  156 
 157  158  159  160  161  162  163  164  165  166  167  168 
 169  170  171  172  173  174  175  176  177  178  179  180 
 181  182  183  184  185  186  187  188  189  190  191  192 
 193  194  195  196  197  198  199  200  201  202  203  204 
 205  206  207  208  209  210  211  212  213  214  215  216 
 217  218  219  220  221  222  223  224  225  226  227  228 
 229  230  231  232  233  234  235  236  237  238  239  240 
 241  242  243  244  245  246  247  248  249  250  251  252 
 253  254  255  256  257  258  259  260  261  262  263  264 
 265  266  267  268  269  270  271  272  273  274  275  276 
 277  278  279  280  281  282  283  284  285  286  287  288 
 289  290  291  292  293  294  295  296  297  298  299  300 
 301  302  303  304  305  306  307  308  309  310  311  312 
 313  314  315  316  317  318  319  320  321  322  323  324 
 325  326  327  328  329  330  331  332  333  334  335  336 
 337  338  339  340  341  342  343  344  345  346  347  348 
 349  350  351  352  353  354  355  356  357  358  359  360 
 361  362  363  364  365  366  367  368  369  370  371  372 
 373  374  375  376  377  378  379  380  381  382  383  384 
 385  386  387  388  389  390  391  392  393  394  395  396 
 397  398  399  400  401  402  403  404  405  406  407  408 
 409  410  411  412  413  414  415  416  417  418  419  420 
 421  422  423  424  425  426  427  428  429  430  431  432 
 433  434  435  436  437  438  439  440  441  442  443  444 
 445  446  447  448  449  450  451  452  453  454  455  456 
 457  458  459  460  461  462  463  464  465  466  467  468 
 469  470  471  472  473  474  475  476  477  478  479  480 
 481  482  483  484  485  486  487  488  489  490  491  492 
 493  494  495  496  497  498  499  500  501  502  503  504 
 505  506  507  508  509  510  511  512  513  514  515  516 
 517  518  519  520  521  522  523  524  525  526  527  528 
 529  530  531  532  533  534  535  536  537  538  539  540 
 541  542  543  544  545  546  547  548  549  550  551  552 
 553  554  555  556  557  558  559  560  561  562  563  564 
 565  566  567  568  569  570  571  572  573  574  575  576 
 577  578  579  580  581  582  583  584  585  586  587  588 
 589  590  591  592  593  594  595  596  597  598  599  600 
 601  602  603  604  605  606  607  608  609  610  611  612 
 613  614  615  616  617  618  619  620  621  622  623  624 
 625  626  627  628  629  630  631  632  633  634  635  636 
 637  638  639  640  641  642  643  644  645  646  647  648 
 649  650  651  652  653  654  655  656  657  658  659  660 
 661  662  663  664  665  666  667  668  669  670  671  672 
 673  674  675  676  677  678  679  680  681  682  683  684 
 685  686  687  688  689  690  691  692  693  694  695  696 
 697  698  699  700  701  702  703  704  705  706  707  708 
 709  710  711  712  713  714  715  716  717  718  719  720 
 721  722  723  724  725  726  727  728  729  730  731  732 
 733  734  735  736  737  738  739  740  741  742  743  744 
 745  746  747  748  749  750  751  752  753  754  755  756 
 757  758  759  760  761  762  763  764  765  766  767  768 
 769  770  771  772  773  774  775  776  777  778  779  780 
 781  782  783  784  785  786  787  788  789  790  791  792 
 793  794  795  796  797  798  799  800  801  802  803  804 
 805  806  807  808  809  810  811  812  813  814  815  816 
 817  818  819  820  821  822  823  824  825  826  827  828 
 829  830  831  832  833  834  835  836  837  838  839  840 
 841  842  843  844  845  846  847  848  849  850  851  852 
 853  854  855  856  857  858  859  860  861  862  863  864 
 865  866  867  868  869  870  871  872  873  874  875  876 
 877  878  879  880  881  882  883  884  885  886  887  888 
 889  890  891  892  893  894  895  896  897  898  899  900 
 901  902  903  904  905  906  907  908  909  910  911  912 
 913  914  915  916  917  918  919  920  921  922  923  924 
 925  926  927  928  929  930  931  932  933  934  935  936 
 937  938  939  940  941  942  943  944  945  946  947  948 
 949  950  951  952  953  954  955  956  957  958  959  960 
 961  962  963  964  965  966  967  968  969  970  971  972 
 973  974  975  976  977  978  979  980  981  982  983  984 
 985  986  987  988  989  990  991  992  993  994  995  996 
 997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 
1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 
1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 
1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 
1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 
1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 
1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 
1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 
1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 
1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 
1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 
1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 
1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 
1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 
1165 1166 1167 1168 1169 1170 1171 1172
missing in rows
   0    0    0    0  250    0  250    0    0    0    0  250 
   0  250    0  250  250    0    0  250    0    0    0  250 
 250    0    0  250    0    0  250    0    0    0    0    0 
 250  250    0  250  250    0    0  250    0    0    0  250 
   0    0  250    0  250  250    0    0    0    0    0    0 
 250  250    0  250  250    0  250  250  250  250    0    0 
   0    0  250  250    0    0  250  250    0    0  250  250 
   0    0    0    0  250    0    0    0    0  250  250    0 
 250  250  250    0    0    0    0    0    0  250    0  250 
   0  250    0    0    0    0    0  250  250    0    0    0 
   0  250  250  250    0  250  250    0    0  250    0  250 
 250  250  250    0  250  250  250    0    0  250    0    0 
 250    0    0    0    0    0    0  250    0  250  250  250 
 250    0    0    0  250    0    0    0  250    0  250  250 
   0  250  250  250    0  250  250    0  250    0  250    0 
 250  250    0  250    0  250  250    0    0    0    0    0 
   0  250  250  250    0    0    0    0    0    0    0  250 
   0    0    0    0  250    0    0  250    0    0    0  250 
   0    0    0    0    0    0  250    0  250  250  250    0 
   0    0    0    0    0    0    0    0    0  250    0    0 
 250  250  250    0  250    0    0  250  250  250    0  250 
   0  250  250    0  250    0    0    0    0    0    0  250 
 250    0    0  250    0    0  250    0  250    0  250  250 
 250    0  250  250    0    0  250  250    0    0    0  250 
   0    0    0    0    0    0  250    0    0    0  250  250 
 250    0  250    0    0    0  250  250    0  250    0    0 
 250    0  250    0    0    0    0    0    0    0  250  250 
 250  250    0    0    0    0    0  250    0  250  250    0 
   0  250  250  250    0  250  250    0    0    0  250  250 
 250    0    0    0    0    0  250  250  250    0  250  250 
   0  250    0  250  250    0    0    0    0    0    0  250 
 250    0    0  250    0    0    0    0    0    0  250    0 
   0  250  250    0  250    0    0    0  250  250  250  250 
   0  250    0    0  250    0  250    0  250    0    0    0 
 250    0    0    0  250  250  250  250    0    0    0    0 
   0    0    0  250  250    0    0    0  250    0  250  250 
   0    0  250  250    0    0    0  250  250    0  250  250 
 250    0    0    0  250  250  250    0  250    0  250  250 
 250  250  250  250    0  250    0  250  250    0  250    0 
   0  250  250    0    0  250    0    0  250  250    0    0 
 250  250  250  250  250    0    0  250  250  250    0  250 
 250    0  250  250  250  250    0    0  250  250    0    0 
   0    0    0  250    0  250  250    0    0  250  250  250 
   0    0  250  250    0  250  250    0  250    0    0  250 
   0  250    0    0    0    0    0  250    0    0  250  250 
   0    0  250    0    0    0    0  250    0    0    0    0 
 250  250  250    0  250    0  250    0    0    0  250    0 
   0    0    0    0  250    0    0    0    0  250  250    0 
 250    0  250    0    0  250  250    0  250    0    0  250 
   0  250    0  250  250  250    0    0  250    0  250    0 
   0    0  250    0  250  250  250  250    0  250    0  250 
 250  250  250    0    0    0    0    0    0    0    0  250 
   0    0    0  250  250    0  250    0    0  250    0    0 
 250    0    0    0  250    0    0    0    0  250  250  250 
 250    0    0    0    0  250    0  250    0  250  250  250 
 250  250  250    0  250    0    0    0    0    0  250  250 
 250  250    0    0  250  250    0    0  250  250  250  250 
 250    0  250  250  250  250    0  250    0  250  250    0 
   0    0    0    0    0    0    0    0    0  250    0    0 
   0    0    0  250  250    0  250  250    0    0  250    0 
 250    0    0  250  250  250  250    0    0  250  250    0 
   0  250  250    0  250    0    0  250  250    0    0  250 
   0    0  250    0  250  250    0  250  250    0  250  250 
   0  250  250  250    0  250  250  250    0    0    0    0 
 250  250  250    0  250    0    0  250  250    0    0  250 
 250    0    0    0    0  250    0    0  250  250  250    0 
 250  250    0  250    0  250    0    0  250    0    0    0 
   0    0    0    0  250    0  250  250  250    0  250  250 
 250  250    0  250    0  250    0    0    0    0  250  250 
   0    0    0    0    0    0  250    0    0  250  250  250 
 250  250  250    0    0  250    0    0    0  250  250    0 
 250  250  250    0  250  250    0  250    0    0  250    0 
 250    0    0    0    0    0    0  250    0    0    0  250 
   0  250  250  250  250    0    0    0    0  250  250    0 
 250    0    0    0  250  250    0  250  250  250  250  250 
   0    0    0    0  250  250    0    0  250  250    0    0 
   0  250    0    0    0  250  250    0    0    0  250  250 
   0  250  250  250    0  250  250    0  250    0  250    0 
 250    0  250  250  250  250    0  250    0  250    0  250 
 250    0    0  250  250  250  250  250    0    0    0    0 
   0  250  250    0  250  250  250  250  250    0  250  250 
 250    0  250    0    0    0    0    0  250  250  250  250 
 250  250  250  250  250  250  250    0  250  250  250    0 
   0    0    0    0  250  250  250    0    0    0  250    0 
   0  250  250    0  250  250    0  250  250  250    0  250 
 250    0    0    0    0  250    0    0    0    0  250  250 
   0  250  250    0    0    0    0  250  250    0  250    0 
   0  250  250  250  250    0  250  250  250  250  250  250 
 250  250  250  250    0  250  250  250    0    0    0    0 
   0    0  250    0    0    0  250    0  250    0  250  250 
   0    0  250  250    0  250  250    0    0    0  250    0 
   0    0    0    0  250    0    0    0    0    0    0    0 
 250  250    0  250  250  250  250  250  250    0  250  250 
   0  250  250    0  250  250    0  250    0  250  250  250 
   0  250    0  250    0    0  250    0  250  250  250    0 
 250  250    0  250  250  250  250  250    0  250    0  250 
 250  250    0  250    0    0    0  250  250    0  250  250 
   0    0  250    0  250  250    0    0
Receivers
  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15 
 16  17  18  19  20  21  22  23  24  25  26  27  28  29  30 
 31  32  33  34  35  36  37  38  39  40  41  42  43  44  45 
 46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 
 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75 
 76  77  78  79  80  81  82  83  84  85  86  87  88  89  90 
 91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 
106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 
121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 
136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 
151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 
166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 
181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 
196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 
211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 
226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 
241 242 243 244 245 246 247 248 249 250
missing in columns
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546 546 546 546 546 546 
546 546 546 546 546 546 546 546 546 546
Total number of missing data: 136500, corresponding to a fraction of 0.466.

For observation moment 2, degree distributions are as follows:
Nodes
   1    2    3    4    5    6    7    8    9   10   11   12 
  13   14   15   16   17   18   19   20   21   22   23   24 
  25   26   27   28   29   30   31   32   33   34   35   36 
  37   38   39   40   41   42   43   44   45   46   47   48 
  49   50   51   52   53   54   55   56   57   58   59   60 
  61   62   63   64   65   66   67   68   69   70   71   72 
  73   74   75   76   77   78   79   80   81   82   83   84 
  85   86   87   88   89   90   91   92   93   94   95   96 
  97   98   99  100  101  102  103  104  105  106  107  108 
 109  110  111  112  113  114  115  116  117  118  119  120 
 121  122  123  124  125  126  127  128  129  130  131  132 
 133  134  135  136  137  138  139  140  141  142  143  144 
 145  146  147  148  149  150  151  152  153  154  155  156 
 157  158  159  160  161  162  163  164  165  166  167  168 
 169  170  171  172  173  174  175  176  177  178  179  180 
 181  182  183  184  185  186  187  188  189  190  191  192 
 193  194  195  196  197  198  199  200  201  202  203  204 
 205  206  207  208  209  210  211  212  213  214  215  216 
 217  218  219  220  221  222  223  224  225  226  227  228 
 229  230  231  232  233  234  235  236  237  238  239  240 
 241  242  243  244  245  246  247  248  249  250  251  252 
 253  254  255  256  257  258  259  260  261  262  263  264 
 265  266  267  268  269  270  271  272  273  274  275  276 
 277  278  279  280  281  282  283  284  285  286  287  288 
 289  290  291  292  293  294  295  296  297  298  299  300 
 301  302  303  304  305  306  307  308  309  310  311  312 
 313  314  315  316  317  318  319  320  321  322  323  324 
 325  326  327  328  329  330  331  332  333  334  335  336 
 337  338  339  340  341  342  343  344  345  346  347  348 
 349  350  351  352  353  354  355  356  357  358  359  360 
 361  362  363  364  365  366  367  368  369  370  371  372 
 373  374  375  376  377  378  379  380  381  382  383  384 
 385  386  387  388  389  390  391  392  393  394  395  396 
 397  398  399  400  401  402  403  404  405  406  407  408 
 409  410  411  412  413  414  415  416  417  418  419  420 
 421  422  423  424  425  426  427  428  429  430  431  432 
 433  434  435  436  437  438  439  440  441  442  443  444 
 445  446  447  448  449  450  451  452  453  454  455  456 
 457  458  459  460  461  462  463  464  465  466  467  468 
 469  470  471  472  473  474  475  476  477  478  479  480 
 481  482  483  484  485  486  487  488  489  490  491  492 
 493  494  495  496  497  498  499  500  501  502  503  504 
 505  506  507  508  509  510  511  512  513  514  515  516 
 517  518  519  520  521  522  523  524  525  526  527  528 
 529  530  531  532  533  534  535  536  537  538  539  540 
 541  542  543  544  545  546  547  548  549  550  551  552 
 553  554  555  556  557  558  559  560  561  562  563  564 
 565  566  567  568  569  570  571  572  573  574  575  576 
 577  578  579  580  581  582  583  584  585  586  587  588 
 589  590  591  592  593  594  595  596  597  598  599  600 
 601  602  603  604  605  606  607  608  609  610  611  612 
 613  614  615  616  617  618  619  620  621  622  623  624 
 625  626  627  628  629  630  631  632  633  634  635  636 
 637  638  639  640  641  642  643  644  645  646  647  648 
 649  650  651  652  653  654  655  656  657  658  659  660 
 661  662  663  664  665  666  667  668  669  670  671  672 
 673  674  675  676  677  678  679  680  681  682  683  684 
 685  686  687  688  689  690  691  692  693  694  695  696 
 697  698  699  700  701  702  703  704  705  706  707  708 
 709  710  711  712  713  714  715  716  717  718  719  720 
 721  722  723  724  725  726  727  728  729  730  731  732 
 733  734  735  736  737  738  739  740  741  742  743  744 
 745  746  747  748  749  750  751  752  753  754  755  756 
 757  758  759  760  761  762  763  764  765  766  767  768 
 769  770  771  772  773  774  775  776  777  778  779  780 
 781  782  783  784  785  786  787  788  789  790  791  792 
 793  794  795  796  797  798  799  800  801  802  803  804 
 805  806  807  808  809  810  811  812  813  814  815  816 
 817  818  819  820  821  822  823  824  825  826  827  828 
 829  830  831  832  833  834  835  836  837  838  839  840 
 841  842  843  844  845  846  847  848  849  850  851  852 
 853  854  855  856  857  858  859  860  861  862  863  864 
 865  866  867  868  869  870  871  872  873  874  875  876 
 877  878  879  880  881  882  883  884  885  886  887  888 
 889  890  891  892  893  894  895  896  897  898  899  900 
 901  902  903  904  905  906  907  908  909  910  911  912 
 913  914  915  916  917  918  919  920  921  922  923  924 
 925  926  927  928  929  930  931  932  933  934  935  936 
 937  938  939  940  941  942  943  944  945  946  947  948 
 949  950  951  952  953  954  955  956  957  958  959  960 
 961  962  963  964  965  966  967  968  969  970  971  972 
 973  974  975  976  977  978  979  980  981  982  983  984 
 985  986  987  988  989  990  991  992  993  994  995  996 
 997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 
1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 
1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 
1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 
1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 
1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 
1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 
1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 
1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 
1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 
1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 
1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 
1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 
1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 
1165 1166 1167 1168 1169 1170 1171 1172
out-degrees
   2    0    5    0    1    0    0    3    1    4    0    3 
   1    0    0    1    1    0    3    1    1    1    2    0 
   0    1    1    0    0    2    0    1    0    0    2    3 
   1    1    5    1    0    1    2    0    4    1    2    2 
   4    2    0    0    0    0    2    0    1    1    2    0 
   0    2    1    0    1    1    1    0    1    1    4    0 
   0    1    1    1    1    1    1    0    1    0    1    1 
   1    2    0    2    1    2    1    1    1    2    1    1 
   1    1    0    1    0    1    2    0    1    1    1    1 
   1    1    0    0    0    0    1    0    0    0    0    0 
   2    1    0    0    0    0    0    0    0    0    1    0 
   0    0    0    1    0    0    1    0    1    1    0    0 
   0    0    0    1    2    1    7    2    1    1    0    0 
   0    1    1    1    0    1    3    0    1    1    1    0 
   1    0    0    2    1    0    0    1    0    1    0    1 
   1    0    1    0    1    1    0    1    0    0    0    1 
   1    0    0    0    1    4    2    2    1    0    0    0 
   0    1    1    1    0    1    0    1    2    1    1    1 
   3    1    0    1    1    1    0    3    0    1    1    1 
   1    0    1    0    0    1    1    1    1    0    1    2 
   0    0    0    0    0    1    1    0    1    1    1    0 
   0    0    0    1    1    0    0    1    0    1    2    0 
   0    0    1    1    1    2    3    0    1    0    1    1 
   0    0    1    2    2    0    1    1    1    1    1    1 
   0    0    0    1    1    0    1    0    2    0    2    0 
   0    1    1    0    2    0    0    0    0    0    1    1 
   1    2    1    1    1    1    0    1    2    1    0    1 
   2    1    1    1    1    1    1    0    1    1    0    1 
   0    0    0    1    1    0    0    0    0    1    1    0 
   0    0    0    1    0    0    0    0    1    0    1    0 
   1    1    0    0    0    0    1    0    1    0    0    0 
   1    1    0    0    0    0    0    0    0    0    1    0 
   0    1    1    0    1    1    0    0    1    0    0    1 
   1    0    1    1    1    1    1    1    0    0    1    0 
   0    0    2    3    1    1    1    2    0    2    2    2 
   1    1    1    0    1    1    1    0    1    0    1    0 
   1    1    0    0    1    1    2    1    1    0    0    0 
   0    0    0    2    1    0    0    1    1    1    0    0 
   0    0    0    1    0    0    0    1    1    0    0    0 
   2    3    1    1    1    0    0    0    1    0    1    1 
   1    1    1    0    1    0    0    0    0    1    0    1 
   1    1    0    1    1    2    1    1    0    1    1    0 
   0    1    1    1    1    0    1    0    0    2    0    0 
   2    1    0    1    1    0    2    1    0    0    1    1 
   1    2    2    1    0    0    1    1    0    1    1    1 
   2    2    0    0    1    1    1    1    1    1    1    1 
   0    0    0    2    1    1    2    2    1    1    1    0 
   0    3    2    1    2    0    1    1    2    0    1    1 
   0    0    0    1    1    0    0    1    0    1    1    0 
   0    1    2    0    1    0    1    1    1    1    1    0 
   1    0    0    0    1    1    0    0    1    1    1    0 
   1    0    0    0    1    0    1    1    1    1    1    1 
   1    1    2    0    2    2    1    0    0    0    1    1 
   1    3    1    0    0    0    1    0    1    0    0    1 
   0    3    3    1    1    0    1    1    0    0    0    0 
   0    0    0    1    1    1    1    1    0    1    1    1 
   1    1    1    0    0    1    1    0    1    1    0    1 
   1    1    1    0    1    1    1    1    1    0    0    0 
   1    1    1    2    1    1    1    1    1    0    1    1 
   1    0    1    0    0    1    1    0    1    0    0    0 
   0    0    0    0    1    0    0    1    1    0    0    0 
   1    1    1    1    0    1    1    1    1    1    1    1 
   0    0    0    0    0    0    1    0    1    1    1    0 
   0    1    1    0    1    1    0    1    1    1    1    1 
   1    1    0    1    0    0    0    1    1    0    1    1 
   1    1    1    1    1    1    1    0    1    0    0    1 
   0    1    1    1    1    1    0    0    1    1    1    0 
   1    1    0    1    1    1    0    1    1    2    1    0 
   0    0    1    0    0    2    2    1    1    1    0    0 
   1    0    1    1    1    0    1    1    2    0    0    1 
   0    1    0    1    1    0    1    0    1    1    1    1 
   1    0    1    1    0    1    1    1    2    1    1    0 
   0    1    1    1    0    1    1    1    1    1    0    0 
   1    1    1    1    0    1    0    0    0    1    1    1 
   0    0    1    1    0    0    1    0    0    0    0    1 
   1    1    1    1    0    1    1    1    0    1    1    0 
   1    0    1    1    1    0    0    1    1    1    1    0 
   1    0    1    1    1    0    0    0    1    1    0    1 
   0    0    1    1    0    0    1    0    1    0    1    1 
   0    1    0    1    1    0    1    1    1    1    0    0 
   1    0    1    0    0    0    1    0    1    1    1    1 
   0    1    0    1    1    1    1    0    0    1    1    0 
   0    1    1    1    1    1    0    0    1    0    1    1 
   1    0    1    0    1    1    1    0    1    0    1    1 
   0    0    0    1    0    0    1    0    1    0    1    1 
   1    1    1    0    0    1    1    0    1    1    0    0 
   0    0    0    2    2    2    2    0    1    0    1    1 
   1    0    1    1    1    1    0    1    0    0    0    1 
   0    1    0    2    0    1    1    1    1    1    1    1 
   0    0    0    2    1    1    1    1    0    0    1    0 
   0    0    0    1    1    0    0    0    0    1    1    0 
   0    0    1    0    1    1    1    1    1    0    1    1 
   0    1    1    0    0    0    0    0    0    0    0    0 
   0    0    0    1    0    1    0    0    1    1    0    1 
   0    1    1    0    0    1    0    1    1    0    0    0 
   0    0    1    0    1    0    1    0    1    1    1    0 
   1    0    1    1    0    1    0    0    0    0    1    0 
   0    0    0    0    1    1    1    1
in-degrees
  3   3   2   2   0   2   0   3   1   6   1   4   7   1   1 
  3   0  17   2   2   3   1   2   0   0   0   0   2   0   1 
  4   2   3   5   2   2   0   2   2   3   3   0   0   4   1 
  0   1   3   1   5   8   0   0   0  35   2   0   2   3   4 
  3   2   3  27   1   2   3   0   0   2   1   9   3   4   2 
  1   5   1   2   1   0   8  11   3   1   8   2   2   3   1 
  4   1   3   2   2   0   3   0   5   3   6   6   3   0   0 
 32   4   0   6   1   1   8   1   0   0   0   1   2   4   1 
  1   1   0   0   2   0   1   5   0   0   0   1   4   1   3 
  1   6   0   2   0   3   1  65   1   0   2   2   0   0   8 
  0   2   1   0   0   0   3   0   2   3   1   2   4   0   2 
  7   2   1   2   2   4   0   1   0   0   4   6   2   2   2 
  3   0   1   7   3   7   3   0   2   2   1   0   2  10   3 
  2   3   1  26  15   4   1   0   2   2  52   0   1   0   0 
  0  23   0   1   1   0   9   0   0   2   1   1   6   1   0 
  0   4   0   6   4  10   0   0   1   2   1   1   0   0   6 
  2   2   1   4  10   8   2   2   2   0

For observation moment 2, number of missing values are:
Senders
   1    2    3    4    5    6    7    8    9   10   11   12 
  13   14   15   16   17   18   19   20   21   22   23   24 
  25   26   27   28   29   30   31   32   33   34   35   36 
  37   38   39   40   41   42   43   44   45   46   47   48 
  49   50   51   52   53   54   55   56   57   58   59   60 
  61   62   63   64   65   66   67   68   69   70   71   72 
  73   74   75   76   77   78   79   80   81   82   83   84 
  85   86   87   88   89   90   91   92   93   94   95   96 
  97   98   99  100  101  102  103  104  105  106  107  108 
 109  110  111  112  113  114  115  116  117  118  119  120 
 121  122  123  124  125  126  127  128  129  130  131  132 
 133  134  135  136  137  138  139  140  141  142  143  144 
 145  146  147  148  149  150  151  152  153  154  155  156 
 157  158  159  160  161  162  163  164  165  166  167  168 
 169  170  171  172  173  174  175  176  177  178  179  180 
 181  182  183  184  185  186  187  188  189  190  191  192 
 193  194  195  196  197  198  199  200  201  202  203  204 
 205  206  207  208  209  210  211  212  213  214  215  216 
 217  218  219  220  221  222  223  224  225  226  227  228 
 229  230  231  232  233  234  235  236  237  238  239  240 
 241  242  243  244  245  246  247  248  249  250  251  252 
 253  254  255  256  257  258  259  260  261  262  263  264 
 265  266  267  268  269  270  271  272  273  274  275  276 
 277  278  279  280  281  282  283  284  285  286  287  288 
 289  290  291  292  293  294  295  296  297  298  299  300 
 301  302  303  304  305  306  307  308  309  310  311  312 
 313  314  315  316  317  318  319  320  321  322  323  324 
 325  326  327  328  329  330  331  332  333  334  335  336 
 337  338  339  340  341  342  343  344  345  346  347  348 
 349  350  351  352  353  354  355  356  357  358  359  360 
 361  362  363  364  365  366  367  368  369  370  371  372 
 373  374  375  376  377  378  379  380  381  382  383  384 
 385  386  387  388  389  390  391  392  393  394  395  396 
 397  398  399  400  401  402  403  404  405  406  407  408 
 409  410  411  412  413  414  415  416  417  418  419  420 
 421  422  423  424  425  426  427  428  429  430  431  432 
 433  434  435  436  437  438  439  440  441  442  443  444 
 445  446  447  448  449  450  451  452  453  454  455  456 
 457  458  459  460  461  462  463  464  465  466  467  468 
 469  470  471  472  473  474  475  476  477  478  479  480 
 481  482  483  484  485  486  487  488  489  490  491  492 
 493  494  495  496  497  498  499  500  501  502  503  504 
 505  506  507  508  509  510  511  512  513  514  515  516 
 517  518  519  520  521  522  523  524  525  526  527  528 
 529  530  531  532  533  534  535  536  537  538  539  540 
 541  542  543  544  545  546  547  548  549  550  551  552 
 553  554  555  556  557  558  559  560  561  562  563  564 
 565  566  567  568  569  570  571  572  573  574  575  576 
 577  578  579  580  581  582  583  584  585  586  587  588 
 589  590  591  592  593  594  595  596  597  598  599  600 
 601  602  603  604  605  606  607  608  609  610  611  612 
 613  614  615  616  617  618  619  620  621  622  623  624 
 625  626  627  628  629  630  631  632  633  634  635  636 
 637  638  639  640  641  642  643  644  645  646  647  648 
 649  650  651  652  653  654  655  656  657  658  659  660 
 661  662  663  664  665  666  667  668  669  670  671  672 
 673  674  675  676  677  678  679  680  681  682  683  684 
 685  686  687  688  689  690  691  692  693  694  695  696 
 697  698  699  700  701  702  703  704  705  706  707  708 
 709  710  711  712  713  714  715  716  717  718  719  720 
 721  722  723  724  725  726  727  728  729  730  731  732 
 733  734  735  736  737  738  739  740  741  742  743  744 
 745  746  747  748  749  750  751  752  753  754  755  756 
 757  758  759  760  761  762  763  764  765  766  767  768 
 769  770  771  772  773  774  775  776  777  778  779  780 
 781  782  783  784  785  786  787  788  789  790  791  792 
 793  794  795  796  797  798  799  800  801  802  803  804 
 805  806  807  808  809  810  811  812  813  814  815  816 
 817  818  819  820  821  822  823  824  825  826  827  828 
 829  830  831  832  833  834  835  836  837  838  839  840 
 841  842  843  844  845  846  847  848  849  850  851  852 
 853  854  855  856  857  858  859  860  861  862  863  864 
 865  866  867  868  869  870  871  872  873  874  875  876 
 877  878  879  880  881  882  883  884  885  886  887  888 
 889  890  891  892  893  894  895  896  897  898  899  900 
 901  902  903  904  905  906  907  908  909  910  911  912 
 913  914  915  916  917  918  919  920  921  922  923  924 
 925  926  927  928  929  930  931  932  933  934  935  936 
 937  938  939  940  941  942  943  944  945  946  947  948 
 949  950  951  952  953  954  955  956  957  958  959  960 
 961  962  963  964  965  966  967  968  969  970  971  972 
 973  974  975  976  977  978  979  980  981  982  983  984 
 985  986  987  988  989  990  991  992  993  994  995  996 
 997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 
1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 
1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 
1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 
1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 
1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 
1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 
1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 
1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 
1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 
1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 
1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 
1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 
1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 
1165 1166 1167 1168 1169 1170 1171 1172
missing in rows
   0    0    0    0    0    0  250    0    0    0    0    0 
   0  250    0    0    0    0    0    0    0    0    0  250 
 250    0    0  250    0    0  250    0    0    0    0    0 
   0    0    0    0  250    0    0  250    0    0    0    0 
   0    0  250    0  250  250    0    0    0    0    0    0 
 250    0    0  250    0    0    0  250    0    0    0    0 
   0    0    0    0    0    0    0  250    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0  250    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0  250  250    0    0    0 
   0    0  250  250    0  250  250    0    0  250    0  250 
 250  250  250    0  250  250    0    0    0    0    0    0 
 250    0    0    0    0    0    0    0    0    0  250  250 
 250    0    0    0  250    0    0    0    0    0    0  250 
   0  250  250    0    0  250  250    0  250    0  250    0 
   0  250    0  250    0    0  250    0    0    0    0    0 
   0  250  250  250    0    0    0    0    0    0    0  250 
   0    0    0    0  250    0    0    0    0    0    0    0 
   0    0    0    0    0    0  250    0  250    0    0    0 
   0    0    0    0    0    0    0    0    0  250    0    0 
 250  250  250    0  250    0    0  250    0    0    0  250 
   0  250  250    0    0    0    0    0    0    0    0  250 
 250    0    0    0    0    0    0    0    0    0    0    0 
 250    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0  250 
 250    0    0    0    0    0  250  250    0  250    0    0 
   0    0    0    0    0    0    0    0    0    0  250    0 
   0    0    0    0    0    0    0  250    0    0  250    0 
   0  250  250    0    0  250  250    0    0    0    0  250 
 250    0    0    0    0    0  250  250    0    0    0  250 
   0    0    0  250  250    0    0    0    0    0    0  250 
   0    0    0  250    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0  250  250    0 
   0  250    0    0    0    0    0    0  250    0    0    0 
 250    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0  250    0    0    0    0    0    0    0  250 
   0    0  250  250    0    0    0    0    0    0  250  250 
 250    0    0    0    0  250  250    0    0    0  250  250 
 250  250  250    0    0  250    0    0    0    0  250    0 
   0    0    0    0    0  250    0    0    0  250    0    0 
   0    0    0  250    0    0    0  250  250    0    0    0 
   0    0  250    0    0    0    0    0  250    0    0    0 
   0    0    0    0    0  250    0    0    0    0  250  250 
   0    0  250    0    0  250    0    0  250    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0  250    0    0    0    0    0    0    0    0    0 
 250  250  250    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0  250    0    0 
 250    0  250    0    0  250  250    0  250    0    0  250 
   0    0    0  250    0  250    0    0    0    0    0    0 
   0    0  250    0    0    0  250  250    0    0    0  250 
   0  250  250    0    0    0    0    0    0    0    0    0 
   0    0    0  250    0    0    0    0    0  250    0    0 
   0    0    0    0  250    0    0    0    0  250  250    0 
 250    0    0    0    0  250    0    0    0  250  250  250 
 250  250  250    0    0    0    0    0    0    0    0    0 
   0    0    0    0  250    0    0    0    0    0  250    0 
   0    0    0  250    0    0    0    0    0  250  250    0 
   0    0    0    0    0    0    0    0    0  250    0    0 
   0    0    0  250  250    0    0  250    0    0  250    0 
 250    0    0  250    0  250  250    0    0  250  250    0 
   0    0    0    0  250    0    0    0    0    0    0    0 
   0    0  250    0  250  250    0  250    0    0    0  250 
   0    0    0  250    0    0  250    0    0    0    0    0 
   0    0  250    0  250    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0  250  250    0 
 250    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0  250    0    0    0    0  250 
 250  250    0  250    0    0    0    0    0    0  250  250 
   0    0    0    0    0    0    0    0    0  250  250    0 
 250    0  250    0    0  250    0    0    0    0    0    0 
   0  250    0    0  250    0    0    0    0    0    0    0 
 250    0    0    0    0    0    0    0    0    0    0  250 
   0    0    0    0  250    0    0    0    0    0    0    0 
 250    0    0    0  250  250    0  250  250  250  250    0 
   0    0    0    0  250    0    0    0  250    0    0    0 
   0  250    0    0    0  250  250    0    0    0    0  250 
   0  250    0    0    0  250  250    0    0    0  250    0 
 250    0    0    0  250  250    0  250    0  250    0    0 
 250    0    0    0    0  250    0    0    0    0    0    0 
   0  250    0    0  250  250    0  250    0    0    0    0 
 250    0  250    0    0    0    0    0  250    0    0  250 
 250    0    0    0    0    0  250    0    0  250    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0  250  250    0  250  250    0  250    0  250    0    0 
   0    0    0    0    0    0    0    0    0    0  250  250 
   0  250  250    0    0    0    0  250    0    0    0    0 
   0  250    0    0    0    0  250    0  250  250  250    0 
 250    0  250    0    0    0    0    0    0    0    0    0 
   0    0  250    0    0    0    0    0  250    0    0  250 
   0    0  250    0    0  250  250    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
 250    0    0  250  250  250  250  250  250    0  250  250 
   0  250  250    0  250    0    0  250    0    0  250    0 
   0    0    0  250    0    0  250    0    0  250  250    0 
 250  250    0  250    0  250    0  250    0    0    0  250 
   0  250    0    0    0    0    0  250  250    0    0  250 
   0    0  250    0    0    0    0    0
Receivers
  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15 
 16  17  18  19  20  21  22  23  24  25  26  27  28  29  30 
 31  32  33  34  35  36  37  38  39  40  41  42  43  44  45 
 46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 
 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75 
 76  77  78  79  80  81  82  83  84  85  86  87  88  89  90 
 91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 
106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 
121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 
136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 
151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 
166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 
181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 
196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 
211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 
226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 
241 242 243 244 245 246 247 248 249 250
missing in columns
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284 284 284 284 284 284 
284 284 284 284 284 284 284 284 284 284
Total number of missing data: 71000, corresponding to a fraction of 0.242.
In reported in- and outdegrees, missings are not counted.

For observation moment 3, degree distributions are as follows:
Nodes
   1    2    3    4    5    6    7    8    9   10   11   12 
  13   14   15   16   17   18   19   20   21   22   23   24 
  25   26   27   28   29   30   31   32   33   34   35   36 
  37   38   39   40   41   42   43   44   45   46   47   48 
  49   50   51   52   53   54   55   56   57   58   59   60 
  61   62   63   64   65   66   67   68   69   70   71   72 
  73   74   75   76   77   78   79   80   81   82   83   84 
  85   86   87   88   89   90   91   92   93   94   95   96 
  97   98   99  100  101  102  103  104  105  106  107  108 
 109  110  111  112  113  114  115  116  117  118  119  120 
 121  122  123  124  125  126  127  128  129  130  131  132 
 133  134  135  136  137  138  139  140  141  142  143  144 
 145  146  147  148  149  150  151  152  153  154  155  156 
 157  158  159  160  161  162  163  164  165  166  167  168 
 169  170  171  172  173  174  175  176  177  178  179  180 
 181  182  183  184  185  186  187  188  189  190  191  192 
 193  194  195  196  197  198  199  200  201  202  203  204 
 205  206  207  208  209  210  211  212  213  214  215  216 
 217  218  219  220  221  222  223  224  225  226  227  228 
 229  230  231  232  233  234  235  236  237  238  239  240 
 241  242  243  244  245  246  247  248  249  250  251  252 
 253  254  255  256  257  258  259  260  261  262  263  264 
 265  266  267  268  269  270  271  272  273  274  275  276 
 277  278  279  280  281  282  283  284  285  286  287  288 
 289  290  291  292  293  294  295  296  297  298  299  300 
 301  302  303  304  305  306  307  308  309  310  311  312 
 313  314  315  316  317  318  319  320  321  322  323  324 
 325  326  327  328  329  330  331  332  333  334  335  336 
 337  338  339  340  341  342  343  344  345  346  347  348 
 349  350  351  352  353  354  355  356  357  358  359  360 
 361  362  363  364  365  366  367  368  369  370  371  372 
 373  374  375  376  377  378  379  380  381  382  383  384 
 385  386  387  388  389  390  391  392  393  394  395  396 
 397  398  399  400  401  402  403  404  405  406  407  408 
 409  410  411  412  413  414  415  416  417  418  419  420 
 421  422  423  424  425  426  427  428  429  430  431  432 
 433  434  435  436  437  438  439  440  441  442  443  444 
 445  446  447  448  449  450  451  452  453  454  455  456 
 457  458  459  460  461  462  463  464  465  466  467  468 
 469  470  471  472  473  474  475  476  477  478  479  480 
 481  482  483  484  485  486  487  488  489  490  491  492 
 493  494  495  496  497  498  499  500  501  502  503  504 
 505  506  507  508  509  510  511  512  513  514  515  516 
 517  518  519  520  521  522  523  524  525  526  527  528 
 529  530  531  532  533  534  535  536  537  538  539  540 
 541  542  543  544  545  546  547  548  549  550  551  552 
 553  554  555  556  557  558  559  560  561  562  563  564 
 565  566  567  568  569  570  571  572  573  574  575  576 
 577  578  579  580  581  582  583  584  585  586  587  588 
 589  590  591  592  593  594  595  596  597  598  599  600 
 601  602  603  604  605  606  607  608  609  610  611  612 
 613  614  615  616  617  618  619  620  621  622  623  624 
 625  626  627  628  629  630  631  632  633  634  635  636 
 637  638  639  640  641  642  643  644  645  646  647  648 
 649  650  651  652  653  654  655  656  657  658  659  660 
 661  662  663  664  665  666  667  668  669  670  671  672 
 673  674  675  676  677  678  679  680  681  682  683  684 
 685  686  687  688  689  690  691  692  693  694  695  696 
 697  698  699  700  701  702  703  704  705  706  707  708 
 709  710  711  712  713  714  715  716  717  718  719  720 
 721  722  723  724  725  726  727  728  729  730  731  732 
 733  734  735  736  737  738  739  740  741  742  743  744 
 745  746  747  748  749  750  751  752  753  754  755  756 
 757  758  759  760  761  762  763  764  765  766  767  768 
 769  770  771  772  773  774  775  776  777  778  779  780 
 781  782  783  784  785  786  787  788  789  790  791  792 
 793  794  795  796  797  798  799  800  801  802  803  804 
 805  806  807  808  809  810  811  812  813  814  815  816 
 817  818  819  820  821  822  823  824  825  826  827  828 
 829  830  831  832  833  834  835  836  837  838  839  840 
 841  842  843  844  845  846  847  848  849  850  851  852 
 853  854  855  856  857  858  859  860  861  862  863  864 
 865  866  867  868  869  870  871  872  873  874  875  876 
 877  878  879  880  881  882  883  884  885  886  887  888 
 889  890  891  892  893  894  895  896  897  898  899  900 
 901  902  903  904  905  906  907  908  909  910  911  912 
 913  914  915  916  917  918  919  920  921  922  923  924 
 925  926  927  928  929  930  931  932  933  934  935  936 
 937  938  939  940  941  942  943  944  945  946  947  948 
 949  950  951  952  953  954  955  956  957  958  959  960 
 961  962  963  964  965  966  967  968  969  970  971  972 
 973  974  975  976  977  978  979  980  981  982  983  984 
 985  986  987  988  989  990  991  992  993  994  995  996 
 997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 
1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 
1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 
1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 
1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 
1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 
1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 
1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 
1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 
1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 
1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 
1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 
1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 
1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 
1165 1166 1167 1168 1169 1170 1171 1172
out-degrees
   2    0    7    0    1    1    1    2    1    2    1    3 
   1    0    0    0    0    2    6    0    2    0    1    1 
   2    1    2    0    0    2    1    1    0    0    3    3 
   1    1    3    1    1    0    2    1    3    2    3    1 
   2    3    1    2    0    0    0    0    0    0    1    0 
   1    0    0    1    0    1    1    1    1    1    9    1 
   0    0    0    1    1    1    1    2    1    0    1    1 
   0    0    0    1    1    1    0    0    0    1    0    2 
   1    0    1    0    0    0    2    1    0    0    1    1 
   2    0    1    0    0    0    1    1    2    0    1    1 
   1    1    0    0    0    1    0    0    0    0    1    1 
   1    0    1    0    0    2    1    0    0    1    1    1 
   1    0    0    0    1    0    8    1    1    1    1    0 
   0    0    1    1    1    1    0    1    1    1    0    0 
   1    1    1    2    1    2    1    1    0    0    3    1 
   0    0    1    1    0    1    1    1    0    1    0    0 
   0    1    0    1    1    5    0    1    1    0    0    1 
   0    0    1    0    1    2    0    1    2    1    0    1 
   0    1    0    1    1    1    1    2    0    0    0    0 
   0    0    0    1    2    1    1    1    1    0    1    1 
   0    0    1    1    1    1    1    1    1    1    1    1 
   0    1    1    0    1    0    1    0    0    0    0    1 
   1    0    1    1    0    2    1    0    1    0    1    0 
   0    0    0    0    1    0    0    1    0    0    1    0 
   0    0    0    0    0    0    1    0    0    0    1    0 
   1    1    1    0    2    0    0    1    0    0    1    1 
   0    2    0    0    1    2    0    0    0    1    0    0 
   2    1    1    1    1    1    1    0    1    1    0    1 
   1    0    0    1    1    1    0    1    0    1    0    0 
   0    1    0    0    1    1    1    1    0    0    1    1 
   0    1    0    1    1    0    0    0    0    1    0    1 
   1    0    0    1    0    0    0    0    0    1    1    0 
   1    1    1    0    0    0    1    1    0    0    0    1 
   1    1    1    1    2    1    0    0    1    1    1    0 
   2    0    2    3    1    0    1    0    0    1    1    2 
   0    0    0    0    0    0    1    0    0    0    0    1 
   1    1    0    0    1    0    1    2    1    0    1    1 
   1    1    1    0    0    1    0    1    1    1    1    1 
   1    0    0    1    0    1    0    1    0    1    0    0 
   0    0    0    0    1    0    0    1    1    0    1    0 
   1    1    0    1    1    0    0    1    1    1    0    0 
   0    1    1    0    0    2    1    1    1    1    0    0 
   2    1    0    1    0    1    0    0    0    0    0    1 
   0    1    1    1    0    1    3    2    1    1    0    1 
   1    0    2    1    0    0    0    0    0    1    0    0 
   2    0    0    0    0    1    1    1    1    0    2    0 
   1    1    0    1    3    0    0    1    1    1    1    0 
   0    1    2    1    1    0    0    0    2    1    1    1 
   1    1    1    1    1    1    1    1    0    1    1    0 
   1    0    2    0    1    1    0    0    2    1    1    0 
   1    1    1    0    1    2    1    1    1    1    1    1 
   0    0    1    0    1    0    0    1    0    1    0    0 
   1    1    1    1    1    2    2    1    1    1    1    1 
   1    2    1    0    1    0    1    0    1    2    0    0 
   0    5    3    0    1    1    1    1    1    0    1    1 
   2    1    0    1    0    0    0    0    0    1    1    0 
   0    0    0    1    1    0    1    0    0    0    0    0 
   1    0    1    1    1    0    0    1    1    1    0    0 
   1    1    1    1    1    1    1    1    1    1    1    1 
   1    1    0    1    0    0    1    0    1    1    0    1 
   1    1    1    1    1    0    1    1    1    1    1    1 
   1    0    1    1    1    1    1    1    1    1    0    0 
   0    0    1    0    0    1    1    1    1    0    1    0 
   0    0    0    1    1    1    1    1    0    1    1    0 
   1    0    1    1    1    0    0    1    1    0    0    0 
   0    0    0    0    1    0    1    1    1    1    0    0 
   0    1    1    0    0    0    2    0    0    1    1    1 
   1    0    0    1    0    1    0    0    1    1    1    1 
   0    0    1    0    0    0    1    2    0    1    0    1 
   0    1    0    0    1    1    0    1    1    0    1    0 
   0    0    1    1    0    0    1    0    1    1    1    1 
   1    0    0    1    1    1    0    0    2    1    1    0 
   1    1    1    1    0    1    2    0    1    1    1    0 
   1    1    1    1    0    0    1    0    0    1    0    1 
   1    0    1    1    0    0    1    1    0    1    1    0 
   1    1    1    1    1    1    1    1    1    1    2    0 
   1    1    1    1    1    1    1    1    1    1    0    0 
   1    1    1    1    0    0    0    1    1    1    0    1 
   1    1    1    0    1    0    1    1    1    1    1    0 
   0    1    0    0    0    1    1    0    0    0    1    0 
   0    0    1    0    2    0    1    1    1    1    1    1 
   1    1    1    0    1    1    1    1    1    1    0    0 
   1    1    0    1    0    1    1    0    0    1    0    0 
   0    1    0    0    0    0    1    0    0    0    0    0 
   0    1    0    1    1    1    0    0    0    1    1    1 
   0    0    0    0    0    1    0    0    1    0    0    0 
   0    0    0    2    2    1    2    1    0    0    1    1 
   1    1    1    0    0    0    0    0    1    1    1    0 
   1    1    1    1    0    1    0    0    0    0    0    0 
   0    0    1    1    1    1    1    0    0    0    0    1 
   1    0    1    1    1    1    1    0    0    0    0    0 
   0    0    1    0    1    0    0    1    1    1    1    1 
   1    0    1    1    1    1    1    1    1    0    1    0 
   0    1    1    1    0    1    1    0    0    1    1    1 
   0    0    0    1    1    0    1    1    1    1    1    0 
   1    1    1    1    0    0    0    1    1    0    0    0 
   1    1    0    0    0    0    0    0    0    0    1    1 
   1    1    1    0    0    0    1    1
in-degrees
  5   3   0   1   0   0   0   6   1   6   0   4   3   1   3 
  2   0  12   0   1   3   0   2   0   1   0   0   3   0   3 
  8   1   3   6   2   4   1   3   1   3   2   1   1   2   2 
  0   0   5   1   3   4   0   0   1  33   3   2   2   3   3 
  1   2   3  33   1   4   6   0   0   1   1   4   1   2   2 
  0   3   0   6   2   0   9  11   2   3   7   0   2   6   2 
  4   3   5   0   2   0   3   0   4   0   5   5   3   3   0 
 37   5   3   5   2   1  10   2   3   0   0   0   3  11   0 
  0   0   0   0   1   2   1   1   1   1   0   0   1   1   1 
  1   5   1   1   0   2   2  61   0   1   3   1   0   0   3 
  1   0   0   0   0   0   1   1   1   2   1   1   1   0   2 
  2   4   2   1   2   2   0   1   0   2   1   6   3   0   2 
  3   0   1   6   3   8   2   0   2   2   1   1   2  11   2 
  6   4   2  33  11   1   1   0   1   3  37   1   1   0   0 
  0  18   1   0   1   0  10   0   0   2   3   1   4   0   0 
  0   2   0  10  15  11   2   1   0   2   1   2   2   2   4 
  1   2   0   2   5  11   1   2   2   0

For observation moment 3, number of missing values are:
Senders
   1    2    3    4    5    6    7    8    9   10   11   12 
  13   14   15   16   17   18   19   20   21   22   23   24 
  25   26   27   28   29   30   31   32   33   34   35   36 
  37   38   39   40   41   42   43   44   45   46   47   48 
  49   50   51   52   53   54   55   56   57   58   59   60 
  61   62   63   64   65   66   67   68   69   70   71   72 
  73   74   75   76   77   78   79   80   81   82   83   84 
  85   86   87   88   89   90   91   92   93   94   95   96 
  97   98   99  100  101  102  103  104  105  106  107  108 
 109  110  111  112  113  114  115  116  117  118  119  120 
 121  122  123  124  125  126  127  128  129  130  131  132 
 133  134  135  136  137  138  139  140  141  142  143  144 
 145  146  147  148  149  150  151  152  153  154  155  156 
 157  158  159  160  161  162  163  164  165  166  167  168 
 169  170  171  172  173  174  175  176  177  178  179  180 
 181  182  183  184  185  186  187  188  189  190  191  192 
 193  194  195  196  197  198  199  200  201  202  203  204 
 205  206  207  208  209  210  211  212  213  214  215  216 
 217  218  219  220  221  222  223  224  225  226  227  228 
 229  230  231  232  233  234  235  236  237  238  239  240 
 241  242  243  244  245  246  247  248  249  250  251  252 
 253  254  255  256  257  258  259  260  261  262  263  264 
 265  266  267  268  269  270  271  272  273  274  275  276 
 277  278  279  280  281  282  283  284  285  286  287  288 
 289  290  291  292  293  294  295  296  297  298  299  300 
 301  302  303  304  305  306  307  308  309  310  311  312 
 313  314  315  316  317  318  319  320  321  322  323  324 
 325  326  327  328  329  330  331  332  333  334  335  336 
 337  338  339  340  341  342  343  344  345  346  347  348 
 349  350  351  352  353  354  355  356  357  358  359  360 
 361  362  363  364  365  366  367  368  369  370  371  372 
 373  374  375  376  377  378  379  380  381  382  383  384 
 385  386  387  388  389  390  391  392  393  394  395  396 
 397  398  399  400  401  402  403  404  405  406  407  408 
 409  410  411  412  413  414  415  416  417  418  419  420 
 421  422  423  424  425  426  427  428  429  430  431  432 
 433  434  435  436  437  438  439  440  441  442  443  444 
 445  446  447  448  449  450  451  452  453  454  455  456 
 457  458  459  460  461  462  463  464  465  466  467  468 
 469  470  471  472  473  474  475  476  477  478  479  480 
 481  482  483  484  485  486  487  488  489  490  491  492 
 493  494  495  496  497  498  499  500  501  502  503  504 
 505  506  507  508  509  510  511  512  513  514  515  516 
 517  518  519  520  521  522  523  524  525  526  527  528 
 529  530  531  532  533  534  535  536  537  538  539  540 
 541  542  543  544  545  546  547  548  549  550  551  552 
 553  554  555  556  557  558  559  560  561  562  563  564 
 565  566  567  568  569  570  571  572  573  574  575  576 
 577  578  579  580  581  582  583  584  585  586  587  588 
 589  590  591  592  593  594  595  596  597  598  599  600 
 601  602  603  604  605  606  607  608  609  610  611  612 
 613  614  615  616  617  618  619  620  621  622  623  624 
 625  626  627  628  629  630  631  632  633  634  635  636 
 637  638  639  640  641  642  643  644  645  646  647  648 
 649  650  651  652  653  654  655  656  657  658  659  660 
 661  662  663  664  665  666  667  668  669  670  671  672 
 673  674  675  676  677  678  679  680  681  682  683  684 
 685  686  687  688  689  690  691  692  693  694  695  696 
 697  698  699  700  701  702  703  704  705  706  707  708 
 709  710  711  712  713  714  715  716  717  718  719  720 
 721  722  723  724  725  726  727  728  729  730  731  732 
 733  734  735  736  737  738  739  740  741  742  743  744 
 745  746  747  748  749  750  751  752  753  754  755  756 
 757  758  759  760  761  762  763  764  765  766  767  768 
 769  770  771  772  773  774  775  776  777  778  779  780 
 781  782  783  784  785  786  787  788  789  790  791  792 
 793  794  795  796  797  798  799  800  801  802  803  804 
 805  806  807  808  809  810  811  812  813  814  815  816 
 817  818  819  820  821  822  823  824  825  826  827  828 
 829  830  831  832  833  834  835  836  837  838  839  840 
 841  842  843  844  845  846  847  848  849  850  851  852 
 853  854  855  856  857  858  859  860  861  862  863  864 
 865  866  867  868  869  870  871  872  873  874  875  876 
 877  878  879  880  881  882  883  884  885  886  887  888 
 889  890  891  892  893  894  895  896  897  898  899  900 
 901  902  903  904  905  906  907  908  909  910  911  912 
 913  914  915  916  917  918  919  920  921  922  923  924 
 925  926  927  928  929  930  931  932  933  934  935  936 
 937  938  939  940  941  942  943  944  945  946  947  948 
 949  950  951  952  953  954  955  956  957  958  959  960 
 961  962  963  964  965  966  967  968  969  970  971  972 
 973  974  975  976  977  978  979  980  981  982  983  984 
 985  986  987  988  989  990  991  992  993  994  995  996 
 997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 
1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 
1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 
1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 
1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 
1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 
1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 
1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 
1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 
1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 
1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 
1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 
1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 
1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 
1165 1166 1167 1168 1169 1170 1171 1172
missing in rows
   0    0    0    0    0    0    0    0    0    0    0    0 
   0  250    0    0    0    0    0    0    0    0    0    0 
   0    0    0  250    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0  250  250    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0  250  250    0    0  250    0    0  250    0    0 
   0  250    0    0  250    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0  250 
 250    0    0    0    0    0    0    0    0    0    0  250 
   0    0    0    0    0    0    0    0  250    0    0    0 
   0  250    0    0    0    0    0    0    0    0    0    0 
   0    0  250    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0  250    0    0    0 
   0    0    0    0    0    0    0    0    0  250    0    0 
 250  250    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
 250    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0  250 
   0    0    0    0    0    0  250    0    0  250    0    0 
   0    0    0    0    0    0    0    0    0    0  250    0 
   0    0    0    0    0    0    0  250    0    0  250    0 
   0  250  250    0    0    0  250    0    0    0    0  250 
 250    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0  250  250    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0  250    0    0    0    0    0    0    0    0 
   0    0  250  250    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0  250    0    0    0    0    0 
   0  250  250    0    0    0    0    0    0    0  250    0 
   0    0    0    0    0  250    0    0    0  250    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0  250    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0  250    0    0    0    0    0    0    0    0    0 
   0    0  250    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0  250    0    0  250 
   0    0    0  250    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0  250    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0  250    0 
 250    0    0    0    0    0    0    0    0  250    0    0 
   0    0  250    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0  250    0 
   0    0    0    0    0    0    0    0    0    0  250    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0  250    0    0  250    0    0  250    0 
   0    0    0    0    0  250    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0  250    0    0    0    0    0    0  250 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0  250    0 
 250    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0  250    0    0    0    0    0 
 250  250    0  250    0    0    0    0    0    0  250    0 
   0    0    0    0    0    0    0    0    0  250    0    0 
 250    0    0    0    0  250    0    0    0    0    0    0 
   0  250    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0  250 
   0    0    0    0  250    0    0    0    0    0    0    0 
   0    0    0    0  250  250    0    0  250    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0  250 
   0    0    0    0    0  250  250    0    0    0  250    0 
   0    0    0    0    0  250    0    0    0    0    0    0 
 250    0    0    0    0    0    0    0    0    0    0    0 
   0  250    0    0    0  250    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0  250 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0  250    0    0    0    0  250    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0  250  250 
   0  250  250    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0  250    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0  250    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0  250 
   0    0    0    0  250    0    0  250    0    0    0    0 
   0    0    0    0    0    0    0    0    0    0    0    0 
   0    0    0    0    0  250    0    0    0    0    0  250 
   0    0    0    0    0    0    0  250  250    0    0    0 
   0    0    0    0    0    0    0    0
Receivers
  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15 
 16  17  18  19  20  21  22  23  24  25  26  27  28  29  30 
 31  32  33  34  35  36  37  38  39  40  41  42  43  44  45 
 46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 
 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75 
 76  77  78  79  80  81  82  83  84  85  86  87  88  89  90 
 91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 
106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 
121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 
136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 
151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 
166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 
181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 
196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 
211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 
226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 
241 242 243 244 245 246 247 248 249 250
missing in columns
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 
102 102 102 102 102 102 102 102 102 102
Total number of missing data: 25500, corresponding to a fraction of 0.087.
In reported in- and outdegrees, missings are not counted.

For observation moment 4, degree distributions are as follows:
Nodes
   1    2    3    4    5    6    7    8    9   10   11   12 
  13   14   15   16   17   18   19   20   21   22   23   24 
  25   26   27   28   29   30   31   32   33   34   35   36 
  37   38   39   40   41   42   43   44   45   46   47   48 
  49   50   51   52   53   54   55   56   57   58   59   60 
  61   62   63   64   65   66   67   68   69   70   71   72 
  73   74   75   76   77   78   79   80   81   82   83   84 
  85   86   87   88   89   90   91   92   93   94   95   96 
  97   98   99  100  101  102  103  104  105  106  107  108 
 109  110  111  112  113  114  115  116  117  118  119  120 
 121  122  123  124  125  126  127  128  129  130  131  132 
 133  134  135  136  137  138  139  140  141  142  143  144 
 145  146  147  148  149  150  151  152  153  154  155  156 
 157  158  159  160  161  162  163  164  165  166  167  168 
 169  170  171  172  173  174  175  176  177  178  179  180 
 181  182  183  184  185  186  187  188  189  190  191  192 
 193  194  195  196  197  198  199  200  201  202  203  204 
 205  206  207  208  209  210  211  212  213  214  215  216 
 217  218  219  220  221  222  223  224  225  226  227  228 
 229  230  231  232  233  234  235  236  237  238  239  240 
 241  242  243  244  245  246  247  248  249  250  251  252 
 253  254  255  256  257  258  259  260  261  262  263  264 
 265  266  267  268  269  270  271  272  273  274  275  276 
 277  278  279  280  281  282  283  284  285  286  287  288 
 289  290  291  292  293  294  295  296  297  298  299  300 
 301  302  303  304  305  306  307  308  309  310  311  312 
 313  314  315  316  317  318  319  320  321  322  323  324 
 325  326  327  328  329  330  331  332  333  334  335  336 
 337  338  339  340  341  342  343  344  345  346  347  348 
 349  350  351  352  353  354  355  356  357  358  359  360 
 361  362  363  364  365  366  367  368  369  370  371  372 
 373  374  375  376  377  378  379  380  381  382  383  384 
 385  386  387  388  389  390  391  392  393  394  395  396 
 397  398  399  400  401  402  403  404  405  406  407  408 
 409  410  411  412  413  414  415  416  417  418  419  420 
 421  422  423  424  425  426  427  428  429  430  431  432 
 433  434  435  436  437  438  439  440  441  442  443  444 
 445  446  447  448  449  450  451  452  453  454  455  456 
 457  458  459  460  461  462  463  464  465  466  467  468 
 469  470  471  472  473  474  475  476  477  478  479  480 
 481  482  483  484  485  486  487  488  489  490  491  492 
 493  494  495  496  497  498  499  500  501  502  503  504 
 505  506  507  508  509  510  511  512  513  514  515  516 
 517  518  519  520  521  522  523  524  525  526  527  528 
 529  530  531  532  533  534  535  536  537  538  539  540 
 541  542  543  544  545  546  547  548  549  550  551  552 
 553  554  555  556  557  558  559  560  561  562  563  564 
 565  566  567  568  569  570  571  572  573  574  575  576 
 577  578  579  580  581  582  583  584  585  586  587  588 
 589  590  591  592  593  594  595  596  597  598  599  600 
 601  602  603  604  605  606  607  608  609  610  611  612 
 613  614  615  616  617  618  619  620  621  622  623  624 
 625  626  627  628  629  630  631  632  633  634  635  636 
 637  638  639  640  641  642  643  644  645  646  647  648 
 649  650  651  652  653  654  655  656  657  658  659  660 
 661  662  663  664  665  666  667  668  669  670  671  672 
 673  674  675  676  677  678  679  680  681  682  683  684 
 685  686  687  688  689  690  691  692  693  694  695  696 
 697  698  699  700  701  702  703  704  705  706  707  708 
 709  710  711  712  713  714  715  716  717  718  719  720 
 721  722  723  724  725  726  727  728  729  730  731  732 
 733  734  735  736  737  738  739  740  741  742  743  744 
 745  746  747  748  749  750  751  752  753  754  755  756 
 757  758  759  760  761  762  763  764  765  766  767  768 
 769  770  771  772  773  774  775  776  777  778  779  780 
 781  782  783  784  785  786  787  788  789  790  791  792 
 793  794  795  796  797  798  799  800  801  802  803  804 
 805  806  807  808  809  810  811  812  813  814  815  816 
 817  818  819  820  821  822  823  824  825  826  827  828 
 829  830  831  832  833  834  835  836  837  838  839  840 
 841  842  843  844  845  846  847  848  849  850  851  852 
 853  854  855  856  857  858  859  860  861  862  863  864 
 865  866  867  868  869  870  871  872  873  874  875  876 
 877  878  879  880  881  882  883  884  885  886  887  888 
 889  890  891  892  893  894  895  896  897  898  899  900 
 901  902  903  904  905  906  907  908  909  910  911  912 
 913  914  915  916  917  918  919  920  921  922  923  924 
 925  926  927  928  929  930  931  932  933  934  935  936 
 937  938  939  940  941  942  943  944  945  946  947  948 
 949  950  951  952  953  954  955  956  957  958  959  960 
 961  962  963  964  965  966  967  968  969  970  971  972 
 973  974  975  976  977  978  979  980  981  982  983  984 
 985  986  987  988  989  990  991  992  993  994  995  996 
 997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 
1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 
1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 
1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 
1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 
1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 
1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 
1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 
1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 
1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 
1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 
1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 
1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 
1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 
1165 1166 1167 1168 1169 1170 1171 1172
out-degrees
   2    0    7    0    1    0    0    2    2    7    1    3 
   0    2    3    1    0    1    3    0    1    0    2    1 
   1    0    2    1    0    1    1    0    0    0    2    3 
   0    0    2    0    0    0    3    2    4    2    4    0 
   2    2    1    0    2    1    0    0    0    0    0    0 
   3    0    0    0    1    1    0    0    0    0    8    2 
   0    0    0    0    0    0    2    0    0    0    0    0 
   0    0    0    1    0    1    0    0    0    0    0    1 
   1    0    0    1    0    0    1    2    0    2    1    0 
   2    2    1    0    1    0    1    0    1    1    2    1 
   2    2    2    1    1    0    1    1    1    1    1    1 
   0    2    0    1    2    1    0    0    0    1    1    0 
   1    0    1    1    2    1    7    1    1    1    1    1 
   1    1    0    1    0    0    1    0    0    1    1    1 
   1    0    1    0    1    1    0    0    1    0    0    0 
   1    1    1    1    0    0    1    0    0    0    1    1 
   0    0    1    2    1    4    0    0    2    0    0    0 
   1    1    0    1    0    1    0    0    5    1    1    0 
   1    1    0    1    1    1    0    0    1    0    0    0 
   0    0    0    1    1    1    1    1    1    1    1    1 
   2    1    1    0    2    0    1    0    0    0    1    0 
   1    0    0    1    0    0    0    0    1    0    0    0 
   1    0    0    0    0    2    0    0    0    0    0    0 
   1    0    0    0    0    0    0    0    0    0    1    0 
   0    0    1    1    0    0    0    0    1    0    1    1 
   1    1    0    0    1    2    3    1    1    5    1    0 
   0    1    1    0    1    0    0    0    0    1    1    0 
   1    2    0    1    1    1    1    1    1    1    1    1 
   1    1    1    0    2    1    1    0    0    0    1    1 
   1    0    1    1    0    1    0    1    0    1    1    1 
   1    0    0    0    0    1    0    1    0    1    0    1 
   0    0    0    1    0    1    0    0    0    1    0    0 
   0    0    0    0    0    0    0    0    0    1    1    0 
   1    1    1    0    1    1    0    2    0    0    0    1 
   1    0    1    3    1    1    0    0    0    1    1    0 
   0    0    0    2    0    0    2    0    1    0    0    1 
   1    1    1    2    3    0    0    1    0    0    2    0 
   1    0    1    0    2    0    2    1    1    1    1    0 
   0    1    1    1    0    0    0    0    0    0    1    0 
   0    0    0    0    1    1    1    1    1    1    1    0 
   1    1    1    1    0    0    0    0    0    1    0    1 
   0    1    1    0    0    0    1    1    1    0    0    0 
   0    0    0    0    0    1    0    0    0    0    2    1 
   0    1    0    0    0    0    1    2    1    0    0    0 
   0    1    1    0    0    0    0    0    0    0    1    0 
   2    1    1    0    0    1    1    0    1    1    1    0 
   1    1    1    1    2    1    1    2    1    1    0    0 
   0    1    3    1    1    0    0    0    2    0    0    0 
   1    0    0    1    1    0    0    1    1    1    1    1 
   0    1    2    1    0    1    1    0    0    1    1    0 
   1    1    0    0    1    0    0    0    1    0    1    1 
   0    1    0    0    1    0    0    0    1    1    0    0 
   1    0    0    1    0    1    1    1    1    2    0    1 
   2    3    1    0    0    0    0    0    1    0    1    0 
   3    5    2    1    1    1    1    1    1    1    0    0 
   0    1    1    2    0    0    0    1    0    0    1    0 
   0    0    0    0    0    1    1    1    0    0    1    0 
   0    0    1    1    1    2    0    0    1    0    1    1 
   1    1    1    1    1    1    1    1    1    1    1    1 
   1    1    1    1    1    1    1    1    1    0    1    1 
   1    0    1    1    1    1    0    1    1    0    0    1 
   1    1    0    1    0    1    1    1    1    1    1    0 
   0    0    0    0    1    1    1    1    1    0    0    1 
   0    1    0    1    0    0    1    0    1    1    1    0 
   1    0    0    1    1    0    0    0    1    0    0    0 
   0    0    0    0    0    0    0    0    0    1    1    0 
   1    1    1    0    0    0    2    0    1    1    1    0 
   1    0    0    0    0    1    1    0    0    2    1    0 
   1    1    1    1    0    1    2    1    0    1    1    0 
   0    0    0    1    1    1    1    1    1    1    1    3 
   1    0    0    1    0    1    1    1    1    0    1    1 
   0    1    0    1    0    1    0    0    2    2    1    1 
   1    1    2    0    0    1    1    0    1    1    1    1 
   1    1    1    1    1    0    1    0    0    0    1    1 
   0    0    1    1    1    1    1    1    1    1    1    1 
   1    1    1    1    1    0    1    1    0    1    1    1 
   1    0    1    1    1    0    0    1    1    0    1    1 
   1    1    0    0    0    1    1    0    0    0    1    0 
   1    1    1    0    1    1    1    2    1    1    1    0 
   1    0    0    0    0    0    0    0    0    1    0    0 
   0    1    0    0    0    1    0    0    1    1    1    1 
   1    1    0    1    1    1    0    1    0    1    1    1 
   0    0    0    1    0    0    1    0    0    0    0    0 
   0    0    1    0    1    0    0    0    0    0    0    0 
   0    0    1    1    1    1    0    1    1    1    0    0 
   0    0    0    0    0    0    0    0    0    0    1    1 
   0    1    1    2    1    2    2    1    1    0    0    0 
   1    0    1    1    0    0    1    0    0    0    1    1 
   1    1    1    0    0    0    1    0    0    1    0    0 
   0    0    0    2    1    1    1    0    1    1    0    1 
   0    0    0    0    0    0    0    0    0    0    1    1 
   0    0    1    0    1    0    0    1    1    0    1    1 
   1    0    0    1    1    0    1    0    1    1    1    1 
   1    1    1    1    1    1    1    1    1    0    1    0 
   1    0    1    1    1    0    1    0    1    1    1    0 
   1    1    1    1    0    1    0    1    1    0    1    1 
   1    1    0    0    0    0    0    1    1    0    0    0 
   1    1    0    0    0    0    0    1
in-degrees
  4   3   1   1   0   0   0   6   0   0   0   4   5   1   1 
  1   0   5   0   0   3   1   1   0   2   1   1   1   3  10 
  7   2   6   1   3   2   1   1   2   1   3   0   3   1   3 
  0   2   3   0   3   4   0   0   0  28   2   2   4   2   2 
  1   3   2  36   2   2   3   0   0   0   1   3   1   2   2 
  4   2   1   6   1   0   6  13   2   0   4   2   3   5   1 
  4   2   1   1   4   1   2   0   6   2   4   5   1   1   0 
 32   0   4   2   2   1   7   1   1   0   0   1   4   9   1 
  1   0   0   0   1   1   1   1   0   0   0   1   2   2   1 
  0   5   2   1   0   0   5  59   0   0   2   3   0   0   3 
  1   3   1   0   0   0   1   0   1   1   1   0   3   0   2 
  8   5   1   2   1   2   0   1   0   0   1  11   6   0   5 
  3   0   2   5   2   8   1   0   2   2   1   2   2  12   1 
  2   5   4  26  13   2   2   0   2   2  33   3   1   2   0 
  0  18   0   0   1   0   7   0   0   2   1   1   3   1   1 
  0   2   0   7  14  13   2   1   0   2   2   2   2   2   4 
  2   4   1   2   7  11   2   2   1   0

No missing data for observation 4.




@2
Reading exogenous changing actor covariates.
--------------------------------------------

6 variables, named:
devActLogVar    
comIntLogVar    
relActLogVar    
ageLogVar       
depsUpLogVar    
depsDownLogVar  

A total of 6 exogenous changing actor covariates.

Number of missing cases per period:
 period                    1       2       3     overall
devActLogVar               0       0       0        0 	   ( 0.0 %)
comIntLogVar               0       0       0        0 	   ( 0.0 %)
relActLogVar               0       0       0        0 	   ( 0.0 %)
ageLogVar                  0       0       0        0 	   ( 0.0 %)
depsUpLogVar               0       0       0        0 	   ( 0.0 %)
depsDownLogVar             0       0       0        0 	   ( 0.0 %)

Information about changing covariates:

              minimum  maximum	  mean  centered 
devActLogVar                               Y 
	period   1     0.0     7.5      1.762 
	period   2     0.0     7.4      1.846 
	period   3     0.0     7.3      1.867 
Overall                            1.825 

comIntLogVar                               Y 
	period   1     0.0     6.8      2.606 
	period   2     0.0     7.1      2.523 
	period   3     0.0     7.0      2.587 
Overall                            2.572 

relActLogVar                               Y 
	period   1     0.0     3.5      0.367 
	period   2     0.0     3.8      0.384 
	period   3     0.0     3.5      0.385 
Overall                            0.379 

ageLogVar                                  Y 
	period   1     0.1     4.8      4.001 
	period   2     0.7     4.8      4.030 
	period   3     1.1     4.8      4.057 
Overall                            4.030 

depsUpLogVar                               Y 
	period   1     0.0     4.2      1.287 
	period   2     0.0     4.2      1.289 
	period   3     0.0     4.2      1.289 
Overall                            1.288 

depsDownLogVar                             Y 
	period   1     0.0     4.3      0.742 
	period   2     0.0     4.3      0.742 
	period   3     0.0     4.3      0.752 
Overall                            0.745 

The mean values are subtracted from the covariates.


@2
Reading exogenous dyadic covariates.
------------------------------------

Exogenous dyadic covariate named depUpDyad.
Exogenous dyadic covariate named depDownDyad.
Number of tie variables with missing data per period:
 period         1      2      3      overall
depUpDyad       0      0      0         0 	   ( 0.0 %)
depDownDyad      0      0      0         0 	   ( 0.0 %)

Information about changing dyadic covariates:
                   mean     centered 
depUpDyad                       Y 
	period   1      0.000 
	period   2      0.000 
	period   3      0.000 

depDownDyad                     Y 
	period   1      0.000 
	period   2      0.000 
	period   3      0.000 


The mean values are subtracted from the covariates.


@2
Reading files with times of composition change.
-----------------------------------------------


Composition changes for nodeSet devs.

Actor  5 joins  network at time 2.0000.
Actor  7 joins  network at time 3.0000.
Actor 12 joins  network at time 2.0000.
Actor 14 joins  network at time 4.0000.
Actor 16 joins  network at time 2.0000.
Actor 17 joins  network at time 2.0000.
Actor 20 joins  network at time 2.0000.
Actor 24 joins  network at time 3.0000.
Actor 25 joins  network at time 3.0000.
Actor 28 joins  network at time 4.0000.
Actor 31 joins  network at time 3.0000.
Actor 37 joins  network at time 2.0000.
Actor 38 joins  network at time 2.0000.
Actor 40 joins  network at time 2.0000.
Actor 41 joins  network at time 3.0000.
Actor 44 joins  network at time 3.0000.
Actor 48 joins  network at time 2.0000.
Actor 51 joins  network at time 3.0000.
Actor 53 joins  network at time 4.0000.
Actor 54 joins  network at time 4.0000.
Actor 61 joins  network at time 3.0000.
Actor 62 joins  network at time 2.0000.
Actor 64 joins  network at time 3.0000.
Actor 65 joins  network at time 2.0000.
Actor 67 joins  network at time 2.0000.
Actor 68 joins  network at time 3.0000.
Actor 69 joins  network at time 2.0000.
Actor 70 joins  network at time 2.0000.
Actor 75 joins  network at time 2.0000.
Actor 76 joins  network at time 2.0000.
Actor 79 joins  network at time 2.0000.
Actor 80 joins  network at time 3.0000.
Actor 83 joins  network at time 2.0000.
Actor 84 joins  network at time 2.0000.
Actor 89 joins  network at time 2.0000.
Actor 94 joins  network at time 2.0000.
Actor 95 joins  network at time 2.0000.
Actor 97 joins  network at time 2.0000.
Actor 98 joins  network at time 2.0000.
Actor 99 joins  network at time 3.0000.
Actor 106 joins  network at time 2.0000.
Actor 108 joins  network at time 2.0000.
Actor 110 joins  network at time 2.0000.
Actor 116 joins  network at time 3.0000.
Actor 117 joins  network at time 3.0000.
Actor 122 joins  network at time 2.0000.
Actor 123 joins  network at time 4.0000.
Actor 124 joins  network at time 4.0000.
Actor 126 joins  network at time 3.0000.
Actor 127 joins  network at time 4.0000.
Actor 130 joins  network at time 4.0000.
Actor 132 joins  network at time 3.0000.
Actor 133 joins  network at time 3.0000.
Actor 134 joins  network at time 4.0000.
Actor 135 joins  network at time 3.0000.
Actor 137 joins  network at time 4.0000.
Actor 138 joins  network at time 3.0000.
Actor 139 joins  network at time 2.0000.
Actor 142 joins  network at time 2.0000.
Actor 145 joins  network at time 3.0000.
Actor 152 joins  network at time 2.0000.
Actor 154 joins  network at time 2.0000.
Actor 155 joins  network at time 3.0000.
Actor 156 joins  network at time 4.0000.
Actor 157 joins  network at time 4.0000.
Actor 161 joins  network at time 3.0000.
Actor 165 joins  network at time 2.0000.
Actor 167 joins  network at time 2.0000.
Actor 168 joins  network at time 4.0000.
Actor 170 joins  network at time 3.0000.
Actor 171 joins  network at time 3.0000.
Actor 172 joins  network at time 2.0000.
Actor 174 joins  network at time 3.0000.
Actor 175 joins  network at time 3.0000.
Actor 177 joins  network at time 4.0000.
Actor 179 joins  network at time 3.0000.
Actor 181 joins  network at time 2.0000.
Actor 182 joins  network at time 4.0000.
Actor 184 joins  network at time 3.0000.
Actor 186 joins  network at time 2.0000.
Actor 187 joins  network at time 3.0000.
Actor 194 joins  network at time 3.0000.
Actor 195 joins  network at time 4.0000.
Actor 196 joins  network at time 3.0000.
Actor 204 joins  network at time 3.0000.
Actor 209 joins  network at time 3.0000.
Actor 212 joins  network at time 2.0000.
Actor 216 joins  network at time 2.0000.
Actor 223 joins  network at time 3.0000.
Actor 225 joins  network at time 4.0000.
Actor 226 joins  network at time 2.0000.
Actor 227 joins  network at time 2.0000.
Actor 238 joins  network at time 4.0000.
Actor 241 joins  network at time 4.0000.
Actor 242 joins  network at time 4.0000.
Actor 243 joins  network at time 3.0000.
Actor 245 joins  network at time 3.0000.
Actor 248 joins  network at time 3.0000.
Actor 249 joins  network at time 2.0000.
Actor 250 joins  network at time 2.0000.
Actor 252 joins  network at time 3.0000.
Actor 254 joins  network at time 3.0000.
Actor 255 joins  network at time 3.0000.
Actor 257 joins  network at time 2.0000.
Actor 264 joins  network at time 3.0000.
Actor 265 joins  network at time 3.0000.
Actor 268 joins  network at time 2.0000.
Actor 271 joins  network at time 2.0000.
Actor 273 joins  network at time 2.0000.
Actor 275 joins  network at time 2.0000.
Actor 276 joins  network at time 2.0000.
Actor 277 joins  network at time 4.0000.
Actor 279 joins  network at time 2.0000.
Actor 280 joins  network at time 2.0000.
Actor 283 joins  network at time 2.0000.
Actor 284 joins  network at time 2.0000.
Actor 288 joins  network at time 2.0000.
Actor 295 joins  network at time 2.0000.
Actor 299 joins  network at time 2.0000.
Actor 300 joins  network at time 4.0000.
Actor 301 joins  network at time 3.0000.
Actor 303 joins  network at time 2.0000.
Actor 307 joins  network at time 4.0000.
Actor 308 joins  network at time 3.0000.
Actor 310 joins  network at time 4.0000.
Actor 313 joins  network at time 2.0000.
Actor 315 joins  network at time 2.0000.
Actor 323 joins  network at time 4.0000.
Actor 324 joins  network at time 2.0000.
Actor 325 joins  network at time 2.0000.
Actor 326 joins  network at time 2.0000.
Actor 332 joins  network at time 4.0000.
Actor 334 joins  network at time 2.0000.
Actor 335 joins  network at time 4.0000.
Actor 338 joins  network at time 4.0000.
Actor 339 joins  network at time 4.0000.
Actor 340 joins  network at time 2.0000.
Actor 342 joins  network at time 3.0000.
Actor 343 joins  network at time 4.0000.
Actor 347 joins  network at time 2.0000.
Actor 348 joins  network at time 4.0000.
Actor 349 joins  network at time 4.0000.
Actor 355 joins  network at time 3.0000.
Actor 356 joins  network at time 3.0000.
Actor 357 joins  network at time 2.0000.
Actor 359 joins  network at time 2.0000.
Actor 360 joins  network at time 3.0000.
Actor 362 joins  network at time 2.0000.
Actor 364 joins  network at time 3.0000.
Actor 365 joins  network at time 3.0000.
Actor 372 joins  network at time 3.0000.
Actor 373 joins  network at time 2.0000.
Actor 376 joins  network at time 3.0000.
Actor 383 joins  network at time 2.0000.
Actor 386 joins  network at time 2.0000.
Actor 387 joins  network at time 2.0000.
Actor 389 joins  network at time 2.0000.
Actor 393 joins  network at time 2.0000.
Actor 394 joins  network at time 4.0000.
Actor 395 joins  network at time 4.0000.
Actor 396 joins  network at time 2.0000.
Actor 398 joins  network at time 3.0000.
Actor 401 joins  network at time 2.0000.
Actor 403 joins  network at time 2.0000.
Actor 405 joins  network at time 3.0000.
Actor 409 joins  network at time 3.0000.
Actor 413 joins  network at time 2.0000.
Actor 414 joins  network at time 2.0000.
Actor 415 joins  network at time 2.0000.
Actor 416 joins  network at time 2.0000.
Actor 424 joins  network at time 4.0000.
Actor 425 joins  network at time 2.0000.
Actor 429 joins  network at time 2.0000.
Actor 431 joins  network at time 2.0000.
Actor 432 joins  network at time 3.0000.
Actor 435 joins  network at time 4.0000.
Actor 436 joins  network at time 4.0000.
Actor 440 joins  network at time 2.0000.
Actor 441 joins  network at time 2.0000.
Actor 443 joins  network at time 3.0000.
Actor 444 joins  network at time 3.0000.
Actor 445 joins  network at time 3.0000.
Actor 449 joins  network at time 2.0000.
Actor 450 joins  network at time 3.0000.
Actor 451 joins  network at time 4.0000.
Actor 453 joins  network at time 2.0000.
Actor 455 joins  network at time 3.0000.
Actor 456 joins  network at time 3.0000.
Actor 457 joins  network at time 3.0000.
Actor 458 joins  network at time 4.0000.
Actor 459 joins  network at time 4.0000.
Actor 460 joins  network at time 2.0000.
Actor 462 joins  network at time 3.0000.
Actor 464 joins  network at time 2.0000.
Actor 465 joins  network at time 2.0000.
Actor 467 joins  network at time 4.0000.
Actor 470 joins  network at time 2.0000.
Actor 471 joins  network at time 2.0000.
Actor 474 joins  network at time 4.0000.
Actor 477 joins  network at time 2.0000.
Actor 478 joins  network at time 4.0000.
Actor 481 joins  network at time 2.0000.
Actor 482 joins  network at time 2.0000.
Actor 483 joins  network at time 2.0000.
Actor 484 joins  network at time 3.0000.
Actor 485 joins  network at time 2.0000.
Actor 488 joins  network at time 3.0000.
Actor 489 joins  network at time 3.0000.
Actor 490 joins  network at time 2.0000.
Actor 492 joins  network at time 2.0000.
Actor 493 joins  network at time 2.0000.
Actor 495 joins  network at time 3.0000.
Actor 496 joins  network at time 2.0000.
Actor 497 joins  network at time 2.0000.
Actor 498 joins  network at time 2.0000.
Actor 501 joins  network at time 3.0000.
Actor 502 joins  network at time 2.0000.
Actor 508 joins  network at time 2.0000.
Actor 510 joins  network at time 3.0000.
Actor 511 joins  network at time 2.0000.
Actor 514 joins  network at time 2.0000.
Actor 515 joins  network at time 4.0000.
Actor 516 joins  network at time 3.0000.
Actor 519 joins  network at time 3.0000.
Actor 520 joins  network at time 2.0000.
Actor 522 joins  network at time 3.0000.
Actor 523 joins  network at time 2.0000.
Actor 525 joins  network at time 3.0000.
Actor 528 joins  network at time 2.0000.
Actor 530 joins  network at time 2.0000.
Actor 536 joins  network at time 2.0000.
Actor 539 joins  network at time 2.0000.
Actor 540 joins  network at time 2.0000.
Actor 543 joins  network at time 4.0000.
Actor 548 joins  network at time 2.0000.
Actor 553 joins  network at time 3.0000.
Actor 554 joins  network at time 3.0000.
Actor 555 joins  network at time 4.0000.
Actor 557 joins  network at time 2.0000.
Actor 559 joins  network at time 2.0000.
Actor 563 joins  network at time 2.0000.
Actor 569 joins  network at time 2.0000.
Actor 574 joins  network at time 3.0000.
Actor 575 joins  network at time 2.0000.
Actor 577 joins  network at time 3.0000.
Actor 579 joins  network at time 3.0000.
Actor 582 joins  network at time 3.0000.
Actor 583 joins  network at time 3.0000.
Actor 585 joins  network at time 4.0000.
Actor 588 joins  network at time 4.0000.
Actor 590 joins  network at time 2.0000.
Actor 592 joins  network at time 4.0000.
Actor 593 joins  network at time 2.0000.
Actor 594 joins  network at time 3.0000.
Actor 597 joins  network at time 2.0000.
Actor 599 joins  network at time 2.0000.
Actor 603 joins  network at time 3.0000.
Actor 605 joins  network at time 2.0000.
Actor 606 joins  network at time 2.0000.
Actor 607 joins  network at time 3.0000.
Actor 608 joins  network at time 3.0000.
Actor 610 joins  network at time 2.0000.
Actor 612 joins  network at time 3.0000.
Actor 613 joins  network at time 2.0000.
Actor 614 joins  network at time 4.0000.
Actor 615 joins  network at time 3.0000.
Actor 624 joins  network at time 2.0000.
Actor 628 joins  network at time 3.0000.
Actor 629 joins  network at time 2.0000.
Actor 631 joins  network at time 2.0000.
Actor 634 joins  network at time 3.0000.
Actor 637 joins  network at time 2.0000.
Actor 641 joins  network at time 3.0000.
Actor 646 joins  network at time 3.0000.
Actor 647 joins  network at time 4.0000.
Actor 648 joins  network at time 2.0000.
Actor 649 joins  network at time 4.0000.
Actor 654 joins  network at time 3.0000.
Actor 656 joins  network at time 2.0000.
Actor 658 joins  network at time 4.0000.
Actor 659 joins  network at time 3.0000.
Actor 660 joins  network at time 3.0000.
Actor 661 joins  network at time 3.0000.
Actor 662 joins  network at time 3.0000.
Actor 663 joins  network at time 4.0000.
Actor 665 joins  network at time 2.0000.
Actor 671 joins  network at time 2.0000.
Actor 672 joins  network at time 2.0000.
Actor 673 joins  network at time 2.0000.
Actor 674 joins  network at time 2.0000.
Actor 677 joins  network at time 3.0000.
Actor 678 joins  network at time 2.0000.
Actor 681 joins  network at time 2.0000.
Actor 682 joins  network at time 2.0000.
Actor 683 joins  network at time 4.0000.
Actor 684 joins  network at time 2.0000.
Actor 685 joins  network at time 2.0000.
Actor 687 joins  network at time 2.0000.
Actor 688 joins  network at time 3.0000.
Actor 689 joins  network at time 2.0000.
Actor 690 joins  network at time 2.0000.
Actor 692 joins  network at time 2.0000.
Actor 694 joins  network at time 3.0000.
Actor 695 joins  network at time 4.0000.
Actor 706 joins  network at time 3.0000.
Actor 712 joins  network at time 3.0000.
Actor 713 joins  network at time 4.0000.
Actor 715 joins  network at time 2.0000.
Actor 716 joins  network at time 4.0000.
Actor 719 joins  network at time 4.0000.
Actor 721 joins  network at time 3.0000.
Actor 724 joins  network at time 3.0000.
Actor 725 joins  network at time 2.0000.
Actor 726 joins  network at time 4.0000.
Actor 727 joins  network at time 3.0000.
Actor 730 joins  network at time 3.0000.
Actor 731 joins  network at time 3.0000.
Actor 734 joins  network at time 2.0000.
Actor 735 joins  network at time 2.0000.
Actor 737 joins  network at time 3.0000.
Actor 740 joins  network at time 2.0000.
Actor 741 joins  network at time 2.0000.
Actor 744 joins  network at time 2.0000.
Actor 747 joins  network at time 3.0000.
Actor 749 joins  network at time 4.0000.
Actor 750 joins  network at time 3.0000.
Actor 752 joins  network at time 3.0000.
Actor 753 joins  network at time 2.0000.
Actor 755 joins  network at time 2.0000.
Actor 756 joins  network at time 4.0000.
Actor 758 joins  network at time 2.0000.
Actor 759 joins  network at time 2.0000.
Actor 760 joins  network at time 3.0000.
Actor 762 joins  network at time 2.0000.
Actor 763 joins  network at time 3.0000.
Actor 764 joins  network at time 2.0000.
Actor 769 joins  network at time 2.0000.
Actor 770 joins  network at time 2.0000.
Actor 771 joins  network at time 3.0000.
Actor 773 joins  network at time 3.0000.
Actor 776 joins  network at time 2.0000.
Actor 777 joins  network at time 2.0000.
Actor 780 joins  network at time 2.0000.
Actor 781 joins  network at time 2.0000.
Actor 786 joins  network at time 2.0000.
Actor 789 joins  network at time 2.0000.
Actor 790 joins  network at time 3.0000.
Actor 791 joins  network at time 4.0000.
Actor 793 joins  network at time 4.0000.
Actor 794 joins  network at time 2.0000.
Actor 796 joins  network at time 2.0000.
Actor 798 joins  network at time 2.0000.
Actor 801 joins  network at time 2.0000.
Actor 809 joins  network at time 2.0000.
Actor 811 joins  network at time 4.0000.
Actor 812 joins  network at time 2.0000.
Actor 813 joins  network at time 2.0000.
Actor 815 joins  network at time 2.0000.
Actor 816 joins  network at time 3.0000.
Actor 817 joins  network at time 4.0000.
Actor 818 joins  network at time 4.0000.
Actor 820 joins  network at time 4.0000.
Actor 822 joins  network at time 2.0000.
Actor 827 joins  network at time 4.0000.
Actor 828 joins  network at time 3.0000.
Actor 835 joins  network at time 2.0000.
Actor 838 joins  network at time 4.0000.
Actor 839 joins  network at time 3.0000.
Actor 840 joins  network at time 2.0000.
Actor 841 joins  network at time 4.0000.
Actor 842 joins  network at time 2.0000.
Actor 843 joins  network at time 3.0000.
Actor 846 joins  network at time 4.0000.
Actor 850 joins  network at time 2.0000.
Actor 851 joins  network at time 2.0000.
Actor 853 joins  network at time 2.0000.
Actor 854 joins  network at time 4.0000.
Actor 855 joins  network at time 2.0000.
Actor 857 joins  network at time 3.0000.
Actor 858 joins  network at time 2.0000.
Actor 860 joins  network at time 2.0000.
Actor 863 joins  network at time 2.0000.
Actor 865 joins  network at time 3.0000.
Actor 872 joins  network at time 2.0000.
Actor 876 joins  network at time 4.0000.
Actor 878 joins  network at time 2.0000.
Actor 879 joins  network at time 2.0000.
Actor 880 joins  network at time 2.0000.
Actor 881 joins  network at time 4.0000.
Actor 886 joins  network at time 2.0000.
Actor 887 joins  network at time 2.0000.
Actor 889 joins  network at time 3.0000.
Actor 893 joins  network at time 4.0000.
Actor 894 joins  network at time 4.0000.
Actor 896 joins  network at time 3.0000.
Actor 897 joins  network at time 4.0000.
Actor 898 joins  network at time 3.0000.
Actor 899 joins  network at time 3.0000.
Actor 900 joins  network at time 2.0000.
Actor 905 joins  network at time 3.0000.
Actor 906 joins  network at time 2.0000.
Actor 909 joins  network at time 3.0000.
Actor 910 joins  network at time 2.0000.
Actor 914 joins  network at time 3.0000.
Actor 918 joins  network at time 3.0000.
Actor 919 joins  network at time 3.0000.
Actor 923 joins  network at time 2.0000.
Actor 924 joins  network at time 4.0000.
Actor 926 joins  network at time 3.0000.
Actor 927 joins  network at time 2.0000.
Actor 928 joins  network at time 2.0000.
Actor 930 joins  network at time 4.0000.
Actor 931 joins  network at time 4.0000.
Actor 933 joins  network at time 2.0000.
Actor 935 joins  network at time 4.0000.
Actor 937 joins  network at time 3.0000.
Actor 939 joins  network at time 2.0000.
Actor 940 joins  network at time 2.0000.
Actor 941 joins  network at time 3.0000.
Actor 942 joins  network at time 4.0000.
Actor 944 joins  network at time 3.0000.
Actor 946 joins  network at time 3.0000.
Actor 948 joins  network at time 2.0000.
Actor 949 joins  network at time 4.0000.
Actor 952 joins  network at time 2.0000.
Actor 953 joins  network at time 2.0000.
Actor 954 joins  network at time 3.0000.
Actor 955 joins  network at time 2.0000.
Actor 956 joins  network at time 2.0000.
Actor 962 joins  network at time 4.0000.
Actor 963 joins  network at time 2.0000.
Actor 965 joins  network at time 3.0000.
Actor 966 joins  network at time 4.0000.
Actor 967 joins  network at time 2.0000.
Actor 968 joins  network at time 3.0000.
Actor 969 joins  network at time 2.0000.
Actor 971 joins  network at time 2.0000.
Actor 972 joins  network at time 2.0000.
Actor 973 joins  network at time 3.0000.
Actor 975 joins  network at time 3.0000.
Actor 981 joins  network at time 3.0000.
Actor 982 joins  network at time 2.0000.
Actor 983 joins  network at time 2.0000.
Actor 984 joins  network at time 4.0000.
Actor 985 joins  network at time 3.0000.
Actor 986 joins  network at time 2.0000.
Actor 987 joins  network at time 2.0000.
Actor 988 joins  network at time 2.0000.
Actor 989 joins  network at time 2.0000.
Actor 990 joins  network at time 2.0000.
Actor 991 joins  network at time 3.0000.
Actor 993 joins  network at time 2.0000.
Actor 994 joins  network at time 3.0000.
Actor 995 joins  network at time 2.0000.
Actor 1001 joins  network at time 2.0000.
Actor 1002 joins  network at time 2.0000.
Actor 1003 joins  network at time 2.0000.
Actor 1007 joins  network at time 2.0000.
Actor 1010 joins  network at time 3.0000.
Actor 1011 joins  network at time 4.0000.
Actor 1013 joins  network at time 3.0000.
Actor 1014 joins  network at time 3.0000.
Actor 1016 joins  network at time 4.0000.
Actor 1017 joins  network at time 2.0000.
Actor 1018 joins  network at time 3.0000.
Actor 1020 joins  network at time 2.0000.
Actor 1021 joins  network at time 2.0000.
Actor 1026 joins  network at time 2.0000.
Actor 1031 joins  network at time 4.0000.
Actor 1032 joins  network at time 4.0000.
Actor 1034 joins  network at time 4.0000.
Actor 1035 joins  network at time 4.0000.
Actor 1040 joins  network at time 3.0000.
Actor 1041 joins  network at time 2.0000.
Actor 1043 joins  network at time 2.0000.
Actor 1046 joins  network at time 3.0000.
Actor 1047 joins  network at time 2.0000.
Actor 1048 joins  network at time 2.0000.
Actor 1049 joins  network at time 2.0000.
Actor 1051 joins  network at time 4.0000.
Actor 1052 joins  network at time 2.0000.
Actor 1053 joins  network at time 3.0000.
Actor 1054 joins  network at time 3.0000.
Actor 1055 joins  network at time 3.0000.
Actor 1056 joins  network at time 2.0000.
Actor 1057 joins  network at time 3.0000.
Actor 1058 joins  network at time 2.0000.
Actor 1059 joins  network at time 3.0000.
Actor 1060 joins  network at time 2.0000.
Actor 1062 joins  network at time 2.0000.
Actor 1063 joins  network at time 2.0000.
Actor 1064 joins  network at time 2.0000.
Actor 1071 joins  network at time 3.0000.
Actor 1075 joins  network at time 2.0000.
Actor 1077 joins  network at time 4.0000.
Actor 1079 joins  network at time 2.0000.
Actor 1080 joins  network at time 3.0000.
Actor 1083 joins  network at time 3.0000.
Actor 1084 joins  network at time 2.0000.
Actor 1086 joins  network at time 3.0000.
Actor 1087 joins  network at time 3.0000.
Actor 1091 joins  network at time 2.0000.
Actor 1097 joins  network at time 2.0000.
Actor 1105 joins  network at time 3.0000.
Actor 1106 joins  network at time 2.0000.
Actor 1108 joins  network at time 3.0000.
Actor 1109 joins  network at time 3.0000.
Actor 1110 joins  network at time 3.0000.
Actor 1111 joins  network at time 3.0000.
Actor 1112 joins  network at time 3.0000.
Actor 1113 joins  network at time 3.0000.
Actor 1115 joins  network at time 3.0000.
Actor 1116 joins  network at time 4.0000.
Actor 1118 joins  network at time 3.0000.
Actor 1119 joins  network at time 3.0000.
Actor 1121 joins  network at time 4.0000.
Actor 1122 joins  network at time 2.0000.
Actor 1124 joins  network at time 4.0000.
Actor 1126 joins  network at time 2.0000.
Actor 1127 joins  network at time 3.0000.
Actor 1128 joins  network at time 2.0000.
Actor 1130 joins  network at time 2.0000.
Actor 1132 joins  network at time 3.0000.
Actor 1135 joins  network at time 3.0000.
Actor 1137 joins  network at time 2.0000.
Actor 1138 joins  network at time 3.0000.
Actor 1139 joins  network at time 3.0000.
Actor 1141 joins  network at time 3.0000.
Actor 1142 joins  network at time 3.0000.
Actor 1144 joins  network at time 3.0000.
Actor 1145 joins  network at time 2.0000.
Actor 1146 joins  network at time 4.0000.
Actor 1147 joins  network at time 2.0000.
Actor 1148 joins  network at time 3.0000.
Actor 1150 joins  network at time 2.0000.
Actor 1152 joins  network at time 4.0000.
Actor 1153 joins  network at time 2.0000.
Actor 1154 joins  network at time 3.0000.
Actor 1156 joins  network at time 2.0000.
Actor 1160 joins  network at time 4.0000.
Actor 1161 joins  network at time 4.0000.
Actor 1163 joins  network at time 2.0000.
Actor 1164 joins  network at time 3.0000.
Actor 1167 joins  network at time 3.0000.
Actor 1169 joins  network at time 2.0000.
Actor 1170 joins  network at time 2.0000.

In period 2, 262 actors joined and 0 actors left the network.

In period 3, 182 actors joined and 0 actors left the network.

In period 4, 102 actors joined and 0 actors left the network.


There are missing data for network variable net.

For the similarity variable calculated from each actor covariate,
the mean is subtracted.
These means are:
Similarity devActLogVar             :       0.7360 
Similarity comIntLogVar             :       0.7329 
Similarity relActLogVar             :       0.8453 
Similarity ageLogVar                :       0.8483 
Similarity depsUpLogVar             :       0.7268 
Similarity depsDownLogVar           :       0.7853 



@1
Initial data description.
=========================


@2
Change in networks:
-------------------

For the following statistics, missing values (if any) are not counted.

Network density indicators:
observation time              1      2      3      4
density                    0.005  0.004  0.003  0.003
average degree             1.211  0.909  0.736  0.647
number of ties               758    807    788    758
missing fraction           0.466  0.242  0.087  0.000

The average degree is 0.876 


Tie changes between subsequent observations:
 periods        0 =>  0   0 =>  1   1 =>  0   1 =>  1   Distance Jaccard   Missing
  1 ==>   2    155654        88       325       433       413     0.512    136500 (47%)
  2 ==>   3    221043       150       362       445       512     0.465     71000 (24%)
  3 ==>   4    266517       195       345       443       540     0.451     25500 (9%)


Standard values for initial parameter values
-------------------------------------------------

constant net rate (period 1)            1.3198 
constant net rate (period 2)            1.1534 
constant net rate (period 3)            1.0095 
outdegree (density)                               -1.5450 

Initialisation of project <<hicss-2023-final>> executed succesfully.


-----------------------------------
New Analysis started.
Date and time: 01/06/2022 19:58:02
New results follow.
-----------------------------------

RSiena version 1.3.0.1 (02 Mai 21)


@1
Estimation by stochastic approximation algorithm.
=================================================

Current random number seed is 17.
Effects object used: effects 

NB. Request for conditional estimation has been over-ridden.

Estimation method: unconditional moment estimation
.

Time duration for simulations in each period is 1.0.
Changing composition.
Joiners/leavers option: 1
Standard errors are estimated with the likelihood ratio method.
Dolby method (regression on scores) is used.
Initial value of gain parameter is  0.6928203.
Reduction factor for gain parameter is  0.5000000.
Number of subphases in Phase 2 is 4.

Initial parameter values are 
  1. rate:  constant net rate (period 1)                    1.3198
  2. rate:  constant net rate (period 2)                    1.1534
  3. rate:  constant net rate (period 3)                    1.0095
  4. eval:  outdegree (density)                            -1.5450
  5. eval:  indegree - popularity (sqrt)                    0.0000
  6. eval:  outdegree-trunc(2)                              0.0000
  7. eval:  out-isolate                                     0.0000
  8. eval:  anti in-isolates                                0.0000
  9. eval:  indegree at least 2                             0.0000
 10. eval:  indegree at least 3                             0.0000


Observed values of target statistics are
  1. Amount of network change in period 1                               413.0000
  2. Amount of network change in period 2                               512.0000
  3. Amount of network change in period 3                               540.0000
  4. Number of ties                                                    1754.0000
  5. Sum of indegrees x sqrt(indegree)                                 5181.3115
  6. Sum of outdegrees trunc(2)                                        1639.0000
  7. Number of out-isolates                                            2091.0000
  8. Number of indegrees at least 1                                     519.0000
  9. Number of indegrees at least 2                                     316.0000
 10. Number of indegrees at least 3                                     177.0000

 10 parameters, 10 statistics

Estimation of derivatives by the LR method (type 1).


@2
End of stochastic approximation algorithm, phase 3.
---------------------------------------------------

Total of 4087 iterations.
Parameter estimates based on 1087 iterations,
convergence diagnostics, covariance and derivative matrices based on 3000 iterations.

Information for convergence diagnosis.
Averages, standard deviations, and t-ratios for deviations from targets:
  1.  -0.2987  16.9524  -0.0176 
  2.   0.3133  19.5828   0.0160 
  3.  -0.0430  19.8409  -0.0022 
  4.  -0.2603  31.2345  -0.0083 
  5.   2.6269 183.2353   0.0143 
  6.  -0.4543  29.4114  -0.0154 
  7.   0.2107  25.0480   0.0084 
  8.   0.1383   9.1930   0.0150 
  9.  -0.2417   9.2804  -0.0260 
 10.   0.0650   7.0377   0.0092 

Good convergence is indicated by the t-ratios being close to zero.

Overall maximum convergence ratio =  0.0867 .



@2
Estimation Results.
-------------------

Regular end of estimation algorithm.
Total of 4087 iteration steps.


@3
Estimates and standard errors
                             
 1. rate:  constant net rate (period 1)                            0.8154  (   0.0429)
 2. rate:  constant net rate (period 2)                            0.8187  (   0.0395)
 3. rate:  constant net rate (period 3)                            0.7685  (   0.0389)
 4. eval:  outdegree (density)                                    -3.2843  (   0.2307)
 5. eval:  indegree - popularity (sqrt)                            0.4575  (   0.0383)
 6. eval:  outdegree-trunc(2)                                     -1.7971  (   0.4310)
 7. eval:  out-isolate                                             0.4823  (   0.4257)
 8. eval:  anti in-isolates                                       -0.5289  (   0.2073)
 9. eval:  indegree at least 2                                    -0.3953  (   0.1949)
10. eval:  indegree at least 3                                    -0.9437  (   0.2833)


@3
Covariance matrices
                   
Covariance matrix of estimates (correlations below diagonal):
     0.002      0.000      0.000      0.000      0.000      0.001      0.001      0.000      0.000      0.000
     0.024      0.002      0.000     -0.001      0.000      0.002      0.003      0.000      0.000      0.000
    -0.007      0.014      0.002     -0.001      0.000      0.003      0.004      0.001      0.000      0.000
    -0.027     -0.067     -0.124      0.053     -0.004     -0.059     -0.037     -0.021     -0.018     -0.026
     0.008      0.009      0.032     -0.428      0.001     -0.005     -0.003      0.004      0.003      0.004
     0.057      0.119      0.174     -0.596     -0.304      0.186      0.159      0.005      0.000      0.009
     0.069      0.158      0.220     -0.380     -0.182      0.869      0.181      0.008      0.004      0.012
     0.012     -0.010      0.075     -0.445      0.491      0.054      0.096      0.043      0.014      0.024
    -0.013      0.011      0.047     -0.391      0.458      0.004      0.053      0.341      0.038      0.017
    -0.015      0.018      0.042     -0.396      0.363      0.075      0.098      0.406      0.299      0.080

Derivative matrix of expected statistics X by parameters and
covariance/correlation matrix of X can be found using
summary(ans) within R, or by using the 'verbose' option in Siena07.
 
Total computation time 252.33 seconds.


-----------------------------------
New Analysis started.
Date and time: 01/06/2022 20:02:14
New results follow.
-----------------------------------

RSiena version 1.3.0.1 (02 Mai 21)


@1
Estimation by stochastic approximation algorithm.
=================================================

Current random number seed is 17.
Effects object used: effects 

NB. Request for conditional estimation has been over-ridden.

Estimation method: unconditional moment estimation
.

Time duration for simulations in each period is 1.0.
Changing composition.
Joiners/leavers option: 1
Standard errors are estimated with the likelihood ratio method.
Dolby method (regression on scores) is used.
Initial value of gain parameter is  0.6928203.
Reduction factor for gain parameter is  0.5000000.
Number of subphases in Phase 2 is 4.

Initial parameter values are 
  1. rate:  constant net rate (period 1)                    1.3198
  2. rate:  constant net rate (period 2)                    1.1534
  3. rate:  constant net rate (period 3)                    1.0095
  4. eval:  outdegree (density)                            -1.5450
  5. eval:  indegree - popularity (sqrt)                    0.0000
  6. eval:  outdegree-trunc(2)                              0.0000
  7. eval:  out-isolate                                     0.0000
  8. eval:  anti in-isolates                                0.0000
  9. eval:  indegree at least 2                             0.0000
 10. eval:  indegree at least 3                             0.0000
 11. eval:  devActLogVar ego                                0.0000
 12. eval:  comIntLogVar alter                              0.0000
 13. eval:  relActLogVar alter                              0.0000
 14. eval:  ageLogVar alter                                 0.0000


Observed values of target statistics are
  1. Amount of network change in period 1                               413.0000
  2. Amount of network change in period 2                               512.0000
  3. Amount of network change in period 3                               540.0000
  4. Number of ties                                                    1754.0000
  5. Sum of indegrees x sqrt(indegree)                                 5181.3115
  6. Sum of outdegrees trunc(2)                                        1639.0000
  7. Number of out-isolates                                            2091.0000
  8. Number of indegrees at least 1                                     519.0000
  9. Number of indegrees at least 2                                     316.0000
 10. Number of indegrees at least 3                                     177.0000
 11. Sum of outdegrees x devActLogVar                                  2419.3892
 12. Sum of indegrees x comIntLogVar                                   2516.7282
 13. Sum of indegrees x relActLogVar                                    685.1799
 14. Sum of indegrees x ageLogVar                                        58.9602

 14 parameters, 14 statistics

Estimation of derivatives by the LR method (type 1).


@2
End of stochastic approximation algorithm, phase 3.
---------------------------------------------------

Total of 4216 iterations.
Parameter estimates based on 1216 iterations,
convergence diagnostics, covariance and derivative matrices based on 3000 iterations.

Information for convergence diagnosis.
Averages, standard deviations, and t-ratios for deviations from targets:
  1.   0.3000  17.6574   0.0170 
  2.   0.0540  18.9251   0.0029 
  3.   0.5323  20.1467   0.0264 
  4.  -0.8277  29.8454  -0.0277 
  5.  -5.4364 173.1023  -0.0314 
  6.  -1.0017  28.2307  -0.0355 
  7.   1.0640  24.4322   0.0435 
  8.   0.2670   9.2409   0.0289 
  9.   0.1517   9.3543   0.0162 
 10.  -0.0503   7.0676  -0.0071 
 11.   0.7964  60.5872   0.0131 
 12.  -2.6326  83.9597  -0.0314 
 13.  -0.9636  30.7784  -0.0313 
 14.   0.0889  24.6501   0.0036 

Good convergence is indicated by the t-ratios being close to zero.

Overall maximum convergence ratio =  0.0764 .



@2
Estimation Results.
-------------------

Regular end of estimation algorithm.
Total of 4216 iteration steps.


@3
Estimates and standard errors
                             
 1. rate:  constant net rate (period 1)                            0.8105  (   0.0425)
 2. rate:  constant net rate (period 2)                            0.8358  (   0.0417)
 3. rate:  constant net rate (period 3)                            0.8136  (   0.0399)
 4. eval:  outdegree (density)                                    -5.5148  (   0.3651)
 5. eval:  indegree - popularity (sqrt)                            0.4483  (   0.0483)
 6. eval:  outdegree-trunc(2)                                     -1.4518  (   0.4455)
 7. eval:  out-isolate                                            -1.4919  (   0.6805)
 8. eval:  anti in-isolates                                       -0.4066  (   0.2136)
 9. eval:  indegree at least 2                                    -0.2998  (   0.1950)
10. eval:  indegree at least 3                                    -0.8133  (   0.2880)
11. eval:  devActLogVar ego                                        0.6015  (   0.0714)
12. eval:  comIntLogVar alter                                      0.0883  (   0.0470)
13. eval:  relActLogVar alter                                     -0.0225  (   0.0848)
14. eval:  ageLogVar alter                                        -0.1591  (   0.0811)


@3
Covariance matrices
                   
Covariance matrix of estimates (correlations below diagonal):
     0.002      0.000      0.000     -0.001      0.000      0.000     -0.002      0.000      0.000      0.000      0.000      0.000      0.000      0.000
     0.018      0.002      0.000     -0.001      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000
    -0.032     -0.017      0.002     -0.001      0.000      0.001      0.002      0.000      0.000      0.000      0.000      0.000      0.000      0.000
    -0.087     -0.073     -0.044      0.133     -0.006     -0.007      0.116     -0.025     -0.023     -0.025     -0.019      0.000     -0.001      0.003
     0.004      0.034      0.054     -0.337      0.002      0.000      0.001      0.003      0.003      0.002      0.000     -0.001     -0.001      0.000
    -0.003      0.019      0.074     -0.042     -0.002      0.198      0.243      0.006      0.004      0.013     -0.015     -0.002     -0.001      0.001
    -0.058     -0.012      0.084      0.465      0.033      0.800      0.463      0.005      0.002      0.015     -0.040     -0.004      0.000      0.002
    -0.017      0.016      0.043     -0.318      0.280      0.065      0.032      0.046      0.017      0.025      0.000      0.001      0.003     -0.002
     0.000     -0.011      0.023     -0.318      0.266      0.046      0.012      0.397      0.038      0.017      0.000      0.001      0.003     -0.001
     0.032      0.006      0.003     -0.237      0.155      0.101      0.077      0.410      0.310      0.083     -0.001      0.002      0.003     -0.001
     0.072      0.055      0.004     -0.720      0.007     -0.478     -0.833      0.014      0.035     -0.026      0.005      0.000      0.000      0.000
     0.011     -0.036     -0.038      0.004     -0.600     -0.114     -0.127      0.145      0.137      0.183      0.093      0.002      0.000     -0.001
     0.022      0.013      0.029     -0.020     -0.134     -0.016      0.006      0.182      0.161      0.104     -0.019     -0.032      0.007      0.002
    -0.015      0.014     -0.018      0.118     -0.076      0.017      0.028     -0.142     -0.089     -0.026     -0.050     -0.279      0.289      0.007

Derivative matrix of expected statistics X by parameters and
covariance/correlation matrix of X can be found using
summary(ans) within R, or by using the 'verbose' option in Siena07.
 
Total computation time 324.53 seconds.


-----------------------------------
New Analysis started.
Date and time: 01/06/2022 20:07:39
New results follow.
-----------------------------------

RSiena version 1.3.0.1 (02 Mai 21)


@1
Estimation by stochastic approximation algorithm.
=================================================

Current random number seed is 17.
Effects object used: effects 

NB. Request for conditional estimation has been over-ridden.

Estimation method: unconditional moment estimation
.

Time duration for simulations in each period is 1.0.
Changing composition.
Joiners/leavers option: 1
Standard errors are estimated with the likelihood ratio method.
Dolby method (regression on scores) is used.
Initial value of gain parameter is  0.6928203.
Reduction factor for gain parameter is  0.5000000.
Number of subphases in Phase 2 is 4.

Initial parameter values are 
  1. rate:  constant net rate (period 1)                    1.3198
  2. rate:  constant net rate (period 2)                    1.1534
  3. rate:  constant net rate (period 3)                    1.0095
  4. eval:  outdegree (density)                            -1.5450
  5. eval:  indegree - popularity (sqrt)                    0.0000
  6. eval:  outdegree-trunc(2)                              0.0000
  7. eval:  out-isolate                                     0.0000
  8. eval:  anti in-isolates                                0.0000
  9. eval:  indegree at least 2                             0.0000
 10. eval:  indegree at least 3                             0.0000
 11. eval:  depUpDyad                                       0.0000
 12. eval:  depDownDyad                                     0.0000
 13. eval:  devActLogVar ego                                0.0000
 14. eval:  comIntLogVar alter                              0.0000
 15. eval:  relActLogVar alter                              0.0000
 16. eval:  ageLogVar alter                                 0.0000
 17. eval:  depsUpLogVar alter                              0.0000
 18. eval:  depsDownLogVar alter                            0.0000


Observed values of target statistics are
  1. Amount of network change in period 1                               413.0000
  2. Amount of network change in period 2                               512.0000
  3. Amount of network change in period 3                               540.0000
  4. Number of ties                                                    1754.0000
  5. Sum of indegrees x sqrt(indegree)                                 5181.3115
  6. Sum of outdegrees trunc(2)                                        1639.0000
  7. Number of out-isolates                                            2091.0000
  8. Number of indegrees at least 1                                     519.0000
  9. Number of indegrees at least 2                                     316.0000
 10. Number of indegrees at least 3                                     177.0000
 11. Sum of ties x depUpDyad                                             65.8404
 12. Sum of ties x depDownDyad                                           99.7346
 13. Sum of outdegrees x devActLogVar                                  2419.3892
 14. Sum of indegrees x comIntLogVar                                   2516.7282
 15. Sum of indegrees x relActLogVar                                    685.1799
 16. Sum of indegrees x ageLogVar                                        58.9602
 17. Sum of indegrees x depsUpLogVar                                    335.6224
 18. Sum of indegrees x depsDownLogVar                                  -54.7451

 18 parameters, 18 statistics

Estimation of derivatives by the LR method (type 1).


@2
End of stochastic approximation algorithm, phase 3.
---------------------------------------------------

Total of 4096 iterations.
Parameter estimates based on 1096 iterations,
convergence diagnostics, covariance and derivative matrices based on 3000 iterations.

Information for convergence diagnosis.
Averages, standard deviations, and t-ratios for deviations from targets:
  1.   0.4373  17.6593   0.0248 
  2.   0.3537  19.3013   0.0183 
  3.  -0.1210  20.1904  -0.0060 
  4.  -0.4587  29.4210  -0.0156 
  5.  -1.0204 174.5181  -0.0058 
  6.  -0.3130  28.0370  -0.0112 
  7.  -0.0537  24.5180  -0.0022 
  8.  -0.1273   9.1649  -0.0139 
  9.  -0.1887   9.2590  -0.0204 
 10.  -0.0683   6.9587  -0.0098 
 11.  -0.0366   3.1017  -0.0118 
 12.  -0.1103   4.8178  -0.0229 
 13.  -1.6451  59.1740  -0.0278 
 14.  -0.2728  84.5912  -0.0032 
 15.  -0.2285  30.2752  -0.0075 
 16.   0.1502  24.9733   0.0060 
 17.  -0.2284  45.1819  -0.0051 
 18.   0.3992  35.6515   0.0112 

Good convergence is indicated by the t-ratios being close to zero.

Overall maximum convergence ratio =  0.0566 .



@2
Estimation Results.
-------------------

Regular end of estimation algorithm.
Total of 4096 iteration steps.


@3
Estimates and standard errors
                             
 1. rate:  constant net rate (period 1)                            0.8160  (   0.0424)
 2. rate:  constant net rate (period 2)                            0.8436  (   0.0412)
 3. rate:  constant net rate (period 3)                            0.8181  (   0.0410)
 4. eval:  outdegree (density)                                    -5.6688  (   0.3816)
 5. eval:  indegree - popularity (sqrt)                            0.4527  (   0.0497)
 6. eval:  outdegree-trunc(2)                                     -1.3681  (   0.4335)
 7. eval:  out-isolate                                            -1.5300  (   0.6879)
 8. eval:  anti in-isolates                                       -0.4125  (   0.2229)
 9. eval:  indegree at least 2                                    -0.3093  (   0.2031)
10. eval:  indegree at least 3                                    -0.8145  (   0.2812)
11. eval:  depUpDyad                                               1.9586  (   0.6108)
12. eval:  depDownDyad                                             1.2726  (   0.5080)
13. eval:  devActLogVar ego                                        0.5853  (   0.0732)
14. eval:  comIntLogVar alter                                      0.0963  (   0.0476)
15. eval:  relActLogVar alter                                     -0.0199  (   0.0891)
16. eval:  ageLogVar alter                                        -0.1592  (   0.0853)
17. eval:  depsUpLogVar alter                                     -0.0051  (   0.0461)
18. eval:  depsDownLogVar alter                                    0.0277  (   0.0584)


@3
Covariance matrices
                   
Covariance matrix of estimates (correlations below diagonal):
     0.002      0.000      0.000      0.000      0.000      0.000     -0.001      0.000      0.000      0.000      0.001      0.001      0.000      0.000      0.000      0.000      0.000      0.000
     0.033      0.002      0.000      0.000      0.000      0.001      0.001      0.000      0.000      0.000      0.001      0.001      0.000      0.000      0.000      0.000      0.000      0.000
    -0.029     -0.039      0.002     -0.001      0.000      0.001      0.002      0.000      0.000      0.000      0.002      0.001      0.000      0.000      0.000      0.000      0.000      0.000
    -0.015     -0.018     -0.082      0.146     -0.007     -0.005      0.133     -0.026     -0.024     -0.024      0.000     -0.014     -0.020      0.001     -0.002      0.002     -0.002     -0.001
    -0.014      0.031      0.064     -0.350      0.002     -0.001     -0.001      0.003      0.002      0.002      0.003      0.000      0.000     -0.001     -0.001      0.000      0.000      0.000
    -0.016      0.052      0.078     -0.030     -0.066      0.188      0.232      0.002      0.001      0.012      0.015      0.013     -0.015      0.001     -0.003     -0.001      0.001      0.003
    -0.036      0.052      0.059      0.505     -0.029      0.777      0.473      0.000     -0.005      0.017      0.042      0.007     -0.042      0.001     -0.005     -0.002     -0.001      0.004
    -0.035      0.038     -0.012     -0.309      0.301      0.025      0.003      0.050      0.018      0.023      0.002     -0.004      0.000      0.002      0.004     -0.003      0.001      0.002
    -0.028     -0.013      0.048     -0.309      0.223      0.011     -0.038      0.387      0.041      0.018      0.001     -0.001      0.001      0.002      0.003     -0.001      0.001      0.001
    -0.035      0.008      0.022     -0.226      0.161      0.101      0.087      0.369      0.316      0.079      0.006      0.001     -0.001      0.002      0.004      0.000      0.001      0.001
     0.027      0.043      0.062      0.001      0.085      0.057      0.100      0.016      0.008      0.035      0.373     -0.008     -0.005     -0.002      0.001     -0.001     -0.001      0.001
     0.055      0.071      0.058     -0.074      0.016      0.061      0.021     -0.039     -0.010      0.010     -0.026      0.258     -0.003      0.001      0.001      0.001      0.001     -0.001
     0.022     -0.027      0.030     -0.721      0.051     -0.464     -0.837      0.015      0.044     -0.030     -0.107     -0.074      0.005      0.000      0.000      0.000      0.000      0.000
    -0.018     -0.029     -0.009      0.066     -0.610      0.030      0.026      0.142      0.165      0.153     -0.066      0.026     -0.033      0.002      0.000     -0.001      0.000      0.000
     0.027      0.036     -0.045     -0.071     -0.171     -0.068     -0.079      0.213      0.186      0.144      0.024      0.014      0.008      0.023      0.008      0.002      0.000      0.000
     0.012      0.019     -0.005      0.051     -0.070     -0.020     -0.027     -0.134     -0.076     -0.008     -0.019      0.032      0.032     -0.257      0.258      0.007      0.000     -0.001
     0.013      0.027     -0.010     -0.092     -0.023      0.034     -0.030      0.114      0.101      0.062     -0.032      0.042      0.019      0.101      0.024     -0.117      0.002      0.000
    -0.016      0.019      0.021     -0.066      0.109      0.122      0.099      0.134      0.102      0.042      0.037     -0.037     -0.069      0.039      0.046     -0.147     -0.077      0.003

Derivative matrix of expected statistics X by parameters and
covariance/correlation matrix of X can be found using
summary(ans) within R, or by using the 'verbose' option in Siena07.
 
Total computation time 339.52 seconds.


-----------------------------------
New Analysis started.
Date and time: 01/06/2022 20:23:27
New results follow.
-----------------------------------

RSiena version 1.3.0.1 (02 Mai 21)


@1
Estimation by stochastic approximation algorithm.
=================================================

Current random number seed is 17.
Effects object used: effects.fix 

NB. Request for conditional estimation has been over-ridden.

Estimation method: unconditional moment estimation
.

Time duration for simulations in each period is 1.0.
Changing composition.
Joiners/leavers option: 1
Standard errors are estimated with the likelihood ratio method.
Dolby method (regression on scores) is used.
Initial value of gain parameter is  0.6928203.
Reduction factor for gain parameter is  0.5000000.
Number of subphases in Phase 2 is 4.

Initial parameter values are 
  1. rate:  constant net rate (period 1)                    1.3198
  2. rate:  constant net rate (period 2)                    1.1534
  3. rate:  constant net rate (period 3)                    1.0095
  4. rate:  outdegree effect on rate net                    0.0000
  5. eval:  outdegree (density)                            -1.5450
  6. eval:  indegree - popularity (sqrt)                    0.0000
  7. eval:  outdegree-trunc(2)                              0.0000
  8. eval:  out-isolate                                     0.0000
  9. eval:  anti in-isolates                                0.0000
 10. eval:  indegree at least 2                             0.0000
 11. eval:  indegree at least 3                             0.0000
 12. eval:  depUpDyad                                       0.0000
 13. eval:  depDownDyad                                     0.0000
 14. eval:  devActLogVar ego                                0.0000
 15. eval:  comIntLogVar alter                              0.0000
 16. eval:  relActLogVar alter                              0.0000
 17. eval:  ageLogVar alter                                 0.0000
 18. eval:  depsUpLogVar alter                              0.0000
 19. eval:  depsDownLogVar alter                            0.0000


Observed values of target statistics are
  1. Amount of network change in period 1                               413.0000
  2. Amount of network change in period 2                               512.0000
  3. Amount of network change in period 3                               540.0000
  4. Amount of change x outdegrees                                     1938.0000
  5. Number of ties                                                    1754.0000
  6. Sum of indegrees x sqrt(indegree)                                 5181.3115
  7. Sum of outdegrees trunc(2)                                        1639.0000
  8. Number of out-isolates                                            2091.0000
  9. Number of indegrees at least 1                                     519.0000
 10. Number of indegrees at least 2                                     316.0000
 11. Number of indegrees at least 3                                     177.0000
 12. Sum of ties x depUpDyad                                             65.8404
 13. Sum of ties x depDownDyad                                           99.7346
 14. Sum of outdegrees x devActLogVar                                  2419.3892
 15. Sum of indegrees x comIntLogVar                                   2516.7282
 16. Sum of indegrees x relActLogVar                                    685.1799
 17. Sum of indegrees x ageLogVar                                        58.9602
 18. Sum of indegrees x depsUpLogVar                                    335.6224
 19. Sum of indegrees x depsDownLogVar                                  -54.7451

 19 parameters, 19 statistics

Estimation of derivatives by the LR method (type 1).


@2
End of stochastic approximation algorithm, phase 3.
---------------------------------------------------

Total of 4178 iterations.
Parameter estimates based on 1178 iterations,
convergence diagnostics, covariance and derivative matrices based on 3000 iterations.

Information for convergence diagnosis.
Averages, standard deviations, and t-ratios for deviations from targets:
  1.    0.0910  16.7564   0.0054 
  2.   -0.1873  19.2047  -0.0098 
  3.    0.5013  20.0714   0.0250 
  4. -212.3663  51.4836  -4.1249 
  5.   -0.5477  30.2475  -0.0181 
  6.    1.7837 170.2765   0.0105 
  7.   -0.3007  28.3539  -0.0106 
  8.    0.1120  24.0609   0.0047 
  9.   -0.1777   9.3493  -0.0190 
 10.   -0.2380   9.4704  -0.0251 
 11.   -0.0030   7.1049  -0.0004 
 12.   -0.0976   3.1859  -0.0306 
 13.   -0.1819   4.7755  -0.0381 
 14.   -0.0047  64.7621  -0.0001 
 15.    1.7625  82.5707   0.0213 
 16.   -0.5929  30.2899  -0.0196 
 17.    1.0700  24.6249   0.0435 
 18.    0.8918  43.8546   0.0203 
 19.    0.6758  34.9749   0.0193 

Good convergence is indicated by the t-ratios being close to zero.

Overall maximum convergence ratio =  6.8914 .
One or more of the t-statistics are rather large.
Convergence of the algorithm is doubtful.



@2
Estimation Results.
-------------------

Regular end of estimation algorithm.
Total of 4178 iteration steps.


@3
Estimates and standard errors
                             
 1. rate:  constant net rate (period 1)                            0.6794  (   0.0418)
 2. rate:  constant net rate (period 2)                            0.7089  (   0.0394)
 3. rate:  constant net rate (period 3)                            0.6906  (   0.0388)
 4. rate:  outdegree effect on rate net                            0.1584  (   0.0330)
 5. eval:  outdegree (density)                                    -5.3842  (   0.3478)
 6. eval:  indegree - popularity (sqrt)                            0.4323  (   0.0482)
 7. eval:  outdegree-trunc(2)                                     -1.3282  (   0.3513)
 8. eval:  out-isolate                                            -1.5058  (   0.5986)
 9. eval:  anti in-isolates                                       -0.3622  (   0.2142)
10. eval:  indegree at least 2                                    -0.2623  (   0.1932)
11. eval:  indegree at least 3                                    -0.7374  (   0.2681)
12. eval:  depUpDyad                                               1.8698  (   0.5339)
13. eval:  depDownDyad                                             1.3829  (   0.4193)
14. eval:  devActLogVar ego                                        0.5423  (   0.0636)
15. eval:  comIntLogVar alter                                      0.0925  (   0.0442)
16. eval:  relActLogVar alter                                     -0.0198  (   0.0818)
17. eval:  ageLogVar alter                                        -0.1523  (   0.0818)
18. eval:  depsUpLogVar alter                                     -0.0018  (   0.0467)
19. eval:  depsDownLogVar alter                                    0.0392  (   0.0545)


@3
Covariance matrices
                   
Covariance matrix of estimates (correlations below diagonal):
     0.002      0.000      0.000     -0.001      0.000      0.000     -0.001     -0.002      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000
     0.208      0.002      0.000     -0.001      0.000      0.000      0.001      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000
     0.201      0.222      0.002     -0.001      0.000      0.000      0.001      0.001      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000
    -0.454     -0.467     -0.477      0.001     -0.001      0.000      0.000      0.001      0.000      0.000      0.000      0.000      0.001      0.000      0.000      0.000      0.000      0.000      0.000
    -0.013     -0.019     -0.029     -0.058      0.121     -0.007     -0.003      0.100     -0.027     -0.023     -0.029     -0.002     -0.016     -0.017      0.000     -0.001      0.003     -0.001     -0.002
     0.000      0.008      0.002      0.011     -0.429      0.002     -0.001     -0.001      0.004      0.003      0.003      0.002      0.000      0.000     -0.001     -0.001      0.000      0.000      0.000
    -0.055      0.071      0.095     -0.006     -0.028     -0.082      0.123      0.161      0.006      0.002      0.006     -0.013     -0.002     -0.007     -0.001      0.001      0.000      0.000      0.001
    -0.093      0.011      0.052      0.029      0.481     -0.044      0.766      0.358      0.007     -0.002      0.001     -0.012     -0.018     -0.029     -0.001      0.002      0.001      0.001      0.000
    -0.019      0.003      0.020      0.042     -0.357      0.343      0.083      0.057      0.046      0.019      0.024     -0.003      0.000      0.000      0.001      0.004     -0.003      0.001      0.002
    -0.026     -0.003     -0.042      0.044     -0.339      0.272      0.025     -0.018      0.451      0.037      0.016      0.001      0.000      0.000      0.001      0.003     -0.002      0.001      0.001
    -0.020      0.007      0.020      0.008     -0.311      0.214      0.062      0.009      0.423      0.309      0.072     -0.007      0.000      0.000      0.002      0.002     -0.001      0.001      0.001
     0.020     -0.012     -0.019      0.002     -0.012      0.063     -0.067     -0.036     -0.028      0.005     -0.047      0.285     -0.008      0.000     -0.002     -0.001      0.001      0.000     -0.001
     0.017      0.010      0.003      0.061     -0.111     -0.022     -0.013     -0.073      0.002      0.005      0.001     -0.037      0.176      0.000      0.001      0.001      0.001      0.000      0.000
     0.075      0.041      0.046     -0.056     -0.766      0.101     -0.331     -0.762      0.002      0.034      0.026     -0.012      0.014      0.004      0.000      0.000      0.000      0.000      0.000
     0.016      0.004      0.043     -0.017      0.026     -0.548     -0.034     -0.047      0.142      0.139      0.180     -0.066      0.077      0.011      0.002      0.000     -0.001      0.000      0.000
     0.021      0.034      0.041     -0.015     -0.042     -0.127      0.038      0.043      0.215      0.202      0.111     -0.027      0.038     -0.055     -0.004      0.007      0.002      0.000      0.001
    -0.025      0.005     -0.051      0.027      0.120     -0.104     -0.001      0.011     -0.200     -0.097     -0.058      0.019      0.028     -0.034     -0.273      0.228      0.007      0.000     -0.001
    -0.007      0.047      0.008     -0.007     -0.063      0.068      0.030      0.022      0.141      0.118      0.100      0.001     -0.004     -0.042      0.065     -0.044     -0.120      0.002      0.000
     0.003     -0.010     -0.037      0.019     -0.083      0.105      0.030      0.008      0.181      0.135      0.065     -0.031     -0.007     -0.043      0.078      0.125     -0.198     -0.043      0.003

Derivative matrix of expected statistics X by parameters and
covariance/correlation matrix of X can be found using
summary(ans) within R, or by using the 'verbose' option in Siena07.
 
Total computation time 544.62 seconds.


-----------------------------------
New Analysis started.
Date and time: 01/06/2022 20:37:07
New results follow.
-----------------------------------

RSiena version 1.3.0.1 (02 Mai 21)


@1
Estimation by stochastic approximation algorithm.
=================================================

Current random number seed is 17.
Effects object used: effects.fix 

NB. Request for conditional estimation has been over-ridden.

Estimation method: unconditional moment estimation
.

Time duration for simulations in each period is 1.0.
Changing composition.
Joiners/leavers option: 1
Standard errors are estimated with the likelihood ratio method.
Dolby method (regression on scores) is used.
Initial value of gain parameter is  0.6928203.
Reduction factor for gain parameter is  0.5000000.
Number of subphases in Phase 2 is 4.

Initial parameter values are 
  1. rate:  constant net rate (period 1)                    1.3198
  2. rate:  constant net rate (period 2)                    1.1534
  3. rate:  constant net rate (period 3)                    1.0095
  4. rate:  effect devActLogVar on rate                     0.0000
  5. eval:  outdegree (density)                            -1.5450
  6. eval:  indegree - popularity (sqrt)                    0.0000
  7. eval:  outdegree-trunc(2)                              0.0000
  8. eval:  out-isolate                                     0.0000
  9. eval:  anti in-isolates                                0.0000
 10. eval:  indegree at least 2                             0.0000
 11. eval:  indegree at least 3                             0.0000
 12. eval:  depUpDyad                                       0.0000
 13. eval:  depDownDyad                                     0.0000
 14. eval:  devActLogVar ego                                0.0000
 15. eval:  comIntLogVar alter                              0.0000
 16. eval:  relActLogVar alter                              0.0000
 17. eval:  ageLogVar alter                                 0.0000
 18. eval:  depsUpLogVar alter                              0.0000
 19. eval:  depsDownLogVar alter                            0.0000


Observed values of target statistics are
  1. Amount of network change in period 1                               413.0000
  2. Amount of network change in period 2                               512.0000
  3. Amount of network change in period 3                               540.0000
  4. Amount of change x devActLogVar                                   1347.7839
  5. Number of ties                                                    1754.0000
  6. Sum of indegrees x sqrt(indegree)                                 5181.3115
  7. Sum of outdegrees trunc(2)                                        1639.0000
  8. Number of out-isolates                                            2091.0000
  9. Number of indegrees at least 1                                     519.0000
 10. Number of indegrees at least 2                                     316.0000
 11. Number of indegrees at least 3                                     177.0000
 12. Sum of ties x depUpDyad                                             65.8404
 13. Sum of ties x depDownDyad                                           99.7346
 14. Sum of outdegrees x devActLogVar                                  2419.3892
 15. Sum of indegrees x comIntLogVar                                   2516.7282
 16. Sum of indegrees x relActLogVar                                    685.1799
 17. Sum of indegrees x ageLogVar                                        58.9602
 18. Sum of indegrees x depsUpLogVar                                    335.6224
 19. Sum of indegrees x depsDownLogVar                                  -54.7451

 19 parameters, 19 statistics

Estimation of derivatives by the LR method (type 1).


@2
End of stochastic approximation algorithm, phase 3.
---------------------------------------------------

Total of 4068 iterations.
Parameter estimates based on 1068 iterations,
convergence diagnostics, covariance and derivative matrices based on 3000 iterations.

Information for convergence diagnosis.
Averages, standard deviations, and t-ratios for deviations from targets:
  1.  -0.3307  17.6895  -0.0187 
  2.  -0.3180  19.2436  -0.0165 
  3.   0.2847  19.9149   0.0143 
  4.  -0.4461  67.2319  -0.0066 
  5.  -0.1887  29.6616  -0.0064 
  6.   1.7799 172.2667   0.0103 
  7.  -0.2510  27.8918  -0.0090 
  8.   0.0440  24.1730   0.0018 
  9.  -0.3513   9.4127  -0.0373 
 10.  -0.0367   9.3006  -0.0039 
 11.   0.0417   7.1058   0.0059 
 12.   0.1330   3.0973   0.0429 
 13.  -0.0953   4.7049  -0.0203 
 14.   0.7171  61.4774   0.0117 
 15.  -0.2910  85.4010  -0.0034 
 16.  -0.1808  30.9705  -0.0058 
 17.   0.1744  25.1203   0.0069 
 18.  -0.3066  43.8601  -0.0070 
 19.   0.9432  36.2645   0.0260 

Good convergence is indicated by the t-ratios being close to zero.

Overall maximum convergence ratio =  0.0945 .



@2
Estimation Results.
-------------------

Regular end of estimation algorithm.
Total of 4068 iteration steps.


@3
Estimates and standard errors
                             
 1. rate:  constant net rate (period 1)                            0.7616  (   0.0425)
 2. rate:  constant net rate (period 2)                            0.7960  (   0.0415)
 3. rate:  constant net rate (period 3)                            0.7801  (   0.0417)
 4. rate:  effect devActLogVar on rate                             0.0622  (   0.0188)
 5. eval:  outdegree (density)                                    -5.7631  (   0.3878)
 6. eval:  indegree - popularity (sqrt)                            0.4524  (   0.0504)
 7. eval:  outdegree-trunc(2)                                     -1.3030  (   0.4088)
 8. eval:  out-isolate                                            -1.5535  (   0.6562)
 9. eval:  anti in-isolates                                       -0.3891  (   0.2194)
10. eval:  indegree at least 2                                    -0.2874  (   0.2072)
11. eval:  indegree at least 3                                    -0.7673  (   0.2669)
12. eval:  depUpDyad                                               2.1061  (   0.5530)
13. eval:  depDownDyad                                             1.4629  (   0.4671)
14. eval:  devActLogVar ego                                        0.5937  (   0.0728)
15. eval:  comIntLogVar alter                                      0.0789  (   0.0455)
16. eval:  relActLogVar alter                                     -0.0052  (   0.0852)
17. eval:  ageLogVar alter                                        -0.1612  (   0.0797)
18. eval:  depsUpLogVar alter                                     -0.0071  (   0.0455)
19. eval:  depsDownLogVar alter                                    0.0458  (   0.0561)


@3
Covariance matrices
                   
Covariance matrix of estimates (correlations below diagonal):
     0.002      0.000      0.000      0.000      0.000      0.000      0.001      0.003      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000
     0.134      0.002      0.000      0.000     -0.001      0.000      0.001      0.002      0.000      0.000      0.000     -0.001      0.001      0.000      0.000      0.000      0.000      0.000      0.000
     0.150      0.141      0.002      0.000     -0.001      0.000      0.003      0.004      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000
    -0.370     -0.364     -0.332      0.000     -0.001      0.000     -0.001     -0.003      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000
     0.015     -0.051     -0.059     -0.071      0.150     -0.008     -0.004      0.132     -0.025     -0.024     -0.024      0.002     -0.029     -0.021      0.001     -0.002      0.001     -0.001     -0.002
     0.031      0.018      0.051     -0.058     -0.388      0.003     -0.001     -0.001      0.004      0.003      0.003      0.002      0.001      0.000     -0.001     -0.001      0.000      0.000      0.000
     0.085      0.076      0.176     -0.164     -0.025     -0.042      0.167      0.205      0.008      0.008      0.006     -0.016     -0.004     -0.013      0.000     -0.001      0.000     -0.001      0.001
     0.109      0.062      0.159     -0.249      0.520     -0.018      0.765      0.431      0.010      0.008      0.007     -0.010     -0.031     -0.040      0.001     -0.002     -0.002     -0.001      0.001
    -0.007      0.026      0.010      0.017     -0.297      0.321      0.089      0.071      0.048      0.021      0.026     -0.003      0.000      0.000      0.002      0.004     -0.003      0.002      0.002
     0.045      0.031      0.023     -0.059     -0.296      0.267      0.093      0.056      0.454      0.043      0.019     -0.007      0.002      0.000      0.002      0.004     -0.001      0.001      0.001
     0.015     -0.016      0.010      0.021     -0.232      0.211      0.057      0.040      0.445      0.338      0.071     -0.004     -0.004      0.000      0.002      0.002     -0.002      0.001      0.001
     0.001     -0.040      0.002      0.048      0.010      0.080     -0.071     -0.028     -0.026     -0.058     -0.030      0.306     -0.025     -0.001     -0.002      0.000      0.000     -0.001      0.001
     0.017      0.045      0.013      0.050     -0.160      0.030     -0.023     -0.102      0.002      0.026     -0.036     -0.097      0.218      0.002      0.001      0.001      0.001      0.001      0.000
    -0.045      0.019     -0.002      0.129     -0.756      0.065     -0.429     -0.834     -0.027     -0.013     -0.010     -0.021      0.055      0.005      0.000      0.000      0.000      0.000      0.000
     0.007      0.036      0.008     -0.028      0.083     -0.575      0.018      0.034      0.161      0.162      0.185     -0.097      0.064     -0.050      0.002      0.000     -0.001      0.000      0.000
    -0.037     -0.005     -0.003      0.071     -0.069     -0.163     -0.015     -0.036      0.236      0.209      0.073      0.010      0.014      0.004      0.035      0.007      0.002      0.000      0.001
     0.016      0.021      0.042      0.009      0.036     -0.103      0.002     -0.030     -0.179     -0.067     -0.087      0.009      0.031      0.054     -0.264      0.236      0.006      0.000     -0.001
     0.000     -0.018     -0.006      0.048     -0.060      0.025     -0.032     -0.034      0.181      0.127      0.074     -0.032      0.051     -0.005      0.096     -0.008     -0.116      0.002      0.000
    -0.013     -0.019     -0.038      0.033     -0.081      0.103      0.035      0.017      0.149      0.105      0.044      0.019      0.018     -0.023      0.052      0.153     -0.156     -0.088      0.003

Derivative matrix of expected statistics X by parameters and
covariance/correlation matrix of X can be found using
summary(ans) within R, or by using the 'verbose' option in Siena07.
 
Total computation time 307.65 seconds.


-----------------------------------
New Analysis started.
Date and time: 01/06/2022 20:46:10
New results follow.
-----------------------------------

RSiena version 1.3.0.1 (02 Mai 21)


@1
Estimation by stochastic approximation algorithm.
=================================================

Current random number seed is 17.
Effects object used: effects.fix 

NB. Request for conditional estimation has been over-ridden.

Estimation method: unconditional moment estimation
.

Time duration for simulations in each period is 1.0.
Changing composition.
Joiners/leavers option: 1
Standard errors are estimated with the likelihood ratio method.
Dolby method (regression on scores) is used.
Initial value of gain parameter is  0.6928203.
Reduction factor for gain parameter is  0.5000000.
Number of subphases in Phase 2 is 4.

Initial parameter values are 
  1. rate:  constant net rate (period 1)                    1.3198
  2. rate:  constant net rate (period 2)                    1.1534
  3. rate:  constant net rate (period 3)                    1.0095
  4. eval:  outdegree (density)                            -1.5450
  5. eval:  indegree - popularity (sqrt)                    0.0000
  6. eval:  outdegree - activity                            0.0000
  7. eval:  outdegree-trunc(2)                              0.0000
  8. eval:  out-isolate                                     0.0000
  9. eval:  anti in-isolates                                0.0000
 10. eval:  indegree at least 2                             0.0000
 11. eval:  indegree at least 3                             0.0000
 12. eval:  depUpDyad                                       0.0000
 13. eval:  depDownDyad                                     0.0000
 14. eval:  devActLogVar ego                                0.0000
 15. eval:  comIntLogVar alter                              0.0000
 16. eval:  relActLogVar alter                              0.0000
 17. eval:  ageLogVar alter                                 0.0000
 18. eval:  depsUpLogVar alter                              0.0000
 19. eval:  depsDownLogVar alter                            0.0000


Observed values of target statistics are
  1. Amount of network change in period 1                               413.0000
  2. Amount of network change in period 2                               512.0000
  3. Amount of network change in period 3                               540.0000
  4. Number of ties                                                    1754.0000
  5. Sum of indegrees x sqrt(indegree)                                 5181.3115
  6. Sum of squared outdegrees                                         2908.0000
  7. Sum of outdegrees trunc(2)                                        1639.0000
  8. Number of out-isolates                                            2091.0000
  9. Number of indegrees at least 1                                     519.0000
 10. Number of indegrees at least 2                                     316.0000
 11. Number of indegrees at least 3                                     177.0000
 12. Sum of ties x depUpDyad                                             65.8404
 13. Sum of ties x depDownDyad                                           99.7346
 14. Sum of outdegrees x devActLogVar                                  2419.3892
 15. Sum of indegrees x comIntLogVar                                   2516.7282
 16. Sum of indegrees x relActLogVar                                    685.1799
 17. Sum of indegrees x ageLogVar                                        58.9602
 18. Sum of indegrees x depsUpLogVar                                    335.6224
 19. Sum of indegrees x depsDownLogVar                                  -54.7451

 19 parameters, 19 statistics

Estimation of derivatives by the LR method (type 1).


@2
End of stochastic approximation algorithm, phase 3.
---------------------------------------------------

Total of 4146 iterations.
Parameter estimates based on 1146 iterations,
convergence diagnostics, covariance and derivative matrices based on 3000 iterations.

Information for convergence diagnosis.
Averages, standard deviations, and t-ratios for deviations from targets:
  1.  -0.1633  17.5370  -0.0093 
  2.   0.2460  19.7906   0.0124 
  3.   0.5467  19.8408   0.0276 
  4.  -1.0967  29.2432  -0.0375 
  5.  -1.6088 174.5453  -0.0092 
  6.  -0.8887  77.3990  -0.0115 
  7.  -0.9917  27.5985  -0.0359 
  8.   0.9970  23.6960   0.0421 
  9.  -0.3820   9.3311  -0.0409 
 10.  -0.2700   9.0924  -0.0297 
 11.   0.0653   6.9095   0.0095 
 12.  -0.0462   3.0289  -0.0153 
 13.   0.0112   4.7051   0.0024 
 14.  -1.3360  60.2345  -0.0222 
 15.  -0.8444  84.8571  -0.0100 
 16.  -0.9813  31.4088  -0.0312 
 17.   0.0946  24.8901   0.0038 
 18.  -2.0743  44.0517  -0.0471 
 19.   0.4053  35.1059   0.0115 

Good convergence is indicated by the t-ratios being close to zero.

Overall maximum convergence ratio =  0.1057 .



@2
Estimation Results.
-------------------

Regular end of estimation algorithm.
Total of 4146 iteration steps.


@3
Estimates and standard errors
                             
 1. rate:  constant net rate (period 1)                            0.8160  (   0.0429)
 2. rate:  constant net rate (period 2)                            0.8432  (   0.0403)
 3. rate:  constant net rate (period 3)                            0.8194  (   0.0416)
 4. eval:  outdegree (density)                                    -6.2770  (   0.6240)
 5. eval:  indegree - popularity (sqrt)                            0.4516  (   0.0494)
 6. eval:  outdegree - activity                                    0.0811  (   0.0665)
 7. eval:  outdegree-trunc(2)                                     -0.9091  (   0.6327)
 8. eval:  out-isolate                                            -1.5896  (   0.6384)
 9. eval:  anti in-isolates                                       -0.4217  (   0.2215)
10. eval:  indegree at least 2                                    -0.3157  (   0.2021)
11. eval:  indegree at least 3                                    -0.8167  (   0.2749)
12. eval:  depUpDyad                                               1.9674  (   0.5940)
13. eval:  depDownDyad                                             1.3189  (   0.5013)
14. eval:  devActLogVar ego                                        0.5765  (   0.0732)
15. eval:  comIntLogVar alter                                      0.0954  (   0.0471)
16. eval:  relActLogVar alter                                     -0.0185  (   0.0878)
17. eval:  ageLogVar alter                                        -0.1598  (   0.0831)
18. eval:  depsUpLogVar alter                                     -0.0058  (   0.0453)
19. eval:  depsDownLogVar alter                                    0.0266  (   0.0567)


@3
Covariance matrices
                   
Covariance matrix of estimates (correlations below diagonal):
     0.002      0.000      0.000     -0.001      0.000      0.000      0.000     -0.001      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000
    -0.004      0.002      0.000     -0.002      0.000      0.000      0.002      0.001      0.000      0.000      0.000      0.001      0.000      0.000      0.000      0.000      0.000      0.000      0.000
    -0.059      0.019      0.002     -0.002      0.000      0.000      0.003      0.002      0.000      0.000      0.001      0.001      0.002      0.000      0.000      0.000      0.000      0.000      0.000
    -0.027     -0.086     -0.093      0.389     -0.007     -0.032     -0.250      0.075     -0.017     -0.017     -0.023     -0.009     -0.032     -0.011      0.002     -0.001      0.005     -0.001     -0.001
    -0.013      0.013      0.069     -0.226      0.002      0.000     -0.001     -0.001      0.004      0.002      0.002      0.002     -0.002      0.000     -0.001     -0.001     -0.001      0.000      0.000
     0.017      0.055      0.047     -0.782     -0.028      0.004      0.032      0.006     -0.001      0.000     -0.001      0.002      0.003     -0.001      0.000      0.000      0.000      0.000      0.000
    -0.002      0.097      0.097     -0.634     -0.044      0.764      0.400      0.237     -0.011     -0.001     -0.002      0.020      0.027     -0.020     -0.002     -0.002     -0.004      0.001      0.001
    -0.046      0.048      0.071      0.187     -0.036      0.145      0.587      0.408     -0.004      0.004     -0.003      0.031     -0.003     -0.038     -0.001     -0.002     -0.003      0.001      0.002
    -0.027     -0.013      0.037     -0.120      0.340     -0.096     -0.077     -0.028      0.049      0.019      0.023     -0.002     -0.004      0.001      0.001      0.005     -0.003      0.001      0.002
    -0.003     -0.022      0.033     -0.138      0.244     -0.034     -0.004      0.027      0.415      0.041      0.019      0.001     -0.006      0.000      0.001      0.004     -0.001      0.001      0.001
     0.015     -0.006      0.049     -0.135      0.166     -0.041     -0.012     -0.020      0.385      0.338      0.076     -0.008     -0.005      0.001      0.002      0.003     -0.001      0.001      0.000
     0.000      0.028      0.026     -0.024      0.077      0.048      0.053      0.082     -0.015      0.006     -0.050      0.353     -0.019     -0.005     -0.002      0.000      0.000     -0.002      0.001
     0.022      0.004      0.099     -0.103     -0.081      0.080      0.085     -0.009     -0.039     -0.061     -0.037     -0.063      0.251     -0.002      0.002      0.002      0.002      0.000     -0.001
     0.022      0.023      0.012     -0.244      0.093     -0.250     -0.433     -0.814      0.051     -0.002      0.061     -0.111     -0.063      0.005      0.000      0.000      0.000      0.000      0.000
     0.044     -0.038     -0.069      0.071     -0.587     -0.031     -0.056     -0.031      0.115      0.156      0.178     -0.068      0.088     -0.011      0.002      0.000     -0.001      0.000      0.000
    -0.029      0.014      0.012     -0.026     -0.141      0.003     -0.030     -0.028      0.249      0.199      0.142      0.006      0.055     -0.040      0.003      0.008      0.002      0.000      0.000
    -0.014     -0.029      0.028      0.101     -0.140     -0.053     -0.072     -0.051     -0.140     -0.074     -0.025     -0.007      0.042      0.022     -0.223      0.213      0.007      0.000     -0.001
     0.016      0.042      0.040     -0.049      0.047      0.019      0.027      0.018      0.127      0.107      0.087     -0.087      0.008     -0.020      0.043     -0.005     -0.054      0.002      0.000
    -0.010      0.001      0.019     -0.029      0.120     -0.010      0.023      0.047      0.138      0.096      0.017      0.017     -0.035     -0.037      0.033      0.086     -0.184     -0.098      0.003

Derivative matrix of expected statistics X by parameters and
covariance/correlation matrix of X can be found using
summary(ans) within R, or by using the 'verbose' option in Siena07.
 
Total computation time 346.21 seconds.


-----------------------------------
New Analysis started.
Date and time: 01/06/2022 21:16:38
New results follow.
-----------------------------------

RSiena version 1.3.0.1 (02 Mai 21)


@1
Estimation by stochastic approximation algorithm.
=================================================

Current random number seed is 17.
Effects object used: effects.fix 

NB. Request for conditional estimation has been over-ridden.

Estimation method: unconditional moment estimation
.

Time duration for simulations in each period is 1.0.
Changing composition.
Joiners/leavers option: 1
Standard errors are estimated with the likelihood ratio method.
Dolby method (regression on scores) is used.
Initial value of gain parameter is  0.6928203.
Reduction factor for gain parameter is  0.5000000.
Number of subphases in Phase 2 is 4.

Initial parameter values are 
  1. rate:  constant net rate (period 1)                    1.3198
  2. rate:  constant net rate (period 2)                    1.1534
  3. rate:  constant net rate (period 3)                    1.0095
  4. rate:  effect devActLogVar on rate                     0.0000
  5. eval:  outdegree (density)                            -1.5450
  6. eval:  indegree - popularity (sqrt)                    0.0000
  7. eval:  outdegree-trunc(2)                              0.0000
  8. eval:  indegree at least 3                             0.0000
  9. eval:  depUpDyad                                       0.0000
 10. eval:  depDownDyad                                     0.0000
 11. eval:  devActLogVar ego                                0.0000
 12. eval:  comIntLogVar alter                              0.0000
 13. eval:  relActLogVar alter                              0.0000
 14. eval:  ageLogVar alter                                 0.0000
 15. eval:  depsUpLogVar alter                              0.0000
 16. eval:  depsDownLogVar alter                            0.0000


Observed values of target statistics are
  1. Amount of network change in period 1                               413.0000
  2. Amount of network change in period 2                               512.0000
  3. Amount of network change in period 3                               540.0000
  4. Amount of change x devActLogVar                                   1347.7839
  5. Number of ties                                                    1754.0000
  6. Sum of indegrees x sqrt(indegree)                                 5181.3115
  7. Sum of outdegrees trunc(2)                                        1639.0000
  8. Number of indegrees at least 3                                     177.0000
  9. Sum of ties x depUpDyad                                             65.8404
 10. Sum of ties x depDownDyad                                           99.7346
 11. Sum of outdegrees x devActLogVar                                  2419.3892
 12. Sum of indegrees x comIntLogVar                                   2516.7282
 13. Sum of indegrees x relActLogVar                                    685.1799
 14. Sum of indegrees x ageLogVar                                        58.9602
 15. Sum of indegrees x depsUpLogVar                                    335.6224
 16. Sum of indegrees x depsDownLogVar                                  -54.7451

 16 parameters, 16 statistics

Estimation of derivatives by the LR method (type 1).


@2
End of stochastic approximation algorithm, phase 3.
---------------------------------------------------

Total of 4166 iterations.
Parameter estimates based on 1166 iterations,
convergence diagnostics, covariance and derivative matrices based on 3000 iterations.

Information for convergence diagnosis.
Averages, standard deviations, and t-ratios for deviations from targets:
  1.   0.6537  17.2850   0.0378 
  2.   0.4310  18.7735   0.0230 
  3.   0.1127  19.7249   0.0057 
  4.   0.2929  65.8578   0.0044 
  5.   0.0067  30.8854   0.0002 
  6.   3.3186 178.8126   0.0186 
  7.  -0.2283  28.8578  -0.0079 
  8.  -0.0680   7.1884  -0.0095 
  9.   0.0583   3.0924   0.0189 
 10.  -0.0283   4.7216  -0.0060 
 11.   0.0594  64.0539   0.0009 
 12.   0.1270  85.0348   0.0015 
 13.   0.0430  31.0589   0.0014 
 14.   0.3497  23.7624   0.0147 
 15.  -0.3214  45.4902  -0.0071 
 16.  -0.6681  35.7212  -0.0187 

Good convergence is indicated by the t-ratios being close to zero.

Overall maximum convergence ratio =  0.0845 .



@2
Estimation Results.
-------------------

Regular end of estimation algorithm.
Total of 4166 iteration steps.


@3
Estimates and standard errors
                             
 1. rate:  constant net rate (period 1)                            0.7758  (   0.0426)
 2. rate:  constant net rate (period 2)                            0.8140  (   0.0422)
 3. rate:  constant net rate (period 3)                            0.7989  (   0.0417)
 4. rate:  effect devActLogVar on rate                             0.0516  (   0.0176)
 5. eval:  outdegree (density)                                    -5.6225  (   0.2771)
 6. eval:  indegree - popularity (sqrt)                            0.4742  (   0.0454)
 7. eval:  outdegree-trunc(2)                                     -0.4500  (   0.2460)
 8. eval:  indegree at least 3                                    -0.4858  (   0.2427)
 9. eval:  depUpDyad                                               1.9992  (   0.5438)
10. eval:  depDownDyad                                             1.3691  (   0.4554)
11. eval:  devActLogVar ego                                        0.4633  (   0.0369)
12. eval:  comIntLogVar alter                                      0.0984  (   0.0466)
13. eval:  relActLogVar alter                                      0.0343  (   0.0825)
14. eval:  ageLogVar alter                                        -0.1753  (   0.0761)
15. eval:  depsUpLogVar alter                                      0.0063  (   0.0460)
16. eval:  depsDownLogVar alter                                    0.0606  (   0.0533)


@3
Covariance matrices
                   
Covariance matrix of estimates (correlations below diagonal):
     0.002      0.000      0.000      0.000     -0.001      0.000      0.000      0.000     -0.001     -0.001      0.000      0.000      0.000      0.000      0.000      0.000
     0.097      0.002      0.000      0.000     -0.002      0.000      0.001      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000
     0.101      0.126      0.002      0.000     -0.001      0.000      0.000      0.000      0.000     -0.001      0.000      0.000      0.000      0.000      0.000      0.000
    -0.305     -0.342     -0.359      0.000      0.001      0.000      0.000      0.000      0.000      0.001      0.000      0.000      0.000      0.000      0.000      0.000
    -0.082     -0.131     -0.110      0.106      0.077     -0.004     -0.057     -0.010     -0.002     -0.013     -0.007      0.002      0.001      0.000      0.000      0.000
     0.070      0.069      0.077     -0.082     -0.338      0.002     -0.001      0.000      0.002     -0.002      0.000     -0.001     -0.001      0.000      0.000      0.000
     0.041      0.070      0.021     -0.001     -0.833     -0.063      0.061      0.001     -0.009      0.010      0.005     -0.001      0.000      0.001      0.000      0.000
     0.017      0.030     -0.017      0.007     -0.142      0.012      0.021      0.059     -0.002     -0.001      0.000      0.001      0.002      0.000      0.000      0.000
    -0.024     -0.005     -0.016      0.046     -0.015      0.074     -0.064     -0.016      0.296     -0.003     -0.002     -0.001      0.000     -0.001     -0.001      0.000
    -0.031     -0.011     -0.030      0.090     -0.106     -0.082      0.093     -0.007     -0.013      0.207     -0.001      0.003      0.002      0.001      0.000      0.000
     0.072      0.113      0.181     -0.154     -0.698      0.083      0.559      0.040     -0.085     -0.086      0.001      0.000      0.000      0.000      0.000      0.000
    -0.024      0.010     -0.040     -0.036      0.165     -0.693     -0.046      0.118     -0.030      0.125     -0.027      0.002      0.000     -0.001      0.000      0.000
    -0.015     -0.047      0.004      0.044      0.051     -0.241     -0.004      0.104     -0.001      0.043     -0.098     -0.042      0.007      0.002      0.000      0.000
     0.020     -0.037      0.046      0.024      0.022     -0.019      0.041      0.001     -0.015      0.033     -0.025     -0.288      0.294      0.006      0.000     -0.001
     0.013      0.016     -0.006     -0.020     -0.001      0.009     -0.039      0.044     -0.031      0.016     -0.031      0.043     -0.055     -0.051      0.002      0.000
    -0.048     -0.028     -0.001      0.064     -0.022      0.046     -0.013     -0.017      0.015     -0.002     -0.015      0.048      0.100     -0.158     -0.080      0.003

Derivative matrix of expected statistics X by parameters and
covariance/correlation matrix of X can be found using
summary(ans) within R, or by using the 'verbose' option in Siena07.
 
Total computation time 306.33 seconds.


-----------------------------------
New Analysis started.
Date and time: 01/06/2022 21:37:20
New results follow.
-----------------------------------

RSiena version 1.3.0.1 (02 Mai 21)


@1
Estimation by stochastic approximation algorithm.
=================================================

Current random number seed is 17.
Effects object used: effects.fix 

NB. Request for conditional estimation has been over-ridden.

Estimation method: unconditional moment estimation
.

Time duration for simulations in each period is 1.0.
Changing composition.
Joiners/leavers option: 1
Standard errors are estimated with the likelihood ratio method.
Dolby method (regression on scores) is used.
Initial value of gain parameter is  0.6928203.
Reduction factor for gain parameter is  0.5000000.
Number of subphases in Phase 2 is 4.

Initial parameter values are 
  1. rate:  constant net rate (period 1)                    1.3198
  2. rate:  constant net rate (period 2)                    1.1534
  3. rate:  constant net rate (period 3)                    1.0095
  4. rate:  effect devActLogVar on rate                     0.0000
  5. eval:  outdegree (density)                            -1.5450
  6. eval:  indegree - popularity (sqrt)                    0.0000
  7. eval:  indegree at least 3                             0.0000
  8. eval:  depUpDyad                                       0.0000
  9. eval:  depDownDyad                                     0.0000
 10. eval:  devActLogVar ego                                0.0000
 11. eval:  comIntLogVar alter                              0.0000
 12. eval:  relActLogVar alter                              0.0000
 13. eval:  ageLogVar alter                                 0.0000
 14. eval:  depsUpLogVar alter                              0.0000
 15. eval:  depsDownLogVar alter                            0.0000


Observed values of target statistics are
  1. Amount of network change in period 1                               413.0000
  2. Amount of network change in period 2                               512.0000
  3. Amount of network change in period 3                               540.0000
  4. Amount of change x devActLogVar                                   1347.7839
  5. Number of ties                                                    1754.0000
  6. Sum of indegrees x sqrt(indegree)                                 5181.3115
  7. Number of indegrees at least 3                                     177.0000
  8. Sum of ties x depUpDyad                                             65.8404
  9. Sum of ties x depDownDyad                                           99.7346
 10. Sum of outdegrees x devActLogVar                                  2419.3892
 11. Sum of indegrees x comIntLogVar                                   2516.7282
 12. Sum of indegrees x relActLogVar                                    685.1799
 13. Sum of indegrees x ageLogVar                                        58.9602
 14. Sum of indegrees x depsUpLogVar                                    335.6224
 15. Sum of indegrees x depsDownLogVar                                  -54.7451

 15 parameters, 15 statistics

Estimation of derivatives by the LR method (type 1).


@2
End of stochastic approximation algorithm, phase 3.
---------------------------------------------------

Total of 4166 iterations.
Parameter estimates based on 1166 iterations,
convergence diagnostics, covariance and derivative matrices based on 3000 iterations.

Information for convergence diagnosis.
Averages, standard deviations, and t-ratios for deviations from targets:
  1.   0.5987  17.6836   0.0339 
  2.  -0.4763  19.2697  -0.0247 
  3.   0.5540  20.4024   0.0272 
  4.   1.2077  65.4737   0.0184 
  5.  -1.4283  30.5666  -0.0467 
  6.  -4.5173 177.4927  -0.0255 
  7.  -0.1047   7.2913  -0.0144 
  8.  -0.1729   3.1603  -0.0547 
  9.   0.1879   4.7578   0.0395 
 10.  -2.7965  62.2710  -0.0449 
 11.  -2.1194  86.6123  -0.0245 
 12.  -0.1441  30.6838  -0.0047 
 13.  -0.4977  24.3706  -0.0204 
 14.  -0.1997  43.6195  -0.0046 
 15.  -0.0847  35.9810  -0.0024 

Good convergence is indicated by the t-ratios being close to zero.

Overall maximum convergence ratio =  0.1084 .



@2
Estimation Results.
-------------------

Regular end of estimation algorithm.
Total of 4166 iteration steps.


@3
Estimates and standard errors
                             
 1. rate:  constant net rate (period 1)                            0.7762  (   0.0423)
 2. rate:  constant net rate (period 2)                            0.8142  (   0.0419)
 3. rate:  constant net rate (period 3)                            0.8034  (   0.0420)
 4. rate:  effect devActLogVar on rate                             0.0516  (   0.0183)
 5. eval:  outdegree (density)                                    -6.0466  (   0.1513)
 6. eval:  indegree - popularity (sqrt)                            0.4701  (   0.0443)
 7. eval:  indegree at least 3                                    -0.4797  (   0.2323)
 8. eval:  depUpDyad                                               1.9810  (   0.5349)
 9. eval:  depDownDyad                                             1.4207  (   0.4302)
10. eval:  devActLogVar ego                                        0.4924  (   0.0310)
11. eval:  comIntLogVar alter                                      0.0980  (   0.0442)
12. eval:  relActLogVar alter                                      0.0307  (   0.0803)
13. eval:  ageLogVar alter                                        -0.1734  (   0.0771)
14. eval:  depsUpLogVar alter                                      0.0075  (   0.0435)
15. eval:  depsDownLogVar alter                                    0.0614  (   0.0534)


@3
Covariance matrices
                   
Covariance matrix of estimates (correlations below diagonal):
     0.002      0.000      0.000      0.000     -0.001      0.000      0.000      0.001      0.001      0.000      0.000      0.000      0.000      0.000      0.000
     0.098      0.002      0.000      0.000     -0.001      0.000      0.000      0.001      0.001      0.000      0.000      0.000      0.000      0.000      0.000
     0.127      0.109      0.002      0.000     -0.001      0.000      0.000      0.001      0.000      0.000      0.000      0.000      0.000      0.000      0.000
    -0.335     -0.335     -0.349      0.000      0.001      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000      0.000
    -0.081     -0.094     -0.165      0.205      0.023     -0.005     -0.007     -0.011     -0.005     -0.002      0.002      0.001      0.001      0.001      0.000
     0.078      0.065      0.072     -0.133     -0.720      0.002      0.000      0.003     -0.001      0.000     -0.001     -0.001      0.000      0.000      0.000
    -0.027     -0.027     -0.008      0.058     -0.193      0.032      0.054     -0.003     -0.003      0.000      0.001      0.000      0.001      0.000     -0.001
     0.029      0.064      0.035      0.008     -0.130      0.112     -0.028      0.286      0.002     -0.001     -0.002     -0.001     -0.001      0.000      0.000
     0.048      0.040      0.016      0.050     -0.077     -0.029     -0.035      0.007      0.185     -0.002      0.002      0.002      0.000      0.001      0.000
     0.030      0.069      0.165     -0.168     -0.488      0.127      0.015     -0.062     -0.138      0.001      0.000      0.000      0.000      0.000      0.000
    -0.029     -0.027     -0.004      0.005      0.270     -0.696      0.090     -0.080      0.104     -0.017      0.002      0.000     -0.001      0.000      0.000
    -0.029      0.006     -0.023      0.099      0.075     -0.231      0.024     -0.021      0.049     -0.086     -0.091      0.006      0.002      0.000      0.000
    -0.022      0.007     -0.008      0.025      0.064     -0.009      0.070     -0.033      0.004     -0.022     -0.277      0.313      0.006      0.000     -0.001
    -0.007     -0.016      0.015      0.054      0.085     -0.114      0.008      0.006      0.045     -0.098      0.082     -0.014     -0.031      0.002      0.000
    -0.013     -0.050     -0.041      0.054     -0.032      0.063     -0.074      0.004     -0.015     -0.028      0.012      0.029     -0.159     -0.156      0.003

Derivative matrix of expected statistics X by parameters and
covariance/correlation matrix of X can be found using
summary(ans) within R, or by using the 'verbose' option in Siena07.
 
Total computation time 298.44 seconds.
