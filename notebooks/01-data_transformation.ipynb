{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HICSS 2023: Data Transformation\n",
    "\n",
    "This notebook performs data transformation operations by collecting data from the neo4j database.\n",
    "It then transforms the data into the required format for later usage in RSiena.\n",
    "\n",
    "The general database schema looks like this:\n",
    "\n",
    "![Database Schema](../figures/db_schema.png \"Database Schema\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "\n",
    "[ ] Check Database; somehow there are PullRequests related to Projects, Issues and Pull Requests related to themselves?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pytz\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from dateutil.parser import parse\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from neo4j import GraphDatabase\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Functions\n",
    "\n",
    "This section definies various function for data retrieval from Neo4j database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_packages(driver, date):\n",
    "    \"\"\"Queries packages from database\n",
    "\n",
    "    Retrieves a list of packages that have a unique repository\n",
    "    and have been created until the specified date.\n",
    "\n",
    "    Args:\n",
    "        driver: Neo4j database connection's driver.\n",
    "        date: Date to filter packages creation.\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame containing the packages.\n",
    "        Each row represents a package with the attributes\n",
    "        'name', 'repo_name', 'repo_owner', and 'created'.\n",
    "    \"\"\"\n",
    "    with driver.session(database='main') as session:\n",
    "        query = \"\"\"\n",
    "                MATCH (pa:Package)-[r:DEVELOPED_AT]->(pr:Project)\n",
    "                WITH pr, COUNT(r) AS num_pkgs\n",
    "                WHERE num_pkgs = 1\n",
    "                WITH pr\n",
    "                MATCH (pa:Package)-[r:DEVELOPED_AT]->(pr)\n",
    "                WHERE pa.created < DateTime($date)\n",
    "                RETURN pa.name AS name,\n",
    "                       pa.repo_name AS repo_name,\n",
    "                       pa.repo_owner AS repo_owner,\n",
    "                       toString(pa.created) AS created\n",
    "                \"\"\"\n",
    "        \n",
    "        results = session.run(query, date=date).data()\n",
    "    \n",
    "        packages = pd.DataFrame.from_dict(results)\n",
    "        packages['created'] = pd.to_datetime(packages['created'])\n",
    "        packages['observation'] = pd.to_datetime(date)\n",
    "    \n",
    "    return packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_version(driver, package, date):\n",
    "    \"\"\"Queries latest package version from database\n",
    "\n",
    "    Retrieves the latest version for each package in list of\n",
    "    names at observation date.\n",
    "\n",
    "    Args:\n",
    "        driver: Neo4j database connection's driver.\n",
    "        package: Package name.\n",
    "        date: Date of observation.\n",
    "    \n",
    "    Returns:\n",
    "        A list of dictionaries with data.\n",
    "    \"\"\"\n",
    "    with driver.session(database='main') as session:\n",
    "        query = \"\"\"\n",
    "                OPTIONAL MATCH (p:Package { id: $package })-[:RELEASED]->(v:Version)\n",
    "                WHERE v.created < DateTime($date)\n",
    "                AND NOT v.number CONTAINS \"-\"\n",
    "                RETURN p.name AS name,\n",
    "                       v.id AS version_id,\n",
    "                       v.number AS version,\n",
    "                       v.license AS license,\n",
    "                       toString(v.created) AS version_created\n",
    "                ORDER BY v.created DESC\n",
    "                LIMIT 1\n",
    "                \"\"\"\n",
    "        return session.run(query, package=package, date=date).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependencies(driver, version_ids):\n",
    "    \"\"\"Queries version's dependencies from database.\n",
    "\n",
    "    Retrieves the dependencies of for each package version\n",
    "    in list of version IDs.\n",
    "\n",
    "    Args:\n",
    "        driver: Neo4j database connection's driver.\n",
    "        version_ids: List of version IDs.\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame containing the all dependencies for\n",
    "        each version ID. Each row represents an edge from the\n",
    "        package towards its dependency with the attributes\n",
    "        'source', 'target', 'type', and 'created.\n",
    "    \"\"\"\n",
    "    with driver.session(database='main') as session:\n",
    "        query = \"\"\"\n",
    "                UNWIND $versions AS version\n",
    "                MATCH (v:Version { id: version })-[d:DEPENDS_ON]->(p:Package)\n",
    "                RETURN v.package_id AS source,\n",
    "                       p.id AS target,\n",
    "                       d.requirements AS requirements,\n",
    "                       toString(v.created) AS created\n",
    "                \"\"\"\n",
    "\n",
    "        results = session.run(query, versions=version_ids).data()\n",
    "\n",
    "        dependencies = pd.DataFrame.from_dict(results)\n",
    "        dependencies['created'] = pd.to_datetime(dependencies['created'])\n",
    "\n",
    "    return dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_developers(driver, repository, start, end):\n",
    "    \"\"\"Queries participating developers for repositories from database.\n",
    "\n",
    "    Retrieves the participating of for each repositories\n",
    "    in list of IDs.\n",
    "\n",
    "    Args:\n",
    "        driver: Neo4j database connection's driver.\n",
    "        repository: Repository IDs.\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame containing the participating users for\n",
    "        a repository.\n",
    "    \"\"\"\n",
    "    with driver.session(database='main') as session:\n",
    "        query_comments = \"\"\"\n",
    "            MATCH (u:User)-[p:POSTED]->(c:Comment)-[*2]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND c.created >= datetime($start)\n",
    "            AND c.created < datetime($end)\n",
    "            AND u.type <> \"Bot\"\n",
    "            AND NOT u.login CONTAINS \"[bot]\"\n",
    "            RETURN DISTINCT u.login AS login\n",
    "            \"\"\"\n",
    "                \n",
    "        query_issues = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:Issue)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            AND u.type <> \"Bot\"\n",
    "            AND NOT u.login CONTAINS \"[bot]\"\n",
    "            RETURN DISTINCT u.login AS login\n",
    "            \"\"\"\n",
    "\n",
    "        query_pullreq = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:PullRequest)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            AND u.type <> \"Bot\"\n",
    "            AND NOT u.login CONTAINS \"[bot]\"\n",
    "            RETURN DISTINCT u.login AS login\n",
    "            \"\"\"\n",
    "\n",
    "        query_commits = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:Commit)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            AND u.type <> \"Bot\"\n",
    "            AND NOT u.login CONTAINS \"[bot]\"\n",
    "            RETURN DISTINCT u.login AS login\n",
    "            \"\"\"\n",
    "\n",
    "        results_comments = session.run(\n",
    "            query_comments, repository=repository, start=start, end=end).data()\n",
    "        results_issues = session.run(\n",
    "            query_issues, repository=repository, start=start, end=end).data()\n",
    "        results_pullreq = session.run(\n",
    "            query_pullreq, repository=repository, start=start, end=end).data()\n",
    "        results_commits = session.run(\n",
    "            query_commits, repository=repository, start=start, end=end).data()\n",
    "\n",
    "        comments = pd.DataFrame.from_dict(results_comments)        \n",
    "        issues = pd.DataFrame.from_dict(results_issues)\n",
    "        pullreqs = pd.DataFrame.from_dict(results_pullreq)\n",
    "        commits = pd.DataFrame.from_dict(results_commits)\n",
    "\n",
    "        developers = pd.concat([comments, issues, pullreqs, commits], axis=0, ignore_index=True)\n",
    "        developers.drop_duplicates(subset=['login'], inplace=True)\n",
    "        developers.reset_index(inplace=True)\n",
    "\n",
    "    return developers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Get env variables\n",
    "uri = os.getenv(\"NEO4J_URI\")\n",
    "user = os.getenv(\"NEO4J_USERNAME\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password),\n",
    "                              encrypted=False,\n",
    "                              max_connection_lifetime=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2021-04-01\n",
      "2 2021-07-01\n",
      "3 2021-10-01\n",
      "4 2022-01-01\n"
     ]
    }
   ],
   "source": [
    "# Set periods for iteration\n",
    "OBSERVATION_START = '2021-01-01'  # First date of observation period\n",
    "DATE_START = '2021-04-01'  # Date of the first snapshot\n",
    "DATE_END = '2022-01-01'  # Date of the last snapshot\n",
    "PERIOD_LENGTH = relativedelta(months=3)  # Time between snapshots\n",
    "\n",
    "period = DATE_START\n",
    "periods = []\n",
    "obs = 0\n",
    "while period <= DATE_END:\n",
    "    periods.append(period)\n",
    "    next_period = (parse(period) + PERIOD_LENGTH).strftime(\"%Y-%m-%d\")\n",
    "    period = next_period\n",
    "    obs += 1\n",
    "\n",
    "observations = periods\n",
    "\n",
    "[print(i+1, obs) for i, obs in enumerate(observations)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f410f68e6649cc952fcde27ff14026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531435dc268e4e90bbffdbeb2c95c284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44a67802ff047f3917c75350413da3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1424d83a4dc04e2aa17ddc4973218ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5a63f182db4f9a9ebd3bf6caa5e36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "packages = []\n",
    "for obs in tqdm(observations):\n",
    "    _packages = get_packages(driver, obs)\n",
    "\n",
    "    latest_versions = []\n",
    "    for package in tqdm(_packages['name'].tolist(), leave=False):\n",
    "        latest_version = get_latest_version(driver, package, obs)\n",
    "        latest_versions.append(latest_version[0])\n",
    "\n",
    "    versions = pd.DataFrame.from_records(latest_versions)\n",
    "    versions['version_created'] = pd.to_datetime(versions['version_created'])\n",
    "\n",
    "    _packages = _packages.merge(versions, how=\"left\", on=['name'])\n",
    "    _packages.to_csv(f'../data/lists/packages-{obs}.csv', index=False)\n",
    "    packages.append(_packages)\n",
    "\n",
    "# Latest observation makes nodelist to account for later joiners\n",
    "full_packages = packages[(len(observations) - 1)]\n",
    "nodelist_pkgs = full_packages['name'].tolist()\n",
    "nodelist_pkgs = [\"_\".join([\"pkg\", name]) for name in nodelist_pkgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f98ddcc2384d06aadb45078402661c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df72dd4a73144bf18905297f35bc7d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"['index'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nh/wl01s5mn2bqfcl5zvjf_y65w0000gn/T/ipykernel_6566/1540909260.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0m_developers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdev_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_developers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdev_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdev_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../data/lists/developers-{obs}.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdevs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'login'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/posse-data/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/posse-data/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4904\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4905\u001b[0m         \"\"\"\n\u001b[0;32m-> 4906\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4907\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4908\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/posse-data/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/posse-data/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/posse-data/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['index'] not found in axis\""
     ]
    }
   ],
   "source": [
    "developers = []\n",
    "with tqdm(total=len(observations)) as pbar:\n",
    "    for i, obs in enumerate(observations):\n",
    "        repo_names = packages[i]['repo_name'].tolist()\n",
    "        _developers = []\n",
    "        for repo in tqdm(repo_names, leave=False):\n",
    "            if i == 0:\n",
    "                devs = get_developers(driver, repo, OBSERVATION_START, obs)\n",
    "            else:\n",
    "                devs = get_developers(driver, repo, observations[i-1], observations[i])\n",
    "            _developers.extend(devs)\n",
    "        dev_df = pd.DataFrame.from_records(_developers)\n",
    "        print(dev_df.head())\n",
    "        dev_df.drop(labels=['index'], axis=1, inplace=True)\n",
    "        dev_df.to_csv(f'../data/lists/developers-{obs}.csv', index=False)\n",
    "        devs = dev_df['login'].unique().tolist()\n",
    "        developers.append(devs)\n",
    "\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "\n",
    "# Create list of all developers participating in the observation period\n",
    "nodelist_devs = set()\n",
    "for i in range(len(observations)):\n",
    "    nodelist_devs.update(developers[i])\n",
    "nodelist_devs = list(nodelist_devs)\n",
    "nodelist_devs = [\"_\".join([\"dev\", name]) for name in nodelist_devs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependency Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f0e864d0a0429c8bb9ded0d45933ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create dependency networks for each observation\n",
    "dependency_networks = []\n",
    "with tqdm(total=len(observations)) as pbar:\n",
    "    for i, obs in enumerate(observations):\n",
    "        dependencies = get_dependencies(driver, packages[i]['version_id'].tolist())\n",
    "\n",
    "        # Keep edges between nodes in nodelist\n",
    "        dependencies = dependencies[dependencies['target'].isin(packages[i]['name'].tolist())]\n",
    "\n",
    "        # Add prefix to match nodelist\n",
    "        dependencies['source'] = \"pkg_\" + dependencies['source']\n",
    "        dependencies['target'] = \"pkg_\" + dependencies['target']\n",
    "\n",
    "        edgelist = list(zip(dependencies['source'], dependencies['target']))\n",
    "\n",
    "        G = nx.DiGraph()\n",
    "        G.add_nodes_from(nodelist_pkgs)\n",
    "        G.add_edges_from(edgelist)\n",
    "        dependency_networks.append(G)\n",
    "        nx.write_gpickle(G, '../data/networks/dependency_network-{0}.pkl'.format(obs))\n",
    "        pbar.update()\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adjacency Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a27256848594212a9cf7b5b86bc258a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tqdm(total=len(observations)) as pbar:\n",
    "    for i, obs in enumerate(observations):\n",
    "        adj = nx.to_pandas_adjacency(dependency_networks[i], nodelist=nodelist_pkgs)\n",
    "\n",
    "        # Identify missing nodes at observation\n",
    "        available_nodes = list(full_packages[full_packages['created'] < obs]['name'])\n",
    "        available_nodes = [\"_\".join([\"pkg\", name]) for name in available_nodes]\n",
    "        missing_nodes = [item for item in nodelist_pkgs if item not in available_nodes]\n",
    "\n",
    "        # Change rows\n",
    "        adj.loc[ missing_nodes , : ] = np.nan\n",
    "        # Change columns\n",
    "        adj.loc[ : , missing_nodes ] = np.nan\n",
    "\n",
    "        adj = adj.astype('Int8')\n",
    "        adj = adj.astype(str)\n",
    "        adj.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "\n",
    "        am = adj.to_numpy()\n",
    "        np.savetxt('../data/adjacency/dnet{0}.txt'.format(obs), am, fmt='%s')\n",
    "\n",
    "        # With structural zeros instead of NA for Goodness-of-Fit tests\n",
    "        adj.replace(to_replace='NA', value='0', inplace=True)\n",
    "        am_gof = adj.to_numpy()\n",
    "        np.savetxt('../data/adjacency/dnet{0}-gof.txt'.format(i+1), am_gof, fmt='%s')\n",
    "\n",
    "        pbar.update()\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Composition Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/wl01s5mn2bqfcl5zvjf_y65w0000gn/T/ipykernel_5232/4116069977.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  composition['name'] = \"pkg_\" + composition['name']\n",
      "/var/folders/nh/wl01s5mn2bqfcl5zvjf_y65w0000gn/T/ipykernel_5232/4116069977.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  composition['appearance'] = 0\n",
      "/Users/mariomueller/.virtualenvs/posse-data/lib/python3.9/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# Composition changes for dependency network\n",
    "composition = packages[len(observations) - 1][['name', 'created']].copy()\n",
    "composition['name'] = \"pkg_\" + composition['name']\n",
    "composition['appearance'] = 0\n",
    "\n",
    "rev_obs = sorted(observations,  reverse=True)\n",
    "for i, item in enumerate(rev_obs):\n",
    "    obs = len(rev_obs) - i\n",
    "    composition.loc[composition['created'] < item, 'appearance'] = int(obs)\n",
    "\n",
    "arr = []\n",
    "for i, row in composition.iterrows():\n",
    "    curr = [int(row['appearance']), len(observations)]\n",
    "    arr.append(curr)\n",
    "    \n",
    "comp_arr = np.array(arr)\n",
    "np.savetxt('../data/compositions/dependency_network.txt', comp_arr, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affiliation Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6be7ec5540490c8bfa2b6b7c18a694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nh/wl01s5mn2bqfcl5zvjf_y65w0000gn/T/ipykernel_5232/925499789.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mrepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mpackages_repos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# Create affiliation networks for each observation\n",
    "affiliation_networks = []\n",
    "\n",
    "with tqdm(total=len(observations)) as pbar:\n",
    "    for i, obs in enumerate(observations):\n",
    "        packages = packages[i]['name'].tolist()\n",
    "        repos = packages[i]['repo_name'].tolist()\n",
    "        packages_repos = list(zip(packages, repos))\n",
    "        \n",
    "        developers = []\n",
    "        for package, repo in tqdm(packages_repos, leave=False):\n",
    "            if i == 0:\n",
    "                devs = get_developers(driver, repo, OBSERVATION_START, obs)\n",
    "            else:\n",
    "                devs = get_developers(driver, repo, observations[i-1], observations[i])\n",
    "            \n",
    "            devs['package'] = package\n",
    "            \n",
    "            developers.extend(devs.to_dict(orient=\"records\"))\n",
    "\n",
    "        df_devs = pd.DataFrame.from_records(developers)\n",
    "        df_devs['source'] = \"dev_\" + df_devs['login']\n",
    "        df_devs['target'] = \"pkg_\" + df_devs['package']\n",
    "        edgelist = list(zip(df_devs['source'], df_devs['target']))\n",
    "\n",
    "        G = nx.DiGraph()\n",
    "        G.add_nodes_from(nodelist_pkgs)\n",
    "        G.add_nodes_from(nodelist_devs)\n",
    "        G.add_edges_from(edgelist)\n",
    "        affiliation_networks.append(G)\n",
    "        nx.write_gpickle(G, '../data/networks/affiliation_network-{0}.pkl'.format(obs))\n",
    "        pbar.update()\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adjacency Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist_aff = nodelist_devs + nodelist_pkgs\n",
    "\n",
    "with tqdm(total=len(observations)) as pbar:\n",
    "    for i, obs in enumerate(observations):\n",
    "        adj = nx.to_pandas_adjacency(affiliation_networks[i], nodelist=nodelist_aff)\n",
    "\n",
    "        # Identify missing nodes at observation\n",
    "        available_packages = list(full_packages[full_packages['created'] < obs]['name'])\n",
    "        missing_packages = [item for item in nodelist_pkgs if item not in available_packages]\n",
    "        adj.loc[ : , missing_packages ] = np.nan\n",
    "\n",
    "        adj = adj.astype('Int8')\n",
    "        adj = adj.astype(str)\n",
    "        adj.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "\n",
    "        am = adj.to_numpy()\n",
    "        np.savetxt('../data/adjacency/anet{0}.txt'.format(obs), am, fmt='%s')\n",
    "\n",
    "        # With structural zeros instead of NA for Goodness-of-Fit tests\n",
    "        adj.replace(to_replace='NA', value='0', inplace=True)\n",
    "        am_gof = adj.to_numpy()\n",
    "        np.savetxt('../data/adjacency/anet{0}-gof.txt'.format(i+1), am_gof, fmt='%s')\n",
    "\n",
    "        pbar.update()\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Composition Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Composition changes for dependency network\n",
    "composition = packages[len(observations) - 1][['name', 'created']].copy()\n",
    "composition['appearance'] = 0\n",
    "\n",
    "rev_obs = sorted(observations,  reverse=True)\n",
    "for i, item in enumerate(rev_obs):\n",
    "    obs = len(rev_obs) - i\n",
    "    composition.loc[composition['created'] < item, 'appearance'] = int(obs)\n",
    "\n",
    "arr = []\n",
    "for i, row in composition.iterrows():\n",
    "    curr = [int(row['appearance']), len(observations)]\n",
    "    arr.append(curr)\n",
    "    \n",
    "comp_arr = np.array(arr)\n",
    "np.savetxt('../data/compositions/dependency_network.txt', comp_arr, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Dyadic Variables:\n",
    "    - User has dependency with project\n",
    "    - User participated before\n",
    "    - User has collaborated with users related to project before\n",
    "- Individual Variables:\n",
    "    - Packages\n",
    "        - License\n",
    "        - Age\n",
    "        - Dependencies\n",
    "        - Dependents\n",
    "        - Releases\n",
    "    - Developers\n",
    "        - Tenure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composition Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "composition = data[len(observations) - 1][['name', 'created']]\n",
    "composition['appearance'] = 0\n",
    "\n",
    "rev_obs = sorted(observations,  reverse=True)\n",
    "for i, item in enumerate(rev_obs):\n",
    "    obs = len(rev_obs) - i\n",
    "    composition.loc[composition['created'] < item, 'appearance'] = int(obs)\n",
    "\n",
    "arr = []\n",
    "for i, row in composition.iterrows():\n",
    "    curr = [int(row['appearance']), len(observations)]\n",
    "    arr.append(curr)\n",
    "    \n",
    "comp_arr = np.array(arr)\n",
    "# np.savetxt('../rsiena/data/composition-changes.txt', comp_arr, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>created</th>\n",
       "      <th>appearance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eslint</td>\n",
       "      <td>2013-07-04 17:01:29.347000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>debug</td>\n",
       "      <td>2011-11-29 01:11:23.618000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ajv</td>\n",
       "      <td>2015-05-29 22:33:14.989000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>espree</td>\n",
       "      <td>2014-12-06 03:10:12.402000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mkdirp</td>\n",
       "      <td>2011-01-06 02:54:36.080000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                          created  appearance\n",
       "0  eslint 2013-07-04 17:01:29.347000+00:00           1\n",
       "1   debug 2011-11-29 01:11:23.618000+00:00           1\n",
       "2     ajv 2015-05-29 22:33:14.989000+00:00           1\n",
       "3  espree 2014-12-06 03:10:12.402000+00:00           1\n",
       "4  mkdirp 2011-01-06 02:54:36.080000+00:00           1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "composition = data[len(observations) - 1][['name', 'created']]\n",
    "composition['appearance'] = 0\n",
    "\n",
    "rev_obs = sorted(observations,  reverse=True)\n",
    "for i, item in enumerate(rev_obs):\n",
    "    obs = len(rev_obs) - i\n",
    "    composition.loc[composition['created'] < item, 'appearance'] = int(obs)\n",
    "\n",
    "arr = []\n",
    "for i, row in composition.iterrows():\n",
    "    curr = [int(row['appearance']), len(observations)]\n",
    "    arr.append(curr)\n",
    "    \n",
    "comp_arr = np.array(arr)\n",
    "np.savetxt('../rsiena/data/composition-changes.txt', comp_arr, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, obs in enumerate(observations):\n",
    "    G = nx.read_gpickle('data/graph-{0}.pkl'.format(obs))\n",
    "    # Create subgraph based on final nodelist\n",
    "    U = G.subgraph(nodelist).copy()\n",
    "    # U = nx.subgraph(G, nodelist)\n",
    "\n",
    "    # Convert list of tuples to list of lists for neo4j\n",
    "    edgelist = [list(item) for item in list(U.edges())]\n",
    "\n",
    "    # Query dependency types for all edges\n",
    "    dependency_types = get_dependency_type(driver, edgelist, obs)\n",
    "\n",
    "    # Change types to categorical codes\n",
    "    dependency_types['type'].replace(to_replace='dependency', value=1, inplace=True)\n",
    "    dependency_types['type'].replace(to_replace='devDependency', value=2, inplace=True)\n",
    "    dependency_types['type'].replace(to_replace='peerDependency', value=3, inplace=True)\n",
    "\n",
    "    # Add weights to edges according to code of dependency type\n",
    "    for index, row in dependency_types.iterrows():\n",
    "        U.edges[row['source'], row['target']]['weight'] = row['type']\n",
    "\n",
    "    # Export\n",
    "    adj = nx.to_pandas_adjacency(U, nodelist=nodelist, dtype='Int8')\n",
    "\n",
    "    # Identify missing nodes at observation\n",
    "    available_nodes = list(df_created[df_created['created'] < obs]['name'])\n",
    "    missing_nodes = [item for item in nodelist if item not in available_nodes]\n",
    "\n",
    "    # Change rows\n",
    "    adj.loc[ missing_nodes , : ] = np.nan\n",
    "    # Change columns\n",
    "    adj.loc[ : , missing_nodes ] = np.nan\n",
    "\n",
    "    adj = adj.astype('Int8')\n",
    "    adj = adj.astype(str)\n",
    "    adj.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "\n",
    "    am = adj.to_numpy()\n",
    "    np.savetxt('../rsiena/data/net{0}-type.txt'.format(i+1), am, fmt='%s')\n",
    "\n",
    "    adj.replace(to_replace='NA', value='0', inplace=True)\n",
    "    np.savetxt('../rsiena/data/net{0}-type-gof.txt'.format(i+1), am, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = pd.DataFrame(nodelist, columns=['name'])\n",
    "for obs in observations:\n",
    "    _date_obs = datetime.datetime.strptime(obs, '%Y-%m-%d')\n",
    "    timezone = pytz.timezone('UTC')\n",
    "    date_obs = timezone.localize(_date_obs)\n",
    "\n",
    "    latest_versions = get_latest_version(driver, nodelist, obs)\n",
    "\n",
    "    data = {}\n",
    "    for i, row in latest_versions.iterrows():\n",
    "        delta = date_obs - row['created']\n",
    "        data[row['name']] = delta\n",
    "    \n",
    "    _updates = pd.DataFrame.from_dict(data, orient='index', columns=[obs])\n",
    "    updates = updates.merge(_updates, how='outer', right_index=True, left_on=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2016-01-01</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2018-01-01</th>\n",
       "      <th>2019-01-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>199</td>\n",
       "      <td>256</td>\n",
       "      <td>280</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>106 days 08:01:24.643216080</td>\n",
       "      <td>183 days 21:15:55.984375</td>\n",
       "      <td>273 days 17:41:24.567857144</td>\n",
       "      <td>353 days 21:48:01.026578072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>166 days 01:10:56.408254856</td>\n",
       "      <td>220 days 16:11:24.619665196</td>\n",
       "      <td>310 days 04:22:23.649908268</td>\n",
       "      <td>407 days 16:10:11.135340508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0 days 09:09:03</td>\n",
       "      <td>0 days 07:48:27</td>\n",
       "      <td>1 days 06:01:17</td>\n",
       "      <td>2 days 01:44:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22 days 00:19:51.500000</td>\n",
       "      <td>28 days 06:29:50</td>\n",
       "      <td>40 days 05:58:08.500000</td>\n",
       "      <td>37 days 10:07:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44 days 13:46:19</td>\n",
       "      <td>112 days 19:11:46</td>\n",
       "      <td>130 days 10:56:48</td>\n",
       "      <td>154 days 01:37:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>133 days 19:37:29</td>\n",
       "      <td>243 days 07:01:34.750000</td>\n",
       "      <td>482 days 07:40:37.500000</td>\n",
       "      <td>572 days 07:52:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1238 days 02:25:47</td>\n",
       "      <td>1604 days 02:25:47</td>\n",
       "      <td>1969 days 02:25:47</td>\n",
       "      <td>2334 days 02:25:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        2016-01-01                   2017-01-01  \\\n",
       "count                          199                          256   \n",
       "mean   106 days 08:01:24.643216080     183 days 21:15:55.984375   \n",
       "std    166 days 01:10:56.408254856  220 days 16:11:24.619665196   \n",
       "min                0 days 09:09:03              0 days 07:48:27   \n",
       "25%        22 days 00:19:51.500000             28 days 06:29:50   \n",
       "50%               44 days 13:46:19            112 days 19:11:46   \n",
       "75%              133 days 19:37:29     243 days 07:01:34.750000   \n",
       "max             1238 days 02:25:47           1604 days 02:25:47   \n",
       "\n",
       "                        2018-01-01                   2019-01-01  \n",
       "count                          280                          301  \n",
       "mean   273 days 17:41:24.567857144  353 days 21:48:01.026578072  \n",
       "std    310 days 04:22:23.649908268  407 days 16:10:11.135340508  \n",
       "min                1 days 06:01:17              2 days 01:44:12  \n",
       "25%        40 days 05:58:08.500000             37 days 10:07:19  \n",
       "50%              130 days 10:56:48            154 days 01:37:26  \n",
       "75%       482 days 07:40:37.500000            572 days 07:52:17  \n",
       "max             1969 days 02:25:47           2334 days 02:25:47  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates_codes = updates.copy()\n",
    "for i in range(len(observations)):\n",
    "\n",
    "    updates_codes[observations[i]] = updates_codes[observations[i]].apply(\n",
    "        lambda x: x.total_seconds()//(60*60*24)\n",
    "    )\n",
    "\n",
    "    for index, row in updates_codes.iterrows():\n",
    "        # 2 Weeks\n",
    "        if row[observations[i]] <= 14:\n",
    "            updates_codes.loc[index, observations[i]] = 1\n",
    "        # 1 Month\n",
    "        elif row[observations[i]] <= 30:\n",
    "            updates_codes.loc[index, observations[i]] = 2\n",
    "        # 1 Quarter\n",
    "        elif row[observations[i]] <= 90: \n",
    "            updates_codes.loc[index, observations[i]] = 3\n",
    "        # Half a Year\n",
    "        elif row[observations[i]] <= 180:\n",
    "            updates_codes.loc[index, observations[i]] = 4\n",
    "        # 1 Year\n",
    "        elif row[observations[i]] <= 365:\n",
    "            updates_codes.loc[index, observations[i]] = 5\n",
    "        # More than 1 Year\n",
    "        elif row[observations[i]] > 365:\n",
    "            updates_codes.loc[index, observations[i]] = 6\n",
    "\n",
    "updates_codes = updates_codes[observations].astype('Int8')\n",
    "updates_codes = updates_codes[observations].astype(str)\n",
    "updates_codes.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "np.savetxt('../rsiena/data/updates-codes.txt', updates_codes[observations].values, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Licenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses = pd.DataFrame(nodelist, columns=['name'])\n",
    "\n",
    "for i, obs in enumerate(observations):\n",
    "    latest_versions = get_latest_version(driver, nodelist, obs)\n",
    "    latest_licenses = get_licenses(driver, list(latest_versions['_id']))\n",
    "    licenses = licenses.merge(latest_licenses, how='outer', on=['name'])\n",
    "    \n",
    "licenses.columns = ['name'] + observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2018-01-01</th>\n",
       "      <th>2019-01-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@atlaskit/build-utils</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apache</td>\n",
       "      <td>Apache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@atlaskit/button</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apache</td>\n",
       "      <td>Apache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@atlaskit/docs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apache</td>\n",
       "      <td>Apache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@atlaskit/icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@atlaskit/theme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apache</td>\n",
       "      <td>Apache</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name 2016-01-01 2017-01-01 2018-01-01 2019-01-01\n",
       "0  @atlaskit/build-utils        NaN        NaN     Apache     Apache\n",
       "1       @atlaskit/button        NaN        NaN     Apache     Apache\n",
       "2         @atlaskit/docs        NaN        NaN     Apache     Apache\n",
       "3         @atlaskit/icon        NaN        NaN       NULL       NULL\n",
       "4        @atlaskit/theme        NaN        NaN     Apache     Apache"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses_codes = licenses.copy()\n",
    "\n",
    "licenses_codes.replace(to_replace='NULL', value=np.nan, inplace=True)\n",
    "licenses_codes[observations] = licenses_codes[observations].apply(lambda col:pd.Categorical(col).codes)\n",
    "\n",
    "licenses_codes = licenses_codes.astype(str)\n",
    "licenses_codes.replace(to_replace='-1', value='NA', inplace=True)\n",
    "licenses_codes.replace(to_replace='4', value='5', inplace=True)\n",
    "licenses_codes.replace(to_replace='3', value='4', inplace=True)\n",
    "licenses_codes.replace(to_replace='2', value='3', inplace=True)\n",
    "licenses_codes.replace(to_replace='1', value='2', inplace=True)\n",
    "licenses_codes.replace(to_replace='0', value='1', inplace=True)\n",
    "\n",
    "\n",
    "np.savetxt('../rsiena/data/licenses-codes.txt',\n",
    "           licenses_codes[observations].values, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2018-01-01</th>\n",
       "      <th>2019-01-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@atlaskit/build-utils</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@atlaskit/button</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@atlaskit/docs</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@atlaskit/icon</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@atlaskit/theme</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name 2016-01-01 2017-01-01 2018-01-01 2019-01-01\n",
       "0  @atlaskit/build-utils         NA         NA          1          1\n",
       "1       @atlaskit/button         NA         NA          1          1\n",
       "2         @atlaskit/docs         NA         NA          1          1\n",
       "3         @atlaskit/icon         NA         NA         NA         NA\n",
       "4        @atlaskit/theme         NA         NA          1          1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licenses_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "releases = pd.DataFrame(nodelist, columns=['name'])\n",
    "\n",
    "for i in range(len(observations)):\n",
    "    release_counts = get_releases(driver, nodelist, observations[i])\n",
    "    release_counts.columns = ['name', observations[i]]\n",
    "    releases = releases.merge(release_counts, how='outer', on=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2016-01-01</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2018-01-01</th>\n",
       "      <th>2019-01-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>199.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>301.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.376884</td>\n",
       "      <td>40.207031</td>\n",
       "      <td>48.346429</td>\n",
       "      <td>55.534884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47.611047</td>\n",
       "      <td>48.636548</td>\n",
       "      <td>53.227159</td>\n",
       "      <td>63.142402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>455.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>478.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2016-01-01  2017-01-01  2018-01-01  2019-01-01\n",
       "count  199.000000  256.000000  280.000000  301.000000\n",
       "mean    34.376884   40.207031   48.346429   55.534884\n",
       "std     47.611047   48.636548   53.227159   63.142402\n",
       "min      1.000000    1.000000    1.000000    1.000000\n",
       "25%      9.000000   11.000000   16.000000   17.000000\n",
       "50%     19.000000   23.000000   30.000000   36.000000\n",
       "75%     42.000000   49.000000   58.000000   69.000000\n",
       "max    455.000000  460.000000  468.000000  478.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "releases.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "releases_codes = releases.copy()\n",
    "\n",
    "for i in range(len(observations)):\n",
    "    for index, row in releases_codes.iterrows():\n",
    "        if row[observations[i]] <= 5:\n",
    "            releases_codes.loc[index, observations[i]] = 1\n",
    "        elif row[observations[i]] <= 10:\n",
    "            releases_codes.loc[index, observations[i]] = 2\n",
    "        elif row[observations[i]] <= 20:\n",
    "            releases_codes.loc[index, observations[i]] = 3\n",
    "        elif row[observations[i]] <= 30:\n",
    "            releases_codes.loc[index, observations[i]] = 4\n",
    "        elif row[observations[i]] <= 40:\n",
    "            releases_codes.loc[index, observations[i]] = 5\n",
    "        elif row[observations[i]] <= 50: \n",
    "            releases_codes.loc[index, observations[i]] = 6\n",
    "        elif row[observations[i]] <= 60:\n",
    "            releases_codes.loc[index, observations[i]] = 7\n",
    "        elif row[observations[i]] > 60:\n",
    "            releases_codes.loc[index, observations[i]] = 8\n",
    "\n",
    "releases_codes[observations] = releases_codes[observations].astype('Int8')\n",
    "releases_codes[observations] = releases_codes[observations].astype(str)\n",
    "releases_codes.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "np.savetxt('../rsiena/data/releases-codes.txt',\n",
    "           releases_codes[observations].values, fmt='%s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = df_created[['name', 'created']]\n",
    "\n",
    "for obs in observations:\n",
    "    ages[obs] = ages['created'].apply(\n",
    "        lambda x: datetime.datetime.strptime(obs, '%Y-%m-%d').date() - x.date())\n",
    "    ages[obs] = round(ages[obs].dt.days/365, 0)\n",
    "    ages[obs] = ages[obs].apply(lambda x : x if x > 0 else np.nan)\n",
    "\n",
    "ages[observations] = ages[observations].astype('Int8')\n",
    "ages[observations] = ages[observations].astype(str)\n",
    "\n",
    "ages.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "np.savetxt('../rsiena/data/ages.txt', ages[observations].values, fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "833eb098fc81a387e667a83821bd3bfe54e47770c4f6f3f0b07bf099c925af38"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('posse-data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
