{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pytz\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from dateutil.parser import parse\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from neo4j import GraphDatabase\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100\n",
    "WORK_DIR = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "OUTPUT = os.path.join(WORK_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_driver():\n",
    "    load_dotenv(find_dotenv())\n",
    "\n",
    "    # Get env variables\n",
    "    uri = os.getenv(\"NEO4J_URI\")\n",
    "    user = os.getenv(\"NEO4J_USERNAME\")\n",
    "    password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "    return GraphDatabase.driver(uri, auth=(user, password),\n",
    "                                encrypted=False,\n",
    "                                max_connection_lifetime=3600)\n",
    "\n",
    "driver = initialize_driver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2021-03-01\n",
      "2 2021-04-01\n",
      "3 2021-05-01\n",
      "4 2021-06-01\n",
      "5 2021-07-01\n",
      "6 2021-08-01\n",
      "7 2021-09-01\n",
      "8 2021-10-01\n"
     ]
    }
   ],
   "source": [
    "# Set periods for iteration\n",
    "OBSERVATION_START = '2021-02-01'  # First date of observation period\n",
    "DATE_START = '2021-03-01'  # Date of the first snapshot\n",
    "DATE_END = '2021-10-01'  # Date of the last snapshot\n",
    "PERIOD_LENGTH = relativedelta(months=1)  # Time between snapshots\n",
    "\n",
    "def create_observations():\n",
    "    period = DATE_START\n",
    "    periods = []\n",
    "    obs = 0\n",
    "    while period <= DATE_END:\n",
    "        periods.append(period)\n",
    "        next_period = (parse(period) + PERIOD_LENGTH).strftime(\"%Y-%m-%d\")\n",
    "        period = next_period\n",
    "        obs += 1\n",
    "\n",
    "    observations = periods\n",
    "\n",
    "    [print(i+1, obs) for i, obs in enumerate(observations)]\n",
    "\n",
    "    return observations\n",
    "\n",
    "observations = create_observations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling & Nodelists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_packages(driver, date):\n",
    "    with driver.session(database='main') as session:\n",
    "        query = \"\"\"\n",
    "                MATCH (pa:Package)-[r:DEVELOPED_AT]->(pr:Project)\n",
    "                WITH pr, COUNT(r) AS num_pkgs\n",
    "                WHERE num_pkgs = 1\n",
    "                WITH pr\n",
    "                MATCH (pa:Package)-[r:DEVELOPED_AT]->(pr)\n",
    "                WHERE pa.created < DateTime($date)\n",
    "                RETURN pa.name AS name,\n",
    "                       pa.repo_name AS repo_name,\n",
    "                       pa.repo_owner AS repo_owner,\n",
    "                       toString(pa.created) AS created\n",
    "                \"\"\"\n",
    "        \n",
    "        results = session.run(query, date=date).data()\n",
    "    \n",
    "        packages = pd.DataFrame.from_dict(results)\n",
    "        packages['created'] = pd.to_datetime(packages['created'])\n",
    "        packages['observation'] = pd.to_datetime(date)\n",
    "    \n",
    "    return packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repository_activity(repository, start, end):\n",
    "    with driver.session(database='main') as session:\n",
    "        query_comments = \"\"\"\n",
    "            MATCH (c:Comment)-[*2]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND c.created >= datetime($start)\n",
    "            AND c.created < datetime($end)\n",
    "            RETURN count(c)\n",
    "            \"\"\"\n",
    "        \n",
    "        query_issues = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:Issue)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN count(a)\n",
    "            \"\"\"\n",
    "\n",
    "        query_pullreq = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:PullRequest)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN count(a)\n",
    "            \"\"\"\n",
    "\n",
    "        query_commits = \"\"\"\n",
    "            MATCH (u:User)-[a]->(c:Commit)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN count(c)\n",
    "            \"\"\"\n",
    "\n",
    "        results_comments = session.run(\n",
    "            query_comments, repository=repository, start=start, end=end).single().value()\n",
    "        results_issues = session.run(\n",
    "            query_issues, repository=repository, start=start, end=end).single().value()\n",
    "        results_pullreq = session.run(\n",
    "            query_pullreq, repository=repository, start=start, end=end).single().value()\n",
    "        results_commits = session.run(\n",
    "            query_commits, repository=repository, start=start, end=end).single().value()\n",
    "\n",
    "        activity_count = results_comments + results_issues + results_pullreq + results_commits\n",
    "\n",
    "        return activity_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_package_sample():\\n    packages = get_packages(driver, OBSERVATION_START)\\n    \\n    # Get activity for each observation period\\n    for index, row in tqdm(packages.iterrows(), total=len(packages.index)):\\n        for i, obs in enumerate(observations):\\n            if i == 0:\\n                packages.loc[index, \"_\".join([\"act\", obs])] = int(get_repository_activity(row[\\'repo_name\\'], OBSERVATION_START, obs))\\n            else:\\n                packages.loc[index, \"_\".join([\"act\", obs])] = int(get_repository_activity(row[\\'repo_name\\'], observations[i-1], obs))\\n\\n    # Filter active packages\\n    act_columns = [\"_\".join([\"act\", obs]) for obs in observations]\\n    active_packages = packages[packages[act_columns].all(axis=\"columns\")].copy()\\n\\n    sample_pkgs = active_packages.sample(n=SAMPLE_SIZE, random_state=17, ignore_index=True)\\n    nodelist_pkgs = [\"_\".join([\"pkg\", name]) for name in sample_pkgs[\\'name\\'].tolist()]\\n\\n    nodelist = pd.DataFrame(nodelist_pkgs, columns=[\\'id\\'])\\n    nodelist.to_csv(\\'../data/nodelists/packages.csv\\', index=False)\\n\\n    return sample_pkgs, nodelist_pkgs\\n    \\nsample_pkgs, nodelist_pkgs = get_package_sample()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def get_package_sample():\n",
    "    packages = get_packages(driver, OBSERVATION_START)\n",
    "    \n",
    "    # Get activity for each observation period\n",
    "    for index, row in tqdm(packages.iterrows(), total=len(packages.index)):\n",
    "        for i, obs in enumerate(observations):\n",
    "            if i == 0:\n",
    "                packages.loc[index, \"_\".join([\"act\", obs])] = int(get_repository_activity(row['repo_name'], OBSERVATION_START, obs))\n",
    "            else:\n",
    "                packages.loc[index, \"_\".join([\"act\", obs])] = int(get_repository_activity(row['repo_name'], observations[i-1], obs))\n",
    "\n",
    "    # Filter active packages\n",
    "    act_columns = [\"_\".join([\"act\", obs]) for obs in observations]\n",
    "    active_packages = packages[packages[act_columns].all(axis=\"columns\")].copy()\n",
    "\n",
    "    sample_pkgs = active_packages.sample(n=SAMPLE_SIZE, random_state=17, ignore_index=True)\n",
    "    nodelist_pkgs = [\"_\".join([\"pkg\", name]) for name in sample_pkgs['name'].tolist()]\n",
    "\n",
    "    nodelist = pd.DataFrame(nodelist_pkgs, columns=['id'])\n",
    "    nodelist.to_csv('../data/nodelists/packages.csv', index=False)\n",
    "\n",
    "    return sample_pkgs, nodelist_pkgs\n",
    "    \n",
    "sample_pkgs, nodelist_pkgs = get_package_sample()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_version(driver, package, date):\n",
    "    with driver.session(database='main') as session:\n",
    "        query = \"\"\"\n",
    "                OPTIONAL MATCH (p:Package { id: $package })-[:RELEASED]->(v:Version)\n",
    "                WHERE v.created < DateTime($date)\n",
    "                AND NOT v.number CONTAINS \"-\"\n",
    "                RETURN p.name AS name,\n",
    "                       v.id AS version_id,\n",
    "                       v.number AS version,\n",
    "                       v.license AS license,\n",
    "                       toString(v.created) AS version_created\n",
    "                ORDER BY v.created DESC\n",
    "                LIMIT 1\n",
    "                \"\"\"\n",
    "        return session.run(query, package=package, date=date).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependencies(driver, version_ids):\n",
    "    with driver.session(database='main') as session:\n",
    "        query = \"\"\"\n",
    "                UNWIND $versions AS version\n",
    "                MATCH (v:Version { id: version })-[d:DEPENDS_ON]->(p:Package)\n",
    "                RETURN v.package_id AS source,\n",
    "                       p.id AS target,\n",
    "                       d.requirements AS requirements,\n",
    "                       toString(v.created) AS created\n",
    "                \"\"\"\n",
    "\n",
    "        results = session.run(query, versions=version_ids).data()\n",
    "\n",
    "        dependencies = pd.DataFrame.from_dict(results)\n",
    "        dependencies['created'] = pd.to_datetime(dependencies['created'])\n",
    "\n",
    "    return dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a543acde96704b5994abcef6e5493c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e93e67be3549689bd1514651379473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5a45cd5fb44f279d0e39c915bfce6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9962ac55f57a49daaf0220a9e164294a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92d71cd1a1b446ebfcf26b75f297282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ada02e40d94299a95ea1ac73f5ea62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c393a469da454e962afb9bbef0f2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9ada558fa8498baf796cc0f29b74e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5096ec45dcaa4a48ad1448b95692e4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_package_sample_with_dependencies():\n",
    "    packages = get_packages(driver, OBSERVATION_START)\n",
    "    \n",
    "    # Get activity for each observation period\n",
    "    for index, row in tqdm(packages.iterrows(), total=len(packages.index)):\n",
    "        for i, obs in enumerate(observations):\n",
    "            if i == 0:\n",
    "                packages.loc[index, \"_\".join([\"act\", obs])] = int(get_repository_activity(row['repo_name'], OBSERVATION_START, obs))\n",
    "            else:\n",
    "                packages.loc[index, \"_\".join([\"act\", obs])] = int(get_repository_activity(row['repo_name'], observations[i-1], obs))\n",
    "\n",
    "    # Filter active packages\n",
    "    act_columns = [\"_\".join([\"act\", obs]) for obs in observations]\n",
    "    active_packages = packages[packages[act_columns].all(axis=\"columns\")].copy()\n",
    "\n",
    "    sample_pkgs = active_packages.sample(n=SAMPLE_SIZE, random_state=17, ignore_index=True)\n",
    "    \n",
    "    # Get dependencies of sample\n",
    "    latest_versions = []\n",
    "    for i, obs in enumerate(observations):\n",
    "        for pkg in tqdm(sample_pkgs['name'].tolist(), leave=False):\n",
    "            latest_version = get_latest_version(driver, pkg, obs)\n",
    "            try:\n",
    "                latest_versions.append(latest_version[0])\n",
    "            except KeyError:\n",
    "                pass  # Package has no version\n",
    "\n",
    "    versions = pd.DataFrame.from_records(latest_versions)\n",
    "    versions['version_created'] = pd.to_datetime(versions['version_created'])\n",
    "\n",
    "    sample_pkgs = sample_pkgs.merge(versions, how=\"left\", on=['name'])\n",
    "    dependencies = get_dependencies(driver, sample_pkgs['version_id'].tolist())\n",
    "    deps_sources = dependencies['source'].unique().tolist()\n",
    "    deps_targets = dependencies['target'].unique().tolist()\n",
    "    nodelist = list(set(deps_sources + deps_targets))\n",
    "    \n",
    "    sample_pkgs = packages[packages['name'].isin(nodelist)].copy()\n",
    "    \n",
    "    nodelist_pkgs = [\"_\".join([\"pkg\", name]) for name in sample_pkgs['name'].tolist()]\n",
    "\n",
    "    nodelist = pd.DataFrame(nodelist_pkgs, columns=['id'])\n",
    "    nodelist.to_csv('../data/nodelists/packages.csv', index=False)\n",
    "\n",
    "    return sample_pkgs, nodelist_pkgs\n",
    "    \n",
    "sample_pkgs, nodelist_pkgs = get_package_sample_with_dependencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_developers(driver, repository, start, end):\n",
    "    with driver.session(database='main') as session:\n",
    "        query_comments = \"\"\"\n",
    "            MATCH (u:User)-[p:POSTED]->(c:Comment)-[*2]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND c.created >= datetime($start)\n",
    "            AND c.created < datetime($end)\n",
    "            AND u.type <> \"Bot\"\n",
    "            AND NOT u.login CONTAINS \"[bot]\"\n",
    "            RETURN DISTINCT u.login AS login\n",
    "            \"\"\"\n",
    "                \n",
    "        query_issues = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:Issue)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            AND u.type <> \"Bot\"\n",
    "            AND NOT u.login CONTAINS \"[bot]\"\n",
    "            RETURN DISTINCT u.login AS login\n",
    "            \"\"\"\n",
    "\n",
    "        query_pullreq = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:PullRequest)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            AND u.type <> \"Bot\"\n",
    "            AND NOT u.login CONTAINS \"[bot]\"\n",
    "            RETURN DISTINCT u.login AS login\n",
    "            \"\"\"\n",
    "\n",
    "        query_commits = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:Commit)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE r.name = toString($repository)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            AND u.type <> \"Bot\"\n",
    "            AND NOT u.login CONTAINS \"[bot]\"\n",
    "            RETURN DISTINCT u.login AS login\n",
    "            \"\"\"\n",
    "\n",
    "        results_comments = session.run(\n",
    "            query_comments, repository=repository, start=start, end=end).data()\n",
    "        results_issues = session.run(\n",
    "            query_issues, repository=repository, start=start, end=end).data()\n",
    "        results_pullreq = session.run(\n",
    "            query_pullreq, repository=repository, start=start, end=end).data()\n",
    "        results_commits = session.run(\n",
    "            query_commits, repository=repository, start=start, end=end).data()\n",
    "\n",
    "        comments = pd.DataFrame.from_dict(results_comments)        \n",
    "        issues = pd.DataFrame.from_dict(results_issues)\n",
    "        pullreqs = pd.DataFrame.from_dict(results_pullreq)\n",
    "        commits = pd.DataFrame.from_dict(results_commits)\n",
    "\n",
    "        developers = pd.concat([comments, issues, pullreqs, commits], axis=0, ignore_index=True)\n",
    "        developers.drop_duplicates(subset=['login'], inplace=True)\n",
    "\n",
    "    return developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_developer_activity_in_repositories(developer, repositories, start, end):\n",
    "    with driver.session(database='main') as session:\n",
    "        query_comments = \"\"\"\n",
    "            MATCH (u:User)-[p:POSTED]->(c:Comment)-[*2]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND c.created >= datetime($start)\n",
    "            AND c.created < datetime($end)\n",
    "            AND r.name IN $repositories\n",
    "            RETURN count(c)\n",
    "            \"\"\"\n",
    "        \n",
    "        query_issues = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:Issue)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            AND r.name IN $repositories\n",
    "            RETURN count(a)\n",
    "            \"\"\"\n",
    "\n",
    "        query_pullreq = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:PullRequest)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            AND r.name IN $repositories\n",
    "            RETURN count(a)\n",
    "            \"\"\"\n",
    "\n",
    "        query_commits = \"\"\"\n",
    "            MATCH (u:User)-[a]->(c:Commit)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            AND r.name IN $repositories\n",
    "            RETURN count(c)\n",
    "            \"\"\"\n",
    "\n",
    "        results_comments = session.run(\n",
    "            query_comments, developer=developer, repositories=repositories, start=start, end=end).single().value()\n",
    "        results_issues = session.run(\n",
    "            query_issues, developer=developer, repositories=repositories, start=start, end=end).single().value()\n",
    "        results_pullreq = session.run(\n",
    "            query_pullreq, developer=developer, repositories=repositories, start=start, end=end).single().value()\n",
    "        results_commits = session.run(\n",
    "            query_commits, developer=developer, repositories=repositories, start=start, end=end).single().value()\n",
    "\n",
    "        activity_count = results_comments + results_issues + results_pullreq + results_commits\n",
    "\n",
    "        return activity_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5f1dfd440e40af856f223e114269d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5305fa58a80422cac0d1211d472dcf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_developer_sample():\n",
    "    repo_names = sample_pkgs['repo_name'].tolist()\n",
    "    developers = []\n",
    "    for repo in tqdm(repo_names):\n",
    "        repo_devs = get_developers(driver, repo, OBSERVATION_START, DATE_END)\n",
    "        developers.extend(repo_devs.to_dict(orient=\"records\"))\n",
    "\n",
    "    devs = pd.DataFrame.from_records(developers)\n",
    "    devs_sample = devs.drop_duplicates(subset=['login']).copy()\n",
    "    \n",
    "    # Get developer activities to filter later\n",
    "    for index, row in tqdm(devs_sample.iterrows(), total=len(devs_sample.index)):\n",
    "        activity = get_developer_activity_in_repositories(row['login'], sample_pkgs['repo_name'].tolist(), OBSERVATION_START, DATE_END)\n",
    "        devs_sample.loc[index, \"activity\"] = int(activity)\n",
    "\n",
    "    # Remove developers with only 1 participation activity\n",
    "    # TODO: Increase/Decrease activity limit?!\n",
    "    devs_sample = devs_sample[devs_sample['activity'] >= 5].copy()\n",
    "\n",
    "    logins_sample = devs_sample['login'].unique().tolist()\n",
    "    nodelist_devs = [\"_\".join([\"dev\", name]) for name in logins_sample]\n",
    "\n",
    "    nodelist = pd.DataFrame(nodelist_devs, columns=['id'])\n",
    "    nodelist.to_csv('../data/nodelists/developers.csv', index=False)\n",
    "    \n",
    "    return devs_sample, nodelist_devs\n",
    "\n",
    "sample_devs, nodelist_devs = get_developer_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_version(driver, package, date):\n",
    "    with driver.session(database='main') as session:\n",
    "        query = \"\"\"\n",
    "                OPTIONAL MATCH (p:Package { id: $package })-[:RELEASED]->(v:Version)\n",
    "                WHERE v.created < DateTime($date)\n",
    "                AND NOT v.number CONTAINS \"-\"\n",
    "                RETURN p.name AS name,\n",
    "                       v.id AS version_id,\n",
    "                       v.number AS version,\n",
    "                       v.license AS license,\n",
    "                       toString(v.created) AS version_created\n",
    "                ORDER BY v.created DESC\n",
    "                LIMIT 1\n",
    "                \"\"\"\n",
    "        return session.run(query, package=package, date=date).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependencies(driver, version_ids):\n",
    "    with driver.session(database='main') as session:\n",
    "        query = \"\"\"\n",
    "                UNWIND $versions AS version\n",
    "                MATCH (v:Version { id: version })-[d:DEPENDS_ON]->(p:Package)\n",
    "                RETURN v.package_id AS source,\n",
    "                       p.id AS target,\n",
    "                       d.requirements AS requirements,\n",
    "                       toString(v.created) AS created\n",
    "                \"\"\"\n",
    "\n",
    "        results = session.run(query, versions=version_ids).data()\n",
    "\n",
    "        dependencies = pd.DataFrame.from_dict(results)\n",
    "        dependencies['created'] = pd.to_datetime(dependencies['created'])\n",
    "\n",
    "    return dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09db4eb920014635afa0454f7ac4ef10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a72c33c2b5452290133414dd5a1f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fc717c22994fe388f3b224acf6f953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665cb5ee4bef493ca70347df525267de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ffb2143d7b490988da09e5fb595d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b2f372db644bb3bc819e46d4efc1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d892216e534439f915e04865bf5dd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6e84ca918d450ba1ac5c8d1267d8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8171 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cc0940e6df481996db3394cf9df3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_dependency_networks():\n",
    "    # Create dependency networks for each observation\n",
    "    dependency_networks = []\n",
    "\n",
    "    with tqdm(total=len(observations)) as pbar:\n",
    "        for obs in observations:\n",
    "            packages = get_packages(driver, obs)\n",
    "\n",
    "            latest_versions = []\n",
    "            for package in tqdm(packages['name'].tolist(), leave=False):\n",
    "                latest_version = get_latest_version(driver, package, obs)\n",
    "                try:\n",
    "                    latest_versions.append(latest_version[0])\n",
    "                except KeyError:\n",
    "                    pass  # Package has no version\n",
    "\n",
    "            versions = pd.DataFrame.from_records(latest_versions)\n",
    "            versions['version_created'] = pd.to_datetime(versions['version_created'])\n",
    "\n",
    "            packages = packages.merge(versions, how=\"left\", on=['name'])\n",
    "            dependencies = get_dependencies(driver, packages['version_id'].tolist())\n",
    "\n",
    "            # Add prefix to match nodelist\n",
    "            dependencies['source'] = \"pkg_\" + dependencies['source']\n",
    "            dependencies['target'] = \"pkg_\" + dependencies['target']\n",
    "\n",
    "            edgelist = list(zip(dependencies['source'], dependencies['target']))\n",
    "\n",
    "            G = nx.DiGraph()\n",
    "            G.add_nodes_from(nodelist_pkgs)\n",
    "            G.add_edges_from(edgelist)\n",
    "\n",
    "            dependency_networks.append(G)\n",
    "\n",
    "            nx.write_edgelist(G, '../data/edgelists/dependency_network-{0}.edgelist'.format(obs), delimiter=\",\", data=False)\n",
    "            nx.write_gpickle(G, '../data/networks/dependency_network-{0}.pkl'.format(obs))\n",
    "            nx.write_gml(G, '../data/networks/dependency_network-{0}.gml'.format(obs))\n",
    "\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "    return dependency_networks\n",
    "\n",
    "dependency_networks = create_dependency_networks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_developer_affiliations(developer, start, end):\n",
    "    with driver.session(database='main') as session:\n",
    "        query_comments = \"\"\"\n",
    "            MATCH (u:User)-[p:POSTED]->(c:Comment)-[*2]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND c.created >= datetime($start)\n",
    "            AND c.created < datetime($end)\n",
    "            RETURN DISTINCT r.name AS repo_name\n",
    "            \"\"\"\n",
    "                \n",
    "        query_issues = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:Issue)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN DISTINCT r.name AS repo_name\n",
    "            \"\"\"\n",
    "\n",
    "        query_pullreq = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:PullRequest)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN DISTINCT r.name AS repo_name\n",
    "            \"\"\"\n",
    "\n",
    "        query_commits = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:Commit)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN DISTINCT r.name AS repo_name\n",
    "            \"\"\"\n",
    "\n",
    "        results_comments = session.run(\n",
    "            query_comments, developer=developer, start=start, end=end).data()\n",
    "        results_issues = session.run(\n",
    "            query_issues, developer=developer, start=start, end=end).data()\n",
    "        results_pullreq = session.run(\n",
    "            query_pullreq, developer=developer, start=start, end=end).data()\n",
    "        results_commits = session.run(\n",
    "            query_commits, developer=developer, start=start, end=end).data()\n",
    "\n",
    "        comments = pd.DataFrame.from_dict(results_comments)        \n",
    "        issues = pd.DataFrame.from_dict(results_issues)\n",
    "        pullreqs = pd.DataFrame.from_dict(results_pullreq)\n",
    "        commits = pd.DataFrame.from_dict(results_commits)\n",
    "\n",
    "        repositories = pd.concat([comments, issues, pullreqs, commits], axis=0, ignore_index=True)\n",
    "        repositories.drop_duplicates(subset=['repo_name'], inplace=True)\n",
    "\n",
    "    return repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19bef03bf914f04aec54f5f11942ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67e8684c99749edabe867431b3221cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfaeb2f184d401580a8635d7bc4f3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5bca0667104255969fc0dbec21d779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061869dc932d449bb6f3ad159f222094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd2b1a687174d29a507b411c7cc6946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e03fc10c514f99ab7a4787cf9d991b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc17d79b5304b4594853595513934c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e877d403f84411a95659b3deec1b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_affiliation_networks():\n",
    "    # Create affiliation networks for each observation\n",
    "    affiliation_networks = []\n",
    "\n",
    "    with tqdm(total=len(observations)) as pbar:\n",
    "        for i, obs in enumerate(observations):\n",
    "            affiliations = []\n",
    "            for dev in tqdm(sample_devs['login'].tolist(), leave=False):\n",
    "                if i == 0:\n",
    "                    dev_affiliations = get_developer_affiliations(dev, OBSERVATION_START, obs)\n",
    "                else:\n",
    "                    dev_affiliations = get_developer_affiliations(dev, observations[i-1], obs)\n",
    "                dev_affiliations['login'] = dev\n",
    "                affiliations.extend(dev_affiliations.to_dict(orient=\"records\"))\n",
    "\n",
    "            affiliations = pd.DataFrame.from_records(affiliations)\n",
    "            # Add package names to affiliation data\n",
    "            affiliations = affiliations.merge(sample_pkgs[[\"repo_name\", \"name\"]], how=\"left\", on=\"repo_name\")\n",
    "            \n",
    "            affiliations['source'] = \"dev_\" + affiliations['login']\n",
    "            affiliations['target'] = \"pkg_\" + affiliations['name']\n",
    "            \n",
    "            # Keep edges between devs and packages that are in nodelists\n",
    "            affiliations = affiliations[affiliations['source'].isin(nodelist_devs)]\n",
    "            affiliations = affiliations[affiliations['target'].isin(nodelist_pkgs)]\n",
    "\n",
    "            edgelist = list(zip(affiliations['source'], affiliations['target']))\n",
    "            \n",
    "            G = nx.DiGraph()\n",
    "            G.add_nodes_from(nodelist_devs, bipartite=0)\n",
    "            G.add_nodes_from(nodelist_pkgs, bipartite=1)\n",
    "            G.add_edges_from(edgelist)\n",
    "\n",
    "            affiliation_networks.append(G)\n",
    "\n",
    "            nx.write_edgelist(G, '../data/edgelists/affiliation_network-{0}.edgelist'.format(obs), delimiter=\",\", data=False)\n",
    "            nx.write_gpickle(G, '../data/networks/affiliation_network-{0}.pkl'.format(obs))\n",
    "            nx.write_gml(G, '../data/networks/affiliation_network-{0}.gml'.format(obs))\n",
    "\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "\n",
    "    return affiliation_networks\n",
    "\n",
    "affiliation_networks = create_affiliation_networks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependent Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2b3204fdf94ec2bb7bfc407c6eefba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjacency list for SIENA (Two-Mode Network)\n",
    "def create_adjacency_matrix_bipartite():\n",
    "    with tqdm(total=len(observations)) as pbar:\n",
    "        for i, obs in enumerate(observations):\n",
    "            adj = nx.bipartite.biadjacency_matrix(affiliation_networks[i], row_order=nodelist_devs, column_order=nodelist_pkgs)\n",
    "            am = adj.toarray()\n",
    "            np.savetxt('../data/adjacency/net-{0}.txt'.format(obs), am, fmt='%s')\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "\n",
    "create_adjacency_matrix_bipartite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669300d387f8473ea02208a71b2a2469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjacency list for SIENA (One-Mode Network)\n",
    "def create_adjacency_matrix():\n",
    "    with tqdm(total=len(observations)) as pbar:\n",
    "        for i, obs in enumerate(observations):\n",
    "            G = dependency_networks[i].subgraph(nodelist_pkgs)\n",
    "            adj = nx.to_pandas_adjacency(G, nodelist=nodelist_pkgs)\n",
    "            adj = adj.astype('Int8')\n",
    "            adj = adj.astype(str)\n",
    "            am = adj.to_numpy()\n",
    "            np.savetxt('../data/adjacency/dnet-{0}.txt'.format(obs), am, fmt='%s')\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "\n",
    "create_adjacency_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7fb025285990>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_networks[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_composition_change():\n",
    "    # Composition changes for dependency network\n",
    "    composition = sample_devs.copy()\n",
    "    composition['name'] = \"dev_\" + composition['login']\n",
    "    composition['appearance'] = 1\n",
    "    \n",
    "    inactive_developers = []\n",
    "    for i, item in enumerate(observations):\n",
    "         # Identify developers without outdegree in first period\n",
    "        devs_degrees = dict(affiliation_networks[i].out_degree(nodelist_devs))\n",
    "        devs_degrees = pd.DataFrame.from_dict(devs_degrees, orient=\"index\", columns=[\"out\"]).reset_index()\n",
    "        devs_degrees.rename(columns={\"index\": \"name\"}, inplace=True)\n",
    "\n",
    "        if i == 0: \n",
    "            inactive_developers.append(devs_degrees[devs_degrees['out'] == 0]['name'].tolist())\n",
    "        else:\n",
    "            devs = devs_degrees[devs_degrees['out'] == 0]['name'].tolist()\n",
    "            still_inactive_developers = [dev for dev in devs if dev in inactive_developers[i-1]]\n",
    "            inactive_developers.append(still_inactive_developers)\n",
    "    \n",
    "    for j, developers in enumerate(inactive_developers):\n",
    "        composition.loc[composition['name'].isin(developers), 'appearance'] = int(j + 2)\n",
    "\n",
    "    arr = []\n",
    "    for i, row in composition.iterrows():\n",
    "        curr = [int(row['appearance']), len(observations)]\n",
    "        arr.append(curr)\n",
    "        \n",
    "    comp_arr = np.array(arr)\n",
    "    np.savetxt('../data/compositions/comp_change.txt', comp_arr, fmt='%d')\n",
    "\n",
    "create_composition_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define and think about what makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_developer_activity(developer, start, end):\n",
    "    with driver.session(database='main') as session:\n",
    "        query_comments = \"\"\"\n",
    "            MATCH (u:User)-[p:POSTED]->(c:Comment)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND c.created >= datetime($start)\n",
    "            AND c.created < datetime($end)\n",
    "            RETURN count(c)\n",
    "            \"\"\"\n",
    "        \n",
    "        query_issues = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:Issue)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN count(a)\n",
    "            \"\"\"\n",
    "\n",
    "        query_pullreq = \"\"\"\n",
    "            MATCH (u:User)-[a]->(:PullRequest)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN count(a)\n",
    "            \"\"\"\n",
    "\n",
    "        query_commits = \"\"\"\n",
    "            MATCH (u:User)-[a]->(c:Commit)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN count(c)\n",
    "            \"\"\"\n",
    "\n",
    "        results_comments = session.run(\n",
    "            query_comments, developer=developer, start=start, end=end).single().value()\n",
    "        results_issues = session.run(\n",
    "            query_issues, developer=developer, start=start, end=end).single().value()\n",
    "        results_pullreq = session.run(\n",
    "            query_pullreq, developer=developer, start=start, end=end).single().value()\n",
    "        results_commits = session.run(\n",
    "            query_commits, developer=developer, start=start, end=end).single().value()\n",
    "\n",
    "        activity_count = results_comments + results_issues + results_pullreq + results_commits\n",
    "\n",
    "        return activity_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9557a20b2747439f4cd13cc69ecc13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5f318e85f947988aab0aa7fdd6c7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d700069de0df4764bd3cde7dfa10064c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2182bf70b1e243baa95dc51488b8cd15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc3a15e9b254f809852536610105700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fca3c1c7ee84b52be23417a30932a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c00fa75b804e0abf7137a1b1e9c97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93cac63a1fc4d1e8a792deffc50034b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea33e4422e34a5d912bebf0a1cc4c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_developer_activity():\n",
    "    activities = sample_devs.copy()\n",
    "\n",
    "    with tqdm(total=len(observations)) as pbar:\n",
    "        for i, obs in enumerate(observations):\n",
    "            for index, row in tqdm(activities.iterrows(), total=len(activities.index), leave=False):\n",
    "                if i == 0:\n",
    "                    activity = get_developer_activity(row['login'], OBSERVATION_START, obs)\n",
    "                else:\n",
    "                    activity = get_developer_activity(row['login'], observations[i-1], obs)\n",
    "                activities.loc[index, obs] = int(activity)\n",
    "\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "    \n",
    "    activities[observations] = activities[observations].astype(\"Int64\")\n",
    "    activities[observations] = activities[observations].astype(str)\n",
    "    activities.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "    np.savetxt('../data/individual/dev_activity.txt', activities[observations].values, fmt='%s')\n",
    "\n",
    "create_developer_activity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417aa114d9cf4b79aca96cb7968fe20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_package_dependencies():\n",
    "    dependencies = sample_pkgs[['name', 'repo_name']].copy()\n",
    "    dependencies['name'] = \"pkg_\" + dependencies['name']\n",
    "\n",
    "    with tqdm(total=len(observations)) as pbar:\n",
    "        for i, obs in enumerate(observations):\n",
    "            idegree = dict(dependency_networks[i].in_degree())\n",
    "            odegree = dict(dependency_networks[i].out_degree())\n",
    "            \n",
    "            df_idegree = pd.DataFrame.from_dict(idegree, orient=\"index\", columns=[\"_\".join([\"in\", obs])]).reset_index()\n",
    "            df_idegree.rename(columns={\"index\": \"name\"}, inplace=True)\n",
    "\n",
    "            df_odegree = pd.DataFrame.from_dict(odegree, orient=\"index\", columns=[\"_\".join([\"out\", obs])]).reset_index()\n",
    "            df_odegree.rename(columns={\"index\": \"name\"}, inplace=True)\n",
    "\n",
    "            dependencies = dependencies.merge(df_idegree, how=\"left\", on=\"name\")\n",
    "            dependencies = dependencies.merge(df_odegree, how=\"left\", on=\"name\")\n",
    "\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "        \n",
    "    columns_in = [\"_\".join([\"in\", obs]) for obs in observations]\n",
    "    columns_out = [\"_\".join([\"out\", obs]) for obs in observations]\n",
    "\n",
    "    dependencies[columns_in] = dependencies[columns_in].astype(\"Int64\")\n",
    "    dependencies[columns_in] = dependencies[columns_in].astype(str)\n",
    "\n",
    "    dependencies[columns_out] = dependencies[columns_out].astype(\"Int64\")\n",
    "    dependencies[columns_out] = dependencies[columns_out].astype(str)\n",
    "\n",
    "    dependencies.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "\n",
    "    np.savetxt('../data/individual/pkg_upstream.txt', dependencies[columns_out].values, fmt='%s')\n",
    "    np.savetxt('../data/individual/pkg_downstream.txt', dependencies[columns_in].values, fmt='%s')\n",
    "    \n",
    "create_package_dependencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723692912ae044a18646340026310cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_package_ages():\n",
    "    ages = sample_pkgs[['name', 'created']].copy()\n",
    "    ages['name'] = \"pkg_\" + ages['name']\n",
    "\n",
    "    with tqdm(total=len(observations)) as pbar:\n",
    "        for i, obs in enumerate(observations):\n",
    "            ages[obs] = (pd.to_datetime(obs, utc=True) - ages['created']) / np.timedelta64(1, 'M')\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "\n",
    "    ages[observations] = ages[observations].astype(float)\n",
    "    ages[observations] = ages[observations].astype(str)\n",
    "\n",
    "    ages.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "    np.savetxt('../data/individual/pkg_age.txt', ages[observations].values, fmt='%s')\n",
    "\n",
    "create_package_ages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Release Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_releases(package, start, end):\n",
    "    with driver.session(database='main') as session:\n",
    "        query = \"\"\"\n",
    "                MATCH (p:Package)-[:RELEASED]->(v:Version)\n",
    "                WHERE p.name = toString($package)\n",
    "                AND datetime($start) <= v.created < datetime($end)\n",
    "                RETURN COUNT(v)\n",
    "                \"\"\"\n",
    "\n",
    "        return session.run(query, package=package, start=start, end=end).single().value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8dcb9e19a8943b38c3209ba2cebfddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad4346b4cfb46218bcc23193256656a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3965f58013484299baa330e3b222e20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5345c137960842488a70ab2ae49d7b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c71293f86b46cfac938e6ede9216b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f5cebe3cf34a248a677ee69d1d4d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3dcccf37e84ccf97df877715056ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4b28296de3423da4b0e21258ff61de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935fc7ff362e43fab0fe8d09c7dfe9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_release_activity():\n",
    "    releases = sample_pkgs[['name']].copy()\n",
    "    with tqdm(total=len(observations)) as pbar:\n",
    "        for i, obs in enumerate(observations):\n",
    "            for index, row in tqdm(releases.iterrows(), total=len(releases.index), leave=False):\n",
    "                if i == 0:\n",
    "                    versions = get_releases(row['name'], OBSERVATION_START, obs)\n",
    "                else:\n",
    "                    versions = get_releases(row['name'], observations[i-1], obs)\n",
    "                    \n",
    "                releases.loc[index, obs] = int(versions)\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "    \n",
    "    releases[observations] = releases[observations].astype(\"Int8\")\n",
    "    releases[observations] = releases[observations].astype(str)\n",
    "    releases.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "    np.savetxt('../data/individual/pkg_releases.txt', releases[observations].values, fmt='%s')\n",
    "\n",
    "create_release_activity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Community Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_added_watchers(repo, start, end):\n",
    "    with driver.session(database='main') as session:\n",
    "        query = \"\"\"\n",
    "                MATCH (r:Repository)<-[w:WATCHES]-(u:User)\n",
    "                WHERE r.name = toString($repo)\n",
    "                AND datetime($start) < w.created <= datetime($end)\n",
    "                RETURN DISTINCT u\n",
    "                \"\"\"\n",
    "\n",
    "        result = session.run(query, repo=repo, start=start, end=end).value()\n",
    "        result_dict = [dict(_) for _ in result]\n",
    "        return len(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d9949996a54ccf9d1dcf2765eadd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f8924300f94c33935e2807bab41fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc51e895ed604601aba2d117c7e52d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b175fd7af3d4b11b89aa654b3a9c7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1358528473e4c76900dee0c5ed8c863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdfa1a0d7524ce3b0a78ed720de8480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0235856b0a546168cb66dd3f52edff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e12506c8754f2e890f23ca4a284893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6477fc88a8540ec81f99336dc5c29fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_community_interest():\n",
    "    stars = sample_pkgs[['name', 'repo_name']].copy()\n",
    "    with tqdm(total=len(observations)) as pbar:\n",
    "        for i, obs in enumerate(observations):\n",
    "            for index, row in tqdm(stars.iterrows(), total=len(stars.index), leave=False):\n",
    "                if i == 0:\n",
    "                    watchers = get_added_watchers(row['repo_name'], OBSERVATION_START, obs)\n",
    "                else:\n",
    "                    watchers = get_added_watchers(row['repo_name'], observations[i-1], obs)\n",
    "                    \n",
    "                stars.loc[index, obs] = int(watchers)\n",
    "\n",
    "            # stars[f'log_{obs}'] = np.log10(stars[obs] + 1)\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "\n",
    "    # columns = [\"_\".join(['log', obs]) for obs in observations]\n",
    "    # stars[columns] = stars[columns].astype(float)\n",
    "    # stars[columns] = stars[columns].astype(str)\n",
    "    stars[observations] = stars[observations].astype(float)\n",
    "    stars[observations] = stars[observations].astype(str)\n",
    "    stars.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "    # np.savetxt('../data/individual/pkg_community.txt', stars[columns].values, fmt='%s')\n",
    "    np.savetxt('../data/individual/pkg_community.txt', stars[observations].values, fmt='%s')\n",
    "    \n",
    "create_community_interest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repository Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def owned_by_organization(repo_name):\n",
    "    with driver.session(database=\"main\") as session:\n",
    "        query = \"\"\"\n",
    "            MATCH (r:Repository)\n",
    "            WHERE r.name = toString($repo_name)\n",
    "            RETURN EXISTS ( (r)-[:OWNED_BY]->(:Organization) )\n",
    "            \"\"\"\n",
    "        return session.run(query, repo_name=repo_name).single().value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_type(login):\n",
    "    with driver.session(database=\"main\") as session:\n",
    "        query = \"\"\"\n",
    "            OPTIONAL MATCH (u:User)\n",
    "            WHERE u.login = toString($login)\n",
    "            RETURN toString(u.type)\n",
    "            \"\"\"\n",
    "        return session.run(query, login=login).single().value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846a723c42634d7aa6d85cb63e472c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2861d75e454b49d5ae54698279d50068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_94496/3176030101.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/individual/pkg_repo_types.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mcreate_repository_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_94496/3176030101.py\u001b[0m in \u001b[0;36mcreate_repository_type\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mowned_by_organization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_94496/3906449036.py\u001b[0m in \u001b[0;36mowned_by_organization\u001b[0;34m(repo_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mRETURN\u001b[0m \u001b[0mEXISTS\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mOWNED_BY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mOrganization\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "def create_repository_type():\n",
    "    types = sample_pkgs[['name', 'repo_name', 'repo_owner']].copy()\n",
    "    types['name'] = \"pkg_\" + types['name']\n",
    "\n",
    "    with tqdm(total=len(observations)) as pbar:\n",
    "        for index, row in tqdm(types.iterrows(), total=len(types.index)):\n",
    "            if owned_by_organization(row['repo_name']):  \n",
    "                types.loc[index, \"type\"] = 1\n",
    "            else:\n",
    "                owner_type = get_user_type(row['repo_owner'])\n",
    "                if owner_type == \"Organization\":\n",
    "                    types.loc[index, \"type\"] = 1\n",
    "                elif owner_type == \"None\" or owner_type == \"User\":\n",
    "                    types.loc[index, \"type\"] = 2\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "\n",
    "    types['type'] = types['type'].astype(\"Int8\")\n",
    "    types['type'] = types['type'].astype(str)\n",
    "\n",
    "    types.replace(to_replace='<NA>', value='NA', inplace=True)\n",
    "    np.savetxt('../data/individual/pkg_repo_types.txt', types['type'].values, fmt='%s')\n",
    "\n",
    "create_repository_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dyadic Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Developer Participated in Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_association(developer, package, start, end):\n",
    "    with driver.session(database='main') as session:\n",
    "        query_comments = \"\"\"\n",
    "            MATCH (pa:Package)-[r:DEVELOPED_AT]->(pr:Project)\n",
    "            WHERE pa.name = toString($package)\n",
    "            WITH pr.id AS repo_name\n",
    "            MATCH (u:User)-[p:POSTED]->(c:Comment)-[*2]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND r.name = repo_name\n",
    "            AND c.created >= datetime($start)\n",
    "            AND c.created < datetime($end)\n",
    "            RETURN count(c) > 0 AS association\n",
    "            \"\"\"\n",
    "                \n",
    "        query_issues = \"\"\"\n",
    "            MATCH (pa:Package)-[r:DEVELOPED_AT]->(pr:Project)\n",
    "            WHERE pa.name = toString($package)\n",
    "            WITH pr.id AS repo_name\n",
    "            MATCH (u:User)-[a]->(i:Issue)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND r.name = repo_name\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN count(i) > 0 AS association\n",
    "            \"\"\"\n",
    "\n",
    "        query_pullreq = \"\"\"\n",
    "            MATCH (pa:Package)-[r:DEVELOPED_AT]->(pr:Project)\n",
    "            WHERE pa.name = toString($package)\n",
    "            WITH pr.id AS repo_name\n",
    "            MATCH (u:User)-[a]->(p:PullRequest)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND r.name = repo_name\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN count(p) > 0 AS association\n",
    "            \"\"\"\n",
    "\n",
    "        query_commits = \"\"\"\n",
    "            MATCH (pa:Package)-[r:DEVELOPED_AT]->(pr:Project)\n",
    "            WHERE pa.name = toString($package)\n",
    "            WITH pr.id AS repo_name\n",
    "            MATCH (u:User)-[a]->(c:Commit)-[:RELATED_TO]->(r:Repository)\n",
    "            WHERE u.login = toString($developer)\n",
    "            AND r.name = repo_name\n",
    "            AND a.created >= datetime($start)\n",
    "            AND a.created < datetime($end)\n",
    "            RETURN count(c) > 0 AS association\n",
    "            \"\"\"\n",
    "\n",
    "        results_comments = session.run(\n",
    "            query_comments, developer=developer, package=package, start=start, end=end).single().value()\n",
    "        results_issues = session.run(\n",
    "            query_issues, developer=developer, package=package, start=start, end=end).single().value()\n",
    "        results_pullreq = session.run(\n",
    "            query_pullreq, developer=developer, package=package, start=start, end=end).single().value()\n",
    "        results_commits = session.run(\n",
    "            query_commits, developer=developer, package=package, start=start, end=end).single().value()\n",
    "\n",
    "    return any([results_comments, results_issues, results_pullreq, results_commits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8463549f96ab405e807f195336afff3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad2976e94e74d23a5e9997eee7058fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fbff7bbc22495486795c8ef5f16f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2677efeaf446a9a8f2b63bd8591836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/859 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4624d7d1bc01457f909bd21e4bf2a052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63adc83265934dc3aa2588cbda9ae484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/676 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11c31e299e74935a864708275b96e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/676 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71623813988945159c8dbb79e409d672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/609 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86b0774fec34ce3b1576da66119f345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_dependencies_associations():\n",
    "    for i, an in tqdm(enumerate(affiliation_networks), total=len(affiliation_networks)):\n",
    "        G = an.copy()\n",
    "        \n",
    "        if i == 0:\n",
    "            start = OBSERVATION_START\n",
    "        else:\n",
    "            start = observations[i-1]\n",
    "        end = observations[i]\n",
    "        \n",
    "        for edge in tqdm(list(G.edges()), leave=False):\n",
    "            # Get dependencies for package\n",
    "            upstream = [dep[1] for dep in dependency_networks[i].out_edges(edge[1])]\n",
    "            downstream = [dep[0] for dep in dependency_networks[i].in_edges(edge[1])]\n",
    "\n",
    "            # Check if developer is associated with any of the dependencies\n",
    "            if upstream:\n",
    "                for udep in upstream:\n",
    "                    if has_association(edge[0][4:], udep[4:], start, end):\n",
    "                        G.edges[edge]['upstream'] = 1\n",
    "                    else:\n",
    "                        G.edges[edge]['upstream'] = 0\n",
    "            else:\n",
    "                G.edges[edge]['upstream'] = 0\n",
    "            \n",
    "            if downstream:\n",
    "                for ddep in downstream:\n",
    "                    if has_association(edge[0][4:], ddep[4:], start, end):\n",
    "                        G.edges[edge]['downstream'] = 1\n",
    "                    else:\n",
    "                        G.edges[edge]['downstream'] = 0\n",
    "            else:\n",
    "                G.edges[edge]['downstream'] = 0\n",
    "\n",
    "        \n",
    "        adj_up = nx.bipartite.biadjacency_matrix(G, row_order=nodelist_devs, column_order=nodelist_pkgs, weight=\"upstream\")\n",
    "        am_up = adj_up.toarray()\n",
    "        np.savetxt('../data/dyadic/dep_up_associations-{0}.txt'.format(observations[i]), am_up, fmt='%s')\n",
    "\n",
    "        adj_down = nx.bipartite.biadjacency_matrix(G, row_order=nodelist_devs, column_order=nodelist_pkgs, weight=\"downstream\")\n",
    "        am_down = adj_down.toarray()\n",
    "        np.savetxt('../data/dyadic/dep_down_associations-{0}.txt'.format(observations[i]), am_down, fmt='%s')\n",
    "        \n",
    "\n",
    "create_dependencies_associations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Developer Collaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def create_developer_collaboration():\n",
    "    for i, an in tqdm(enumerate(affiliation_networks), total=len(affiliation_networks)):\n",
    "        G = an.copy()\n",
    "        \n",
    "        if i == 0:\n",
    "            start = OBSERVATION_START\n",
    "        else:\n",
    "            start = observations[i-1]\n",
    "        end = observations[i]\n",
    "        \n",
    "        for edge in tqdm(list(G.edges()), leave=False):\n",
    "            # Get developer\n",
    "\n",
    "\n",
    "            # Get dependencies for package\n",
    "            upstream = [dep[1] for dep in dependency_networks[i].out_edges(edge[1])]\n",
    "            downstream = [dep[0] for dep in dependency_networks[i].in_edges(edge[1])]\n",
    "\n",
    "            # Check if developer is associated with any of the dependencies\n",
    "            if upstream:\n",
    "                for udep in upstream:\n",
    "                    if has_association(edge[0][4:], udep[4:], start, end):\n",
    "                        G.edges[edge]['upstream'] = 1\n",
    "                    else:\n",
    "                        G.edges[edge]['upstream'] = 0\n",
    "            else:\n",
    "                G.edges[edge]['upstream'] = 0\n",
    "            \n",
    "            if downstream:\n",
    "                for ddep in downstream:\n",
    "                    if has_association(edge[0][4:], ddep[4:], start, end):\n",
    "                        G.edges[edge]['downstream'] = 1\n",
    "                    else:\n",
    "                        G.edges[edge]['downstream'] = 0\n",
    "            else:\n",
    "                G.edges[edge]['downstream'] = 0\n",
    "\n",
    "        \n",
    "        adj_up = nx.bipartite.biadjacency_matrix(G, row_order=nodelist_devs, column_order=nodelist_pkgs, weight=\"upstream\")\n",
    "        am_up = adj_up.toarray()\n",
    "        np.savetxt('../data/dyadic/dep_up_associations-{0}.txt'.format(observations[i]), am_up, fmt='%s')\n",
    "\n",
    "        adj_down = nx.bipartite.biadjacency_matrix(G, row_order=nodelist_devs, column_order=nodelist_pkgs, weight=\"downstream\")\n",
    "        am_down = adj_down.toarray()\n",
    "        np.savetxt('../data/dyadic/dep_down_associations-{0}.txt'.format(observations[i]), am_down, fmt='%s')\n",
    "        \n",
    "\n",
    "create_developer_collaboration()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('posse-data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "050251c9507f1cd1ac24b95d1972ff337919e6ab4fcabee995ebef3358023628"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
